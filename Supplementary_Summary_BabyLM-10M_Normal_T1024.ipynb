{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb0e89b3-2816-40a6-be1b-f83c5214c1fd",
   "metadata": {},
   "source": [
    "# [Not used in the paper] Results for T1024 (=input token length is 1024)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb4dc65c-6467-45fb-b5c9-7c24dac02a6a",
   "metadata": {},
   "source": [
    "# Summary of best models for given numbers of layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b04acd9-4c29-4d1e-a7ef-092f5d11a11c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each row is the output for a model in the following format. Different lines for different model structures. See the cell below for the excecuted codes.\n",
    "# print(f'[ {num_hidden_layers}, {num_attention_heads}, {num_key_value_heads}, {hidden_size}, {intermediate_size}, {head_dim}, {sum(p.numel() for p in model.parameters()) / 10**6:.1f}, {tloss:.4f}, {torch.Tensor(loss).mean():.4f}, {N_step}],')\n",
    "# Example: [16layers, 12(6)heads, hidden-dim=696, inter-layer-dim = 696x4, head-dim=224, #param=218million, train_loss, val_loss, Num-steps]\n",
    "\n",
    "[+60, 2, 1, 624, 2496, 176, 351.7, 3.5747,+3.0256, 12000], # minGemma-hidden_layers60-att_heads2-kv_heads1-hidden624-intermediate2496-head_dim176-T1024--2025-10-09-20-45.pth\n",
    "[+54, 2, 1, 528, 2112, 256, 251.3, 3.4565,+3.0235, 12000], # minGemma-hidden_layers54-att_heads2-kv_heads1-hidden528-intermediate2112-head_dim256-T1024--2025-10-18-14-17.pth\n",
    "[+40, 3, 1, 624, 2496, 288, 276.0, 3.4662,+3.0202, 14500], # minGemma-hidden_layers40-att_heads3-kv_heads1-hidden624-intermediate2496-head_dim288-T1024--2025-10-24-03-16.pth\n",
    "[+30, 5, 1, 600, 2400, 192, 201.4, 3.4747,+3.0201, 12000], # minGemma-hidden_layers30-att_heads5-kv_heads1-hidden600-intermediate2400-head_dim192-T1024--2025-10-20-09-41.pth\n",
    "[+24, 6, 3, 648, 2592, 192, 207.4, 3.4755,+3.0223, 13000], # minGemma-hidden_layers24-att_heads6-kv_heads3-hidden648-intermediate2592-head_dim192-T1024--2025-10-21-09-47.pth\n",
    "[+20, 5, 1, 600, 2400, 256, 153.6, 3.3780,+3.0217, 13000], # minGemma-hidden_layers20-att_heads5-kv_heads1-hidden600-intermediate2400-head_dim256-T1024--2025-09-26-08-14.pth\n",
    "[+18, 6, 3, 576, 2304, 224, 142.5, 3.4368,+3.0234, 13000], # minGemma-hidden_layers18-att_heads6-kv_heads3-hidden576-intermediate2304-head_dim224-T1024--2025-10-28-14-50.pth\n",
    "[+12, 9, 3, 648, 2592, 288, 146.9, 3.4521,+3.0254, 13500], # minGemma-hidden_layers12-att_heads9-kv_heads3-hidden648-intermediate2592-head_dim288-T1024--2025-09-21-00-22.pth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33cc18af-10fc-4256-9475-0981b7adab07",
   "metadata": {},
   "source": [
    "# L60 (Models with 60 Layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4caba3ea-3d38-46d6-b736-1fb2bd8e97af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# L60 Normal Model T1024 (default: x4 B12 lr24e-4 WD1.2 N12000)\n",
    "# Best model for each number of heads:  2(1):3.0256\n",
    "\n",
    "# local best for H2(1): 3.0256  (bad)\n",
    "[ 60, 2, 1, 768, 3072, 240, 530.1, 3.8756, 3.0770, 12500], # 4.8h 47.0G\n",
    "[ 60, 2, 1, 768, 3072, 224, 525.7, 4.0031, 3.0688, 12500], # 4.7h 47.2G\n",
    "[ 60, 2, 1, 768, 3072, 208, 521.3, 3.9062, 3.0512, 12500], # 4.6h 46.6G\n",
    "[ 60, 2, 1, 768, 3072, 192, 516.9, 3.7774, 3.0494, 12500], # 4.5h 46.3G\n",
    "[ 60, 2, 1, 768, 3072, 176, 512.4, 3.7757, 3.0464, 12500], # 4.4h\n",
    "[ 60, 2, 1, 768, 3072, 160, 508.0, 4.0516, 3.0770, 12500], # 4.3h\n",
    "[ 60, 2, 1, 768, 3072, 144, 503.6, 3.9271, 3.0459, 12500], # 4.3h\n",
    "\n",
    "[ 60, 2, 1, 720, 2880, 288, 484.6, 3.7252, 3.0370, 12500], # 5.1h 47.1G\n",
    "[ 60, 2, 1, 720, 2880, 272, 480.4, 3.9561, 3.0723, 12500], # 5.0h 46.7G\n",
    "[ 60, 2, 1, 720, 2880, 256, 476.3, 3.6803, 3.0353, 12500], # 4.7h 46.2G\n",
    "[ 60, 2, 1, 720, 2880, 240, 472.1, 3.9310, 3.0628, 12500], # 4.6h 46.1G\n",
    "[ 60, 2, 1, 720, 2880, 224, 468.0, 3.9149, 3.0671, 12500], # 4.5h\n",
    "[ 60, 2, 1, 720, 2880, 208, 463.8, 3.9573, 3.0628, 12500], # 4.5h\n",
    "[ 60, 2, 1, 720, 2880, 192, 459.7, 3.9565, 3.0783, 12500], # 4.3h\n",
    "[ 60, 2, 1, 720, 2880, 176, 455.5, 3.6681, 3.0425, 12500], # 4.3h 44.6G\n",
    "[ 60, 2, 1, 720, 2880, 160, 451.4, 3.7766, 3.0494,  13000],# 4.4h\n",
    "[ 60, 2, 1, 720, 2880, 160, 451.4, 3.8359,+3.0299, 12500], # 4.2h 44.6G\n",
    "[ 60, 2, 1, 720, 2880, 160, 451.4, 3.9154, 3.0671,  12000],# 4.0h\n",
    "[ 60, 2, 1, 720, 2880, 144, 447.2, 3.8118, 3.0528, 12500], # 4.1h\n",
    "\n",
    "[ 60, 2, 1, 672, 2688, 288, 429.0, 4.0106, 3.0775, 12500], # 4.9h\n",
    "[ 60, 2, 1, 672, 2688, 272, 425.2, 3.5717, 3.0325,  13000],# 5.0h\n",
    "[ 60, 2, 1, 672, 2688, 272, 425.2, 3.6324, 3.0313, 12500], # 4.8h 44.9G\n",
    "[ 60, 2, 1, 672, 2688, 272, 425.2, 3.7851, 3.0432,  12000],# 4.6h 45.1G\n",
    "[ 60, 2, 1, 672, 2688, 256, 421.3, 3.7605, 3.0389, 12500], # 4.5h\n",
    "[ 60, 2, 1, 672, 2688, 240, 417.4, 3.7612, 3.0404, 12500], # 4.4h\n",
    "[ 60, 2, 1, 672, 2688, 224, 413.5, 3.8928, 3.0706, 12500], # 4.3h\n",
    "[ 60, 2, 1, 672, 2688, 208, 409.7, 3.7299, 3.0365, 12500], # 4.2h\n",
    "[ 60, 2, 1, 672, 2688, 192, 405.8, 4.0280, 3.1293, 12500], # 4.1h\n",
    "[ 60, 2, 1, 672, 2688, 176, 401.9, 3.7960, 3.0508, 12500], # 4.0h\n",
    "[ 60, 2, 1, 672, 2688, 160, 398.1, 3.7349, 3.0494, 12500], # 4.0h 43.2G\n",
    "[ 60, 2, 1, 672, 2688, 144, 394.2, 3.7889, 3.0329, 12500], # 3.9h 42.1G\n",
    "\n",
    "[ 60, 2, 1, 624, 2496, 304, 380.4, 3.9139, 3.0906, 12500], # 4.7h 42.9G\n",
    "[ 60, 2, 1, 624, 2496, 288, 376.8, 3.7573, 3.0458,  13000],# 4.7h\n",
    "[ 60, 2, 1, 624, 2496, 288, 376.8, 3.6125,+3.0293, 12500], # 4.5h\n",
    "[ 60, 2, 1, 624, 2496, 288, 376.8, 3.6759, 3.0312,  12000],# 4.3h\n",
    "[ 60, 2, 1, 624, 2496, 288, 376.8, 3.9313, 3.0511,  11500],# 4.1h 42.8G\n",
    "[ 60, 2, 1, 624, 2496, 272, 373.2, 3.7002, 3.0483, 12500], # 4.5h 43.6G\n",
    "[ 60, 2, 1, 624, 2496, 256, 369.6, 3.6903, 3.0524,  13000],# 4.3h 41.8G\n",
    "[ 60, 2, 1, 624, 2496, 256, 369.6, 3.6845, 3.0312, 12500], # 4.2h 42.9G\n",
    "[ 60, 2, 1, 624, 2496, 256, 369.6, 3.9473, 3.0762,  12000],# 4.0h 41.8G\n",
    "[ 60, 2, 1, 624, 2496, 240, 366.0, 3.7764, 3.0497, 12500], # 4.1h 42.3G\n",
    "[ 60, 2, 1, 624, 2496, 224, 362.4, 3.7305, 3.0455, 12500], # 4.0h 42.3G\n",
    "[ 60, 2, 1, 624, 2496, 208, 358.8, 3.9060, 3.0845, 12500], # 3.9h\n",
    "[ 60, 2, 1, 624, 2496, 192, 355.3, 3.8701, 3.0531, 12500], # 3.8h\n",
    "[ 60, 2, 1, 624, 2496, 176, 351.7, 3.7383, 3.0473,  13000],# 3.9h 40.7G\n",
    "[ 60, 2, 1, 624, 2496, 176, 351.7, 3.6283,+3.0299, 12500], # 3.7h\n",
    "[+60, 2, 1, 624, 2496, 176, 351.7, 3.5747,+3.0256,  12000],# 3.6h 40.9G  minGemma-hidden_layers60-att_heads2-kv_heads1-hidden624-intermediate2496-head_dim176-T1024--2025-10-09-20-45.pth\n",
    "[ 60, 2, 1, 624, 2496, 176, 351.7, 3.8843, 3.0462,  11500],# 3.5h\n",
    "[ 60, 2, 1, 624, 2496, 160, 348.1, 3.6655, 3.0325, 12500], # 3.7h\n",
    "[ 60, 2, 1, 624, 2496, 160, 348.1, 3.8101, 3.0446,  12000],# 3.5h 40.8G\n",
    "[ 60, 2, 1, 624, 2496, 144, 344.5, 3.7210, 3.0590, 12500], # 3.6h\n",
    "\n",
    "[ 60, 2, 1, 600, 2400, 192, 331.2, 3.6437, 3.0418, 28000], # 3.0h 23.3G\n",
    "\n",
    "[ 60, 2, 1, 576, 2304, 304, 331.2, 3.6658, 3.0394, 12500], # 4.4h\n",
    "[ 60, 2, 1, 576, 2304, 288, 327.9, 3.8490, 3.0652,  13500],# 4.7h\n",
    "[ 60, 2, 1, 576, 2304, 288, 327.9, 3.5646,+3.0265,  13000],# 4.5h 39.5G\n",
    "[ 60, 2, 1, 576, 2304, 288, 327.9, 3.4631,+3.0279, 12500], # 4.3h\n",
    "[ 60, 2, 1, 576, 2304, 288, 327.9, 3.7834, 3.0694,  12000],# 4.1h\n",
    "[ 60, 2, 1, 576, 2304, 272, 324.6, 3.7167, 3.0855,  13000],# 4.4h\n",
    "[ 60, 2, 1, 576, 2304, 272, 324.6, 3.5601,+3.0279, 12500], # 4.3h 40.5G\n",
    "[ 60, 2, 1, 576, 2304, 272, 324.6, 3.7615, 3.0595,  12000],# 4.1h\n",
    "[ 60, 2, 1, 576, 2304, 256, 321.3, 3.7524, 3.0632,  13000],# 4.1h 40.3G\n",
    "[ 60, 2, 1, 576, 2304, 256, 321.3, 3.5442,+3.0275, 12500], # 3.9h\n",
    "[ 60, 2, 1, 576, 2304, 256, 321.3, 3.7274, 3.0534,  12000],# 3.8h\n",
    "[ 60, 2, 1, 576, 2304, 240, 318.0, 3.6268, 3.0394,  13000],# 4.0h 40.1G\n",
    "[ 60, 2, 1, 576, 2304, 240, 318.0, 3.5012,+3.0269, 12500], # 3.9h\n",
    "[ 60, 2, 1, 576, 2304, 240, 318.0, 3.9016, 3.0541,  12000],# 3.7h\n",
    "[ 60, 2, 1, 576, 2304, 224, 314.7, 3.6571, 3.0343, 12500], # 3.8h 40.2G\n",
    "[ 60, 2, 1, 576, 2304, 208, 311.3, 3.9229, 3.1119, 12500], # 3.7h\n",
    "[ 60, 2, 1, 576, 2304, 192, 308.0, 3.6259, 3.0317, 12500], # 3.6h\n",
    "[ 60, 2, 1, 576, 2304, 192, 308.0, 3.6123, 3.0315,  12000],# 3.5h\n",
    "[ 60, 2, 1, 576, 2304, 192, 308.0, 3.6880, 3.0339,  11500],# 3.3h\n",
    "[ 60, 2, 1, 576, 2304, 176, 304.7, 3.7724, 3.0484, 12500], # 3.6h\n",
    "[ 60, 2, 1, 576, 2304, 160, 301.4, 3.7182, 3.0499,  13500],# 3.7h\n",
    "[ 60, 2, 1, 576, 2304, 160, 301.4, 3.5866, 3.0313,  13000],# 3.6h\n",
    "[ 60, 2, 1, 576, 2304, 160, 301.4, 3.4942,+3.0287, 12500], # 3.5h\n",
    "[ 60, 2, 1, 576, 2304, 160, 301.4, 3.6465, 3.0408,  12000],# 3.3h\n",
    "[ 60, 2, 1, 576, 2304, 144, 298.1, 3.7310, 3.0531,  13500],# 3.6h 37.8G\n",
    "[ 60, 2, 1, 576, 2304, 144, 298.1, 3.5415, 3.0314,  13000],# 3.5h\n",
    "[ 60, 2, 1, 576, 2304, 144, 298.1, 3.5279, 3.0310, 12500], # 3.4h\n",
    "[ 60, 2, 1, 576, 2304, 144, 298.1, 3.6448, 3.0437,  12000],# 3.2h\n",
    "[ 60, 2, 1, 576, 2304, 128, 294.7, 3.7829, 3.0583, 12500], # 2.9h\n",
    "\n",
    "[ 60, 2, 1, 528, 2112, 304, 285.4, 3.6636, 3.0677, 12500], # 4.2h\n",
    "[ 60, 2, 1, 528, 2112, 288, 282.4, 3.5935, 3.0366, 12500], # 4.2h 35.2G\n",
    "[ 60, 2, 1, 528, 2112, 272, 279.3, 3.6990, 3.0597, 12500], # 4.1h\n",
    "[ 60, 2, 1, 528, 2112, 256, 276.3, 3.7303, 3.0898,  14000],# 4.2h\n",
    "[ 60, 2, 1, 528, 2112, 256, 276.3, 3.4202,+3.0275,  13500],# 4.1h\n",
    "[ 60, 2, 1, 528, 2112, 256, 276.3, 3.4581, 3.0318,  13000],# 3.9h 38.8G\n",
    "[ 60, 2, 1, 528, 2112, 256, 276.3, 3.4436,+3.0290, 12500], # 3.8h\n",
    "[ 60, 2, 1, 528, 2112, 256, 276.3, 3.7528, 3.0587,  12000],# 3.6h 36.8G\n",
    "[ 60, 2, 1, 528, 2112, 240, 273.2, 3.5314, 3.0388, 12500], # 3.8h\n",
    "[ 60, 2, 1, 528, 2112, 224, 270.2, 3.6724, 3.0744,  13000],# 3.8h 36.0G\n",
    "[ 60, 2, 1, 528, 2112, 224, 270.2, 3.4741,+3.0304, 12500], # 3.6h\n",
    "[ 60, 2, 1, 528, 2112, 224, 270.2, 3.6150, 3.0485,  12000],# 3.5h\n",
    "[ 60, 2, 1, 528, 2112, 208, 267.1, 3.7048, 3.0589, 12500], # 3.6h 37.8G\n",
    "[ 60, 2, 1, 528, 2112, 192, 264.1, 3.6475, 3.0490, 12500], # 3.5h\n",
    "[ 60, 2, 1, 528, 2112, 176, 261.1, 3.4642, 3.0352, 12500], # 3.4h\n",
    "[ 60, 2, 1, 528, 2112, 160, 258.0, 3.8008, 3.2576, 12500], # 3.3h\n",
    "[ 60, 2, 1, 528, 2112, 144, 255.0, 3.6696, 3.0705, 12500], # 3.2h\n",
    "\n",
    "[ 60, 2, 1, 504, 2016, 336, 269.5, 3.4897, 3.0371, 12500], # 4.3h\n",
    "[ 60, 2, 1, 504, 2016, 320, 266.6, 3.6960, 3.0662,  13000],# 4.4h\n",
    "[ 60, 2, 1, 504, 2016, 320, 266.6, 3.4443,+3.0286, 12500], # 4.2h\n",
    "[ 60, 2, 1, 504, 2016, 320, 266.6, 3.5796, 3.0392,  12000],# 4.0h\n",
    "[ 60, 2, 1, 504, 2016, 304, 263.7, 3.7758, 3.0731,  13000],# 4.3h\n",
    "[+60, 2, 1, 504, 2016, 304, 263.7, 3.4299,+3.0257, 12500], # 4.1h  minGemma-hidden_layers60-att_heads2-kv_heads1-hidden504-intermediate2016-head_dim304-T1024--2025-10-05-21-52.pth\n",
    "[ 60, 2, 1, 504, 2016, 304, 263.7, 3.4811, 3.0316,  12000],# 4.0h 37.3G\n",
    "[ 60, 2, 1, 504, 2016, 304, 263.7, 3.4972, 3.0338,  11500],# 3.8h\n",
    "[ 60, 2, 1, 504, 2016, 304, 263.7, 3.5228, 3.0384,  11000],# 3.6h\n",
    "[ 60, 2, 1, 504, 2016, 304, 263.7, 3.7619, 3.0636,  10500],# 3.4h\n",
    "[ 60, 2, 1, 504, 2016, 304, 263.7, 3.6908, 3.0501,  10000],# 3.3h\n",
    "[ 60, 2, 1, 504, 2016, 288, 260.8, 3.6730, 3.0820, 12500], # 4.0h\n",
    "[ 60, 2, 1, 504, 2016, 272, 257.9, 3.6881, 3.0645, 12500], # 3.9h\n",
    "[ 60, 2, 1, 504, 2016, 256, 255.0, 3.5665, 3.0417, 12500], # 3.7h\n",
    "[ 60, 2, 1, 504, 2016, 240, 252.1, 3.7240, 3.0739,  13000],# 3.8h 33.7G\n",
    "[ 60, 2, 1, 504, 2016, 240, 252.1, 3.4577,+3.0268, 12500], # 3.6h\n",
    "[ 60, 2, 1, 504, 2016, 240, 252.1, 3.5785, 3.0418,  12000],# 3.5h\n",
    "[ 60, 2, 1, 504, 2016, 224, 249.2, 3.4558, 3.0408, 12500], # 3.5h 34.6G\n",
    "[ 60, 2, 1, 504, 2016, 208, 246.3, 3.5996, 3.0478, 12500], # 3.4h 36.4G\n",
    "[ 60, 2, 1, 504, 2016, 192, 243.4, 3.4999, 3.0337, 12500], # 3.3h 33.2G\n",
    "[ 60, 2, 1, 504, 2016, 176, 240.5, 3.4867, 3.0397, 12500], # 3.3h\n",
    "[ 60, 2, 1, 504, 2016, 160, 237.6, 3.6753, 3.0531, 12500], # 3.2h\n",
    "[ 60, 2, 1, 504, 2016, 144, 234.7, 3.7048, 3.0768, 12500], # 3.1h\n",
    "\n",
    "[ 60, 2, 1, 480, 1920, 320, 245.6, 3.4640, 3.0402, 12500], # 4.0h 34.7G\n",
    "[ 60, 2, 1, 480, 1920, 304, 242.9, 3.4126, 3.0374, 12500], # 4.0h\n",
    "[ 60, 2, 1, 480, 1920, 288, 240.1, 3.6187, 3.0539, 12500], # 3.9h 34.3G\n",
    "[ 60, 2, 1, 480, 1920, 272, 237.3, 3.5099, 3.0391, 12500], # 3.8h\n",
    "[ 60, 2, 1, 480, 1920, 256, 234.6, 3.5138, 3.0377, 12500], # 3.5h\n",
    "[ 60, 2, 1, 480, 1920, 240, 231.8, 3.5320, 3.0471, 12500], # 3.4h\n",
    "[ 60, 2, 1, 480, 1920, 224, 229.0, 3.5863, 3.0461,  13500],# 3.6h\n",
    "[ 60, 2, 1, 480, 1920, 224, 229.0, 3.4044,+3.0309,  13000],# 3.5h\n",
    "[ 60, 2, 1, 480, 1920, 224, 229.0, 3.4351,+3.0281, 12500], # 3.4h\n",
    "[ 60, 2, 1, 480, 1920, 224, 229.0, 3.6663, 3.0753,  12000],# 3.2h\n",
    "[ 60, 2, 1, 480, 1920, 208, 226.3, 3.4278, 3.0333, 12500], # 3.3h\n",
    "[ 60, 2, 1, 480, 1920, 192, 223.5, 3.4401, 3.0321, 12500], # 3.2h\n",
    "[ 60, 2, 1, 480, 1920, 176, 220.7, 3.6413, 3.0604, 12500], # 3.1h\n",
    "[ 60, 2, 1, 480, 1920, 160, 218.0, 3.5207, 3.0509, 12500], # 3.0h 32.1G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "eb1f2ae3-fc49-4666-9df6-af16f8f15cfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "147.456\n",
      "L60 att2 kv_heads1 hidden624 intermediate2496 head_dim176 T1024\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='12000' max='12000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [12000/12000 3:38:41, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>3.574700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 60, 2, 1, 624, 2496, 176, 351.7, 3.5747, 3.0256, 12000],\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt; import numpy as np; import time, torch; device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "from transformers import AutoTokenizer, TrainingArguments, DefaultDataCollator, Trainer\n",
    "vocab_size = 50257 # =tokenizer.vocab_size  # FIX!!! # G256128    ### T=256 for minGemma # G8192 for real Gemma\n",
    "num_hidden_layers =  60 # 8 # G28 G18 #blocks\n",
    "num_attention_heads = 2 # 4 # G16 G8\n",
    "num_key_value_heads = 1 # 4 # G16 G1\n",
    "hidden_size = num_attention_heads*312 # 128 # G3072 G2048 # embedding dimension\n",
    "intermediate_size = hidden_size*4 # x4 or x8 # time limiting factor #512 # G24576 G16384  # MLP inner dim\n",
    "head_dim = 176 # 32 # G256 # dim in attention # Doesn't affect time\n",
    "rms_norm_eps = 1e-6 # 1e-6\n",
    "rope_theta = 1000.0 # scale freq is small for S-model. 1000 might work too # G10000.0\n",
    "\n",
    "def apply_rotary_emb(x: torch.Tensor, dim: int) -> torch.Tensor: # seq_len = x.size(1) # N\n",
    "    freqs = 1.0 / (rope_theta ** (torch.arange(0, dim, 2, device=device).float() / dim)) # Dynamically compute frequency cis\n",
    "    t = torch.arange(x.size(1), device=device); freqs = torch.outer(t, freqs).float(); freqs_cis = torch.polar(torch.ones_like(freqs), freqs)  # complex64\n",
    "    x_ = torch.view_as_complex(torch.stack(torch.chunk(x.transpose(1, 2).float(), 2, dim=-1), dim=-1))\n",
    "    x_out = torch.view_as_real(x_ * freqs_cis.unsqueeze(0)).type_as(x)  # Ensure batch dimension is handled\n",
    "    x_out = torch.cat(torch.chunk(x_out, 2, dim=-1), dim=-2)\n",
    "    return x_out.reshape(x_out.shape[0], x_out.shape[1], x_out.shape[2], -1).transpose(1, 2)\n",
    "\n",
    "class RMSNorm(torch.nn.Module): # RMS:4.326552, RMS_no_weight:4.410741 # RMS':4.554899\n",
    "    def __init__(self, dim: int = hidden_size):\n",
    "        super().__init__(); self.weight = torch.nn.Parameter(torch.zeros(dim)) # one weight per feature to be learned\n",
    "    def _norm(self, x): # mean square for each feature (across the last dimension)\n",
    "        return x * torch.rsqrt(x.pow(2).mean(-1, keepdim=True) + rms_norm_eps)\n",
    "    def forward(self, x): # ensure the data type matches the input.\n",
    "        return self._norm(x.float()).type_as(x) * (1 + self.weight)\n",
    "        \n",
    "class GemmaAttention(torch.nn.Module): # MQA = K,V shared by 4Qs\n",
    "    def __init__(self):\n",
    "        super().__init__(); self.qkv_proj = torch.nn.Linear(hidden_size, (num_attention_heads + 2 * num_key_value_heads) * head_dim, bias=False); self.o_proj = torch.nn.Linear(num_attention_heads * head_dim, hidden_size, bias=False) # concatenated attention outputs back to the hidden size.\n",
    "    def forward(self, hidden_states: torch.Tensor,) -> torch.Tensor:  # in=(B, T, hidden_size)\n",
    "        batch_size, input_len, _ = hidden_states.shape\n",
    "        qkv = self.qkv_proj(hidden_states)\n",
    "        xq, xk, xv = qkv.split([num_attention_heads * head_dim, num_key_value_heads * head_dim, num_key_value_heads * head_dim],dim=-1)\n",
    "        xq = xq.view(batch_size, -1, num_attention_heads, head_dim); xk = xk.view(batch_size, -1, num_key_value_heads, head_dim); xv = xv.view(batch_size, -1, num_key_value_heads, head_dim)\n",
    "        xq = apply_rotary_emb(xq, head_dim); xk = apply_rotary_emb(xk, head_dim)\n",
    "        if num_key_value_heads != num_attention_heads:  # Q/KV multiples of K and V to match Q\n",
    "            xk = torch.repeat_interleave(xk, num_attention_heads // num_key_value_heads, dim=2) # [B, T, n_local_heads, head_dim]\n",
    "            xv = torch.repeat_interleave(xv, num_attention_heads // num_key_value_heads, dim=2)\n",
    "        q = xq.transpose(1, 2); k = xk.transpose(1, 2); v = xv.transpose(1, 2) # [batch_size, n_local_heads, input_len, head_dim]\n",
    "        output = torch.nn.functional.scaled_dot_product_attention(q, k, v, attn_mask=None, dropout_p=0, is_causal=True) # B nh T hs        \n",
    "        output = output.transpose(1, 2).contiguous().view(batch_size, input_len, -1)  # [B, T, \"hidden_dim\"]\n",
    "        return self.o_proj(output)\n",
    "\n",
    "class GemmaDecoderLayer(torch.nn.Module): # normalize before and after the attention mechanism\n",
    "    def __init__(self):\n",
    "        super().__init__(); self.self_attn = GemmaAttention(); self.input_layernorm = RMSNorm(); self.post_attention_layernorm = RMSNorm(); self.gate_proj = torch.nn.Linear(hidden_size, intermediate_size); self.up_proj = torch.nn.Linear(hidden_size, intermediate_size); self.down_proj = torch.nn.Linear(intermediate_size, hidden_size) # mlp\n",
    "    def forward(self, hidden_states: torch.Tensor) -> torch.Tensor:  # input_size = (B, T, hidden_size)\n",
    "        residual = hidden_states # Self Attention Block\n",
    "        hidden_states = self.input_layernorm(hidden_states); hidden_states = self.self_attn(hidden_states=hidden_states)\n",
    "        hidden_states = residual + hidden_states\n",
    "        residual = hidden_states # MLP Block\n",
    "        hidden_states = self.post_attention_layernorm(hidden_states); gate = torch.nn.functional.gelu(self.gate_proj(hidden_states)); up = self.up_proj(hidden_states); fuse = gate * up; hidden_states = self.down_proj(fuse) # mlp\n",
    "        return residual + hidden_states\n",
    "\n",
    "class minGemma(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__(); self.embedder = torch.nn.Embedding(vocab_size, hidden_size); self.layers = torch.nn.ModuleList(GemmaDecoderLayer() for _ in range(num_hidden_layers)); self.norm = RMSNorm();\n",
    "    def forward(self, input_token_ids: torch.Tensor) -> torch.Tensor: # (B, T)\n",
    "        hidden_states = self.embedder(input_token_ids[:,:-1]) # (B, T) & (vocab_size, hidden_size) -> (B, T, hidden_size)\n",
    "        hidden_states = hidden_states * (hidden_size**0.5)\n",
    "        for i in range(len(self.layers)):\n",
    "            hidden_states = self.layers[i](hidden_states) # shortened too much???\n",
    "        hidden_states = self.norm(hidden_states) # -> (B, T, hidden_size)        \n",
    "        embedder_weight = self.embedder.weight\n",
    "        logits = torch.matmul(hidden_states, embedder_weight.t()); b,t,v=logits.shape; # (B, T, hidden_size) @ (hidden_size, vocab_size) -> (B, T, vocab_size)\n",
    "        loss = torch.nn.functional.cross_entropy(logits.view(b*t,v), input_token_ids[:,1:].reshape(b*t)) #, weight=None, ignore_index=-100, reduction='mean')\n",
    "        return loss, logits # logits, loss\n",
    "\n",
    "def map_to_array5(ix):\n",
    "    common = torch.stack([torch.from_numpy((train_data[i[0]:i[0]+T+1]).astype(np.int64)) for i in ix]); return {'input_token_ids': common}\n",
    "def map_to_array_Val(ix):\n",
    "    common = torch.stack([torch.from_numpy((val_data[i[0]:i[0]+T+1]).astype(np.int64)) for i in ix]); return {'input_token_ids': common}\n",
    "\n",
    "train_data = np.memmap('train_BabyLM_10M.bin', dtype=np.uint16, mode='r'); val_data = np.memmap('val_BabyLM.bin', dtype=np.uint16, mode='r')\n",
    "T=1024; B=12; N_step=12000; print(T * B * N_step / 1000000) # 0.01 B-tokens being calculated # n_steps=N_step;\n",
    "model = minGemma().to(device); print(f'L{num_hidden_layers}' f' att{num_attention_heads}' f' kv_heads{num_key_value_heads}' f' hidden{hidden_size}' f' intermediate{intermediate_size}' f' head_dim{head_dim}' f' T{T}')\n",
    "\n",
    "# Normal # lr_scheduler_type=\"linear\" can be omitted\n",
    "training_args = TrainingArguments(learning_rate=24.0e-4, weight_decay=1.2, num_train_epochs=1, logging_strategy='epoch', output_dir='./', bf16=True, per_device_train_batch_size=B, per_device_eval_batch_size=B, eval_strategy='no', save_strategy='no', report_to='none', remove_unused_columns=False, dataloader_pin_memory=True) #, dataloader_num_workers=4\n",
    "trainer = Trainer(model=model, args=training_args, train_dataset=torch.utils.data.TensorDataset(torch.randint(len(train_data)-T-1, (B*N_step,))), data_collator=map_to_array5);\n",
    "result = trainer.train(); tloss=result[2][\"train_loss\"] # trainer = Trainer(model=model, args=training_args, eval_dataset=torch.utils.data.TensorDataset(torch.randint(len(val_data)-T-1, (B*400*4,))), data_collator=map_to_array_Val); trainer.can_return_loss = True; loss_current = trainer.evaluate()[\"eval_loss\"]\n",
    "\n",
    "loss = []; model.eval(); B2=16; B2=12; torch.cuda.empty_cache();\n",
    "for k in range(5000): #4000 # std=0.0056 for 1000 with 89sec\n",
    "    val_ind = torch.randint(len(val_data)-T-1, (B2,)); common = (torch.stack([torch.from_numpy((val_data[i:i+T+1]).astype(np.int64)) for i in val_ind]))\n",
    "    loss += [model(common.to('cuda', non_blocking=True))[0].item()]\n",
    "if torch.Tensor(loss).mean() < 3.0256:\n",
    "    torch.save(model.state_dict(), f'{model.__class__.__name__}' f'-hidden_layers{num_hidden_layers}' f'-att_heads{num_attention_heads}' f'-kv_heads{num_key_value_heads}' f'-hidden{hidden_size}' f'-intermediate{intermediate_size}' f'-head_dim{head_dim}' f'-T{T}' f'--{time.strftime(\"%Y-%m-%d-%H-%M\")}.pth')\n",
    "model.train(); del common; print(f'[ {num_hidden_layers}, {num_attention_heads}, {num_key_value_heads}, {hidden_size}, {intermediate_size}, {head_dim}, {sum(p.numel() for p in model.parameters()) / 10**6:.1f}, {tloss:.4f}, {torch.Tensor(loss).mean():.4f}, {N_step}],')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f7887d8e-4943-4885-9e6e-2d811aaef24d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "153.6\n",
      "L60 att2 kv_heads1 hidden504 intermediate2016 head_dim304 T1024\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='12500' max='12500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [12500/12500 4:09:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>12500</td>\n",
       "      <td>3.429900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 60, 2, 1, 504, 2016, 304, 263.7, 3.4299, 3.0257, 12500],\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt; import numpy as np; import time, torch; device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "from transformers import AutoTokenizer, TrainingArguments, DefaultDataCollator, Trainer\n",
    "vocab_size = 50257 # =tokenizer.vocab_size  # FIX!!! # G256128    ### T=256 for minGemma # G8192 for real Gemma\n",
    "num_hidden_layers =  60 # 8 # G28 G18 #blocks\n",
    "num_attention_heads = 2 # 4 # G16 G8\n",
    "num_key_value_heads = 1 # 4 # G16 G1\n",
    "hidden_size = num_attention_heads*252 # 128 # G3072 G2048 # embedding dimension\n",
    "intermediate_size = hidden_size*4 # x4 or x8 # time limiting factor #512 # G24576 G16384  # MLP inner dim\n",
    "head_dim = 304 # 32 # G256 # dim in attention # Doesn't affect time\n",
    "rms_norm_eps = 1e-6 # 1e-6\n",
    "rope_theta = 1000.0 # scale freq is small for S-model. 1000 might work too # G10000.0\n",
    "\n",
    "def apply_rotary_emb(x: torch.Tensor, dim: int) -> torch.Tensor: # seq_len = x.size(1) # N\n",
    "    freqs = 1.0 / (rope_theta ** (torch.arange(0, dim, 2, device=device).float() / dim)) # Dynamically compute frequency cis\n",
    "    t = torch.arange(x.size(1), device=device); freqs = torch.outer(t, freqs).float(); freqs_cis = torch.polar(torch.ones_like(freqs), freqs)  # complex64\n",
    "    x_ = torch.view_as_complex(torch.stack(torch.chunk(x.transpose(1, 2).float(), 2, dim=-1), dim=-1))\n",
    "    x_out = torch.view_as_real(x_ * freqs_cis.unsqueeze(0)).type_as(x)  # Ensure batch dimension is handled\n",
    "    x_out = torch.cat(torch.chunk(x_out, 2, dim=-1), dim=-2)\n",
    "    return x_out.reshape(x_out.shape[0], x_out.shape[1], x_out.shape[2], -1).transpose(1, 2)\n",
    "\n",
    "class RMSNorm(torch.nn.Module): # RMS:4.326552, RMS_no_weight:4.410741 # RMS':4.554899\n",
    "    def __init__(self, dim: int = hidden_size):\n",
    "        super().__init__(); self.weight = torch.nn.Parameter(torch.zeros(dim)) # one weight per feature to be learned\n",
    "    def _norm(self, x): # mean square for each feature (across the last dimension)\n",
    "        return x * torch.rsqrt(x.pow(2).mean(-1, keepdim=True) + rms_norm_eps)\n",
    "    def forward(self, x): # ensure the data type matches the input.\n",
    "        return self._norm(x.float()).type_as(x) * (1 + self.weight)\n",
    "        \n",
    "class GemmaAttention(torch.nn.Module): # MQA = K,V shared by 4Qs\n",
    "    def __init__(self):\n",
    "        super().__init__(); self.qkv_proj = torch.nn.Linear(hidden_size, (num_attention_heads + 2 * num_key_value_heads) * head_dim, bias=False); self.o_proj = torch.nn.Linear(num_attention_heads * head_dim, hidden_size, bias=False) # concatenated attention outputs back to the hidden size.\n",
    "    def forward(self, hidden_states: torch.Tensor,) -> torch.Tensor:  # in=(B, T, hidden_size)\n",
    "        batch_size, input_len, _ = hidden_states.shape\n",
    "        qkv = self.qkv_proj(hidden_states)\n",
    "        xq, xk, xv = qkv.split([num_attention_heads * head_dim, num_key_value_heads * head_dim, num_key_value_heads * head_dim],dim=-1)\n",
    "        xq = xq.view(batch_size, -1, num_attention_heads, head_dim); xk = xk.view(batch_size, -1, num_key_value_heads, head_dim); xv = xv.view(batch_size, -1, num_key_value_heads, head_dim)\n",
    "        xq = apply_rotary_emb(xq, head_dim); xk = apply_rotary_emb(xk, head_dim)\n",
    "        if num_key_value_heads != num_attention_heads:  # Q/KV multiples of K and V to match Q\n",
    "            xk = torch.repeat_interleave(xk, num_attention_heads // num_key_value_heads, dim=2) # [B, T, n_local_heads, head_dim]\n",
    "            xv = torch.repeat_interleave(xv, num_attention_heads // num_key_value_heads, dim=2)\n",
    "        q = xq.transpose(1, 2); k = xk.transpose(1, 2); v = xv.transpose(1, 2) # [batch_size, n_local_heads, input_len, head_dim]\n",
    "        output = torch.nn.functional.scaled_dot_product_attention(q, k, v, attn_mask=None, dropout_p=0, is_causal=True) # B nh T hs        \n",
    "        output = output.transpose(1, 2).contiguous().view(batch_size, input_len, -1)  # [B, T, \"hidden_dim\"]\n",
    "        return self.o_proj(output)\n",
    "\n",
    "class GemmaDecoderLayer(torch.nn.Module): # normalize before and after the attention mechanism\n",
    "    def __init__(self):\n",
    "        super().__init__(); self.self_attn = GemmaAttention(); self.input_layernorm = RMSNorm(); self.post_attention_layernorm = RMSNorm(); self.gate_proj = torch.nn.Linear(hidden_size, intermediate_size); self.up_proj = torch.nn.Linear(hidden_size, intermediate_size); self.down_proj = torch.nn.Linear(intermediate_size, hidden_size) # mlp\n",
    "    def forward(self, hidden_states: torch.Tensor) -> torch.Tensor:  # input_size = (B, T, hidden_size)\n",
    "        residual = hidden_states # Self Attention Block\n",
    "        hidden_states = self.input_layernorm(hidden_states); hidden_states = self.self_attn(hidden_states=hidden_states)\n",
    "        hidden_states = residual + hidden_states\n",
    "        residual = hidden_states # MLP Block\n",
    "        hidden_states = self.post_attention_layernorm(hidden_states); gate = torch.nn.functional.gelu(self.gate_proj(hidden_states)); up = self.up_proj(hidden_states); fuse = gate * up; hidden_states = self.down_proj(fuse) # mlp\n",
    "        return residual + hidden_states\n",
    "\n",
    "class minGemma(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__(); self.embedder = torch.nn.Embedding(vocab_size, hidden_size); self.layers = torch.nn.ModuleList(GemmaDecoderLayer() for _ in range(num_hidden_layers)); self.norm = RMSNorm();\n",
    "    def forward(self, input_token_ids: torch.Tensor) -> torch.Tensor: # (B, T)\n",
    "        hidden_states = self.embedder(input_token_ids[:,:-1]) # (B, T) & (vocab_size, hidden_size) -> (B, T, hidden_size)\n",
    "        hidden_states = hidden_states * (hidden_size**0.5)\n",
    "        for i in range(len(self.layers)):\n",
    "            hidden_states = self.layers[i](hidden_states) # shortened too much???\n",
    "        hidden_states = self.norm(hidden_states) # -> (B, T, hidden_size)        \n",
    "        embedder_weight = self.embedder.weight\n",
    "        logits = torch.matmul(hidden_states, embedder_weight.t()); b,t,v=logits.shape; # (B, T, hidden_size) @ (hidden_size, vocab_size) -> (B, T, vocab_size)\n",
    "        loss = torch.nn.functional.cross_entropy(logits.view(b*t,v), input_token_ids[:,1:].reshape(b*t)) #, weight=None, ignore_index=-100, reduction='mean')\n",
    "        return loss, logits # logits, loss\n",
    "\n",
    "def map_to_array5(ix):\n",
    "    common = torch.stack([torch.from_numpy((train_data[i[0]:i[0]+T+1]).astype(np.int64)) for i in ix]); return {'input_token_ids': common}\n",
    "def map_to_array_Val(ix):\n",
    "    common = torch.stack([torch.from_numpy((val_data[i[0]:i[0]+T+1]).astype(np.int64)) for i in ix]); return {'input_token_ids': common}\n",
    "\n",
    "train_data = np.memmap('train_BabyLM_10M.bin', dtype=np.uint16, mode='r'); val_data = np.memmap('val_BabyLM.bin', dtype=np.uint16, mode='r')\n",
    "T=1024; B=12; N_step=12500; print(T * B * N_step / 1000000) # 0.01 B-tokens being calculated # n_steps=N_step;\n",
    "model = minGemma().to(device); print(f'L{num_hidden_layers}' f' att{num_attention_heads}' f' kv_heads{num_key_value_heads}' f' hidden{hidden_size}' f' intermediate{intermediate_size}' f' head_dim{head_dim}' f' T{T}')\n",
    "\n",
    "# Normal # lr_scheduler_type=\"linear\" can be omitted\n",
    "training_args = TrainingArguments(learning_rate=24.0e-4, weight_decay=1.2, num_train_epochs=1, logging_strategy='epoch', output_dir='./', bf16=True, per_device_train_batch_size=B, per_device_eval_batch_size=B, eval_strategy='no', save_strategy='no', report_to='none', remove_unused_columns=False, dataloader_pin_memory=True) #, dataloader_num_workers=4\n",
    "trainer = Trainer(model=model, args=training_args, train_dataset=torch.utils.data.TensorDataset(torch.randint(len(train_data)-T-1, (B*N_step,))), data_collator=map_to_array5);\n",
    "result = trainer.train(); tloss=result[2][\"train_loss\"] # trainer = Trainer(model=model, args=training_args, eval_dataset=torch.utils.data.TensorDataset(torch.randint(len(val_data)-T-1, (B*400*4,))), data_collator=map_to_array_Val); trainer.can_return_loss = True; loss_current = trainer.evaluate()[\"eval_loss\"]\n",
    "\n",
    "loss = []; model.eval(); B2=16; B2=12; torch.cuda.empty_cache();\n",
    "for k in range(5000): #4000 # std=0.0056 for 1000 with 89sec\n",
    "    val_ind = torch.randint(len(val_data)-T-1, (B2,)); common = (torch.stack([torch.from_numpy((val_data[i:i+T+1]).astype(np.int64)) for i in val_ind]))\n",
    "    loss += [model(common.to('cuda', non_blocking=True))[0].item()]\n",
    "if torch.Tensor(loss).mean() < 3.0257:\n",
    "    torch.save(model.state_dict(), f'{model.__class__.__name__}' f'-hidden_layers{num_hidden_layers}' f'-att_heads{num_attention_heads}' f'-kv_heads{num_key_value_heads}' f'-hidden{hidden_size}' f'-intermediate{intermediate_size}' f'-head_dim{head_dim}' f'-T{T}' f'--{time.strftime(\"%Y-%m-%d-%H-%M\")}.pth')\n",
    "model.train(); del common; print(f'[ {num_hidden_layers}, {num_attention_heads}, {num_key_value_heads}, {hidden_size}, {intermediate_size}, {head_dim}, {sum(p.numel() for p in model.parameters()) / 10**6:.1f}, {tloss:.4f}, {torch.Tensor(loss).mean():.4f}, {N_step}],')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f20c11-804b-497f-934b-7eaf79b88de7",
   "metadata": {},
   "source": [
    "# L54"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1622cb54-f3fc-4f89-af1f-72b947d2ed4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# L54 Normal Model T1024 (default: x4 B12 lr24e-4 WD1.2 N12000)\n",
    "# Best model for each number of heads:  2(1):3.0235\n",
    "\n",
    "# local best for H2(1): 3.0235 (best)\n",
    "[ 54, 2, 1, 768, 3072, 288, 492.9, 3.9135, 3.0539, 12000], # 4.5h 44.1G\n",
    "[ 54, 2, 1, 768, 3072, 272, 488.9, 3.9737, 3.0793, 12000], # 4.4h 45.2G\n",
    "[ 54, 2, 1, 768, 3072, 256, 485.0, 3.8368, 3.0539, 12000], # 4.2h 44.1G\n",
    "[ 54, 2, 1, 768, 3072, 240, 481.0, 3.9531, 3.0555, 12000], # 4.1h 43.9G\n",
    "[ 54, 2, 1, 768, 3072, 224, 477.0, 3.7246, 3.0391, 12000], # 4.1h 43.8G\n",
    "[ 54, 2, 1, 768, 3072, 208, 473.0, 3.8210, 3.0392, 12000], # 4.0h\n",
    "[ 54, 2, 1, 768, 3072, 192, 469.0, 4.0432, 3.0997, 12000], # 3.9h\n",
    "[ 54, 2, 1, 768, 3072, 176, 465.1, 3.7698, 3.0509,  12500],# 4.0h\n",
    "[ 54, 2, 1, 768, 3072, 176, 465.1, 3.8650, 3.0315, 12000], # 3.8h\n",
    "[ 54, 2, 1, 768, 3072, 176, 465.1, 4.0168, 3.0867,  11500],# 3.7h 42.8G\n",
    "[ 54, 2, 1, 768, 3072, 160, 461.1, 4.0772, 3.0554, 12000], # 3.8h\n",
    "\n",
    "[ 54, 2, 1, 720, 2880, 288, 439.7, 3.9941, 3.0996, 12000], # 4.4h 43.8G\n",
    "[ 54, 2, 1, 720, 2880, 272, 436.0, 3.7916, 3.0532, 12000], # 4.3h\n",
    "[ 54, 2, 1, 720, 2880, 256, 432.3, 3.6715, 3.0367, 12000], # 4.1h\n",
    "[ 54, 2, 1, 720, 2880, 240, 428.5, 3.8617, 3.0498, 12000], # 4.0h\n",
    "[ 54, 2, 1, 720, 2880, 224, 424.8, 3.9938, 3.0598, 12000], # 3.9h\n",
    "[ 54, 2, 1, 720, 2880, 208, 421.1, 3.7667, 3.0335, 12000], # 3.9h 41.8G\n",
    "[ 54, 2, 1, 720, 2880, 192, 417.3, 3.7706, 3.0359, 12000], # 3.8h\n",
    "[ 54, 2, 1, 720, 2880, 176, 413.6, 3.8543, 3.0525, 12000], # 3.7h\n",
    "[ 54, 2, 1, 720, 2880, 160, 409.9, 3.9192, 3.0879, 12000], # 3.6h\n",
    "\n",
    "[ 54, 2, 1, 672, 2688, 288, 389.5, 3.8007, 3.0407, 12000], # 4.2h\n",
    "[ 54, 2, 1, 672, 2688, 272, 386.0, 3.9811, 3.1086, 12000], # 4.1h\n",
    "[ 54, 2, 1, 672, 2688, 256, 382.5, 3.9061, 3.0840, 12000], # 3.9h 40.8G\n",
    "[ 54, 2, 1, 672, 2688, 240, 379.1, 3.7209, 3.0339, 12000], # 3.8h\n",
    "[ 54, 2, 1, 672, 2688, 224, 375.6, 3.8581, 3.0681, 12000], # 3.7h\n",
    "[ 54, 2, 1, 672, 2688, 208, 372.1, 3.9906, 3.0837, 12000], # 3.7h\n",
    "[ 54, 2, 1, 672, 2688, 192, 368.6, 3.9270, 3.0706, 12000], # 3.6h 39.9G\n",
    "[ 54, 2, 1, 672, 2688, 176, 365.1, 3.9037, 3.0660, 12000], # 3.5h 39.8G\n",
    "[ 54, 2, 1, 672, 2688, 160, 361.6, 3.8247, 3.0669, 12000], # 3.4h\n",
    "[ 54, 2, 1, 672, 2688, 144, 358.2, 3.8754, 3.0618, 12000], # 3.4h\n",
    "\n",
    "[ 54, 2, 1, 624, 2496, 320, 348.7, 3.8319, 3.0547, 12000], # 4.0h\n",
    "[ 54, 2, 1, 624, 2496, 304, 345.5, 3.9134, 3.0737,  12500],# 4.2h\n",
    "[ 54, 2, 1, 624, 2496, 304, 345.5, 3.5867,+3.0307, 12000], # 4.0h\n",
    "[ 54, 2, 1, 624, 2496, 304, 345.5, 3.7026, 3.0408,  11500],# 3.8h\n",
    "[ 54, 2, 1, 624, 2496, 288, 342.3, 4.0260, 3.0893, 12000], # 3.9h 40.9G\n",
    "[ 54, 2, 1, 624, 2496, 272, 339.0, 3.7496, 3.0487, 12000], # 3.9h\n",
    "[ 54, 2, 1, 624, 2496, 256, 335.8, 3.7780, 3.0483, 12000], # 3.6h\n",
    "[ 54, 2, 1, 624, 2496, 240, 332.6, 3.7199, 3.0485, 12000], # 3.6h\n",
    "[ 54, 2, 1, 624, 2496, 224, 329.3, 3.8009, 3.0637, 12000], # 3.5h\n",
    "[ 54, 2, 1, 624, 2496, 208, 326.1, 3.7699, 3.0410, 12000], # 3.4h\n",
    "[ 54, 2, 1, 624, 2496, 192, 322.9, 3.7237, 3.0540,  13000],# 3.6h 38.2G\n",
    "[ 54, 2, 1, 624, 2496, 192, 322.9, 3.6371,+3.0283,  12500],# 3.5h 38.5G\n",
    "[ 54, 2, 1, 624, 2496, 192, 322.9, 3.6222,+3.0289, 12000], # 3.3h\n",
    "[ 54, 2, 1, 624, 2496, 192, 322.9, 3.6408,+3.0268,  11500],# 3.2h\n",
    "[ 54, 2, 1, 624, 2496, 192, 322.9, 4.0426, 3.0715,  11000],# 3.0h 38.3G\n",
    "[ 54, 2, 1, 624, 2496, 176, 319.6, 3.7793, 3.0435, 12000], # 3.3h 38.0G\n",
    "[ 54, 2, 1, 624, 2496, 160, 316.4, 3.6543, 3.0323, 12000], # 3.2h\n",
    "\n",
    "[ 54, 2, 1, 576, 2304, 304, 301.0, 3.5110, 3.0423,  12500],# 4.0h\n",
    "[ 54, 2, 1, 576, 2304, 304, 301.0, 3.5547,+3.0287, 12000], # 3.8h 37.7G\n",
    "[ 54, 2, 1, 576, 2304, 304, 301.0, 3.6331, 3.0397,  11500],# 3.7h 37.3G\n",
    "[ 54, 2, 1, 576, 2304, 288, 298.0, 3.6504, 3.0465, 12000], # 3.7h\n",
    "[ 54, 2, 1, 576, 2304, 272, 295.0, 3.7389, 3.0612, 12000], # 3.7h\n",
    "[ 54, 2, 1, 576, 2304, 256, 292.1, 3.6567, 3.0402, 12000], # 3.4h\n",
    "[ 54, 2, 1, 576, 2304, 240, 289.1, 3.8438, 3.0581, 12000], # 3.4h\n",
    "[ 54, 2, 1, 576, 2304, 224, 286.1, 3.5690, 3.0343, 12000], # 3.3h 37.4G\n",
    "[ 54, 2, 1, 576, 2304, 208, 283.1, 3.7093, 3.0552,  12500],# 3.4h\n",
    "[ 54, 2, 1, 576, 2304, 208, 283.1, 3.6445, 3.0315, 12000], # 3.2h\n",
    "[ 54, 2, 1, 576, 2304, 208, 283.1, 3.5870, 3.0325,  11500],# 3.1h\n",
    "[ 54, 2, 1, 576, 2304, 192, 280.1, 3.7232, 3.0463, 12000], # 3.1h\n",
    "[ 54, 2, 1, 576, 2304, 176, 277.1, 3.6923, 3.0444, 12000], # 3.1h\n",
    "[ 54, 2, 1, 576, 2304, 160, 274.1, 3.7311, 3.0392, 12000], # 3.0h\n",
    "[ 54, 2, 1, 576, 2304, 144, 271.2, 3.5989, 3.0340, 12000], # 2.9h 33.1G\n",
    "\n",
    "[ 54, 2, 1, 528, 2112, 304, 259.5, 3.4847, 3.0389, 12000], # 3.7h 34.0G\n",
    "[ 54, 2, 1, 528, 2112, 288, 256.8, 3.7593, 3.0636, 12000], # 3.6h\n",
    "[ 54, 2, 1, 528, 2112, 272, 254.0, 3.8375, 3.0686, 12000], # 3.5h\n",
    "[ 54, 2, 1, 528, 2112, 256, 251.3, 3.8867, 3.1255,  13500],# 3.7h\n",
    "[ 54, 2, 1, 528, 2112, 256, 251.3, 3.4877, 3.0312,  13000],# 3.5h\n",
    "[ 54, 2, 1, 528, 2112, 256, 251.3, 3.4388,+3.0264,  12500],# 3.4h\n",
    "[+54, 2, 1, 528, 2112, 256, 251.3, 3.4565,+3.0235, 12000], # 3.3h  minGemma-hidden_layers54-att_heads2-kv_heads1-hidden528-intermediate2112-head_dim256-T1024--2025-10-18-14-17\n",
    "[ 54, 2, 1, 528, 2112, 256, 251.3, 3.7716, 3.0613,  11500],# 3.1h\n",
    "[ 54, 2, 1, 528, 2112, 240, 248.6, 3.7483, 3.0466, 12000], # 3.2h\n",
    "[ 54, 2, 1, 528, 2112, 224, 245.8, 3.4895, 3.0345, 12000], # 3.1h\n",
    "[ 54, 2, 1, 528, 2112, 208, 243.1, 3.7546, 3.0606, 12000], # 3.1h\n",
    "[ 54, 2, 1, 528, 2112, 192, 240.3, 3.6489, 3.0493,  12500],# 3.1h\n",
    "[ 54, 2, 1, 528, 2112, 192, 240.3, 3.4537,+3.0281, 12000], # 3.0h 32.7G\n",
    "[ 54, 2, 1, 528, 2112, 192, 240.3, 3.5730, 3.0336,  11500],# 2.9h\n",
    "[ 54, 2, 1, 528, 2112, 176, 237.6, 3.6062, 3.0363, 12000], # 2.9h\n",
    "[ 54, 2, 1, 528, 2112, 160, 234.9, 3.5102, 3.0392, 12000], # 2.9h\n",
    "\n",
    "[ 54, 2, 1, 504, 2016, 336, 245.1, 3.4953, 3.0355, 12000], # 3.7h 35.0G\n",
    "[ 54, 2, 1, 504, 2016, 320, 242.5, 3.5780, 3.0481, 12000], # 3.6h\n",
    "[ 54, 2, 1, 504, 2016, 304, 239.9, 3.4863, 3.0428,  13000],# 3.9h 34.5G\n",
    "[ 54, 2, 1, 504, 2016, 304, 239.9, 3.4641,+3.0299,  12500],# 3.7h\n",
    "[ 54, 2, 1, 504, 2016, 304, 239.9, 3.5239, 3.0310, 12000], # 3.6h\n",
    "[ 54, 2, 1, 504, 2016, 304, 239.9, 3.6517, 3.0459,  11500],# 3.4h\n",
    "[ 54, 2, 1, 504, 2016, 288, 237.3, 3.4262, 3.0325, 12000], # 3.5h\n",
    "[ 54, 2, 1, 504, 2016, 272, 234.6, 3.4765, 3.0326, 12000], # 3.4h 33.7G\n",
    "[ 54, 2, 1, 504, 2016, 256, 232.0, 3.6555, 3.0709, 12000], # 3.2h\n",
    "#\n",
    "# under construction (240)\n",
    "#\n",
    "[ 54, 2, 1, 504, 2016, 224, 226.8, 3.7594, 3.1085, 12000], # 3.0h\n",
    "[ 54, 2, 1, 504, 2016, 208, 224.2, 3.6793, 3.0844,  13000],# 3.2h\n",
    "[ 54, 2, 1, 504, 2016, 208, 224.2, 3.4092, 3.0305,  12500],# 3.1h 31.7G\n",
    "[ 54, 2, 1, 504, 2016, 208, 224.2, 3.4737,+3.0292, 12000], # 3.0h\n",
    "[ 54, 2, 1, 504, 2016, 208, 224.2, 3.5274, 3.0323,  11500],# 2.9h\n",
    "[ 54, 2, 1, 504, 2016, 192, 221.6, 3.5095, 3.0361, 12000], # 2.9h\n",
    "[ 54, 2, 1, 504, 2016, 176, 219.0, 3.4637, 3.0329, 12000], # 2.8h\n",
    "[ 54, 2, 1, 504, 2016, 160, 216.4, 3.5030, 3.0334, 12000], # 2.8h\n",
    "\n",
    "[ 54, 2, 1, 480, 1920, 320, 223.5, 3.4060, 3.0342, 12000], # 3.5h\n",
    "[ 54, 2, 1, 480, 1920, 304, 221.0, 3.4555, 3.0319, 12000], # 3.4h\n",
    "[ 54, 2, 1, 480, 1920, 288, 218.5, 3.5421, 3.0514,  12500],# 3.5h\n",
    "[ 54, 2, 1, 480, 1920, 288, 218.5, 3.4298,+3.0305, 12000], # 3.3h\n",
    "[ 54, 2, 1, 480, 1920, 288, 218.5, 3.6484, 3.0556,  11500],# 3.2h\n",
    "[ 54, 2, 1, 480, 1920, 272, 216.0, 3.4869, 3.0362, 12000], # 3.3h\n",
    "[ 54, 2, 1, 480, 1920, 256, 213.5, 3.4405, 3.0327, 12000], # 3.0h\n",
    "[ 54, 2, 1, 480, 1920, 240, 211.0, 3.5217, 3.0412, 12000], # 3.0h 30.9G\n",
    "[ 54, 2, 1, 480, 1920, 224, 208.5, 3.7157, 3.0585, 12000], # 2.9h\n",
    "#\n",
    "# under construction (208)\n",
    "#\n",
    "[ 54, 2, 1, 480, 1920, 192, 203.6, 3.7243, 3.0672, 12000], # 2.8h 31.1G\n",
    "[ 54, 2, 1, 480, 1920, 176, 201.1, 3.7700, 3.1299, 12000], # 2.7h\n",
    "[ 54, 2, 1, 480, 1920, 160, 198.6, 3.6368, 3.0521, 12000], # 2.6h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1a3d2ab3-bdf0-45f3-9b8f-d8a74cb274b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "147.456\n",
      "L54 att2 kv_heads1 hidden528 intermediate2112 head_dim256 T1024\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='12000' max='12000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [12000/12000 3:18:54, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>3.456500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 54, 2, 1, 528, 2112, 256, 251.3, 3.4565, 3.0235, 12000],\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt; import numpy as np; import time, torch; device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "from transformers import AutoTokenizer, TrainingArguments, DefaultDataCollator, Trainer\n",
    "vocab_size = 50257 # =tokenizer.vocab_size  # FIX!!! # G256128    ### T=256 for minGemma # G8192 for real Gemma\n",
    "num_hidden_layers =  54 # 8 # G28 G18 #blocks\n",
    "num_attention_heads = 2 # 4 # G16 G8\n",
    "num_key_value_heads = 1 # 4 # G16 G1\n",
    "hidden_size = num_attention_heads*264 # 128 # G3072 G2048 # embedding dimension\n",
    "intermediate_size = hidden_size*4 # x4 or x8 # time limiting factor #512 # G24576 G16384  # MLP inner dim\n",
    "head_dim = 256 # 32 # G256 # dim in attention # Doesn't affect time\n",
    "rms_norm_eps = 1e-6 # 1e-6\n",
    "rope_theta = 1000.0 # scale freq is small for S-model. 1000 might work too # G10000.0\n",
    "\n",
    "def apply_rotary_emb(x: torch.Tensor, dim: int) -> torch.Tensor: # seq_len = x.size(1) # N\n",
    "    freqs = 1.0 / (rope_theta ** (torch.arange(0, dim, 2, device=device).float() / dim)) # Dynamically compute frequency cis\n",
    "    t = torch.arange(x.size(1), device=device); freqs = torch.outer(t, freqs).float(); freqs_cis = torch.polar(torch.ones_like(freqs), freqs)  # complex64\n",
    "    x_ = torch.view_as_complex(torch.stack(torch.chunk(x.transpose(1, 2).float(), 2, dim=-1), dim=-1))\n",
    "    x_out = torch.view_as_real(x_ * freqs_cis.unsqueeze(0)).type_as(x)  # Ensure batch dimension is handled\n",
    "    x_out = torch.cat(torch.chunk(x_out, 2, dim=-1), dim=-2)\n",
    "    return x_out.reshape(x_out.shape[0], x_out.shape[1], x_out.shape[2], -1).transpose(1, 2)\n",
    "\n",
    "class RMSNorm(torch.nn.Module): # RMS:4.326552, RMS_no_weight:4.410741 # RMS':4.554899\n",
    "    def __init__(self, dim: int = hidden_size):\n",
    "        super().__init__(); self.weight = torch.nn.Parameter(torch.zeros(dim)) # one weight per feature to be learned\n",
    "    def _norm(self, x): # mean square for each feature (across the last dimension)\n",
    "        return x * torch.rsqrt(x.pow(2).mean(-1, keepdim=True) + rms_norm_eps)\n",
    "    def forward(self, x): # ensure the data type matches the input.\n",
    "        return self._norm(x.float()).type_as(x) * (1 + self.weight)\n",
    "        \n",
    "class GemmaAttention(torch.nn.Module): # MQA = K,V shared by 4Qs\n",
    "    def __init__(self):\n",
    "        super().__init__(); self.qkv_proj = torch.nn.Linear(hidden_size, (num_attention_heads + 2 * num_key_value_heads) * head_dim, bias=False); self.o_proj = torch.nn.Linear(num_attention_heads * head_dim, hidden_size, bias=False) # concatenated attention outputs back to the hidden size.\n",
    "    def forward(self, hidden_states: torch.Tensor,) -> torch.Tensor:  # in=(B, T, hidden_size)\n",
    "        batch_size, input_len, _ = hidden_states.shape\n",
    "        qkv = self.qkv_proj(hidden_states)\n",
    "        xq, xk, xv = qkv.split([num_attention_heads * head_dim, num_key_value_heads * head_dim, num_key_value_heads * head_dim],dim=-1)\n",
    "        xq = xq.view(batch_size, -1, num_attention_heads, head_dim); xk = xk.view(batch_size, -1, num_key_value_heads, head_dim); xv = xv.view(batch_size, -1, num_key_value_heads, head_dim)\n",
    "        xq = apply_rotary_emb(xq, head_dim); xk = apply_rotary_emb(xk, head_dim)\n",
    "        if num_key_value_heads != num_attention_heads:  # Q/KV multiples of K and V to match Q\n",
    "            xk = torch.repeat_interleave(xk, num_attention_heads // num_key_value_heads, dim=2) # [B, T, n_local_heads, head_dim]\n",
    "            xv = torch.repeat_interleave(xv, num_attention_heads // num_key_value_heads, dim=2)\n",
    "        q = xq.transpose(1, 2); k = xk.transpose(1, 2); v = xv.transpose(1, 2) # [batch_size, n_local_heads, input_len, head_dim]\n",
    "        output = torch.nn.functional.scaled_dot_product_attention(q, k, v, attn_mask=None, dropout_p=0, is_causal=True) # B nh T hs        \n",
    "        output = output.transpose(1, 2).contiguous().view(batch_size, input_len, -1)  # [B, T, \"hidden_dim\"]\n",
    "        return self.o_proj(output)\n",
    "\n",
    "class GemmaDecoderLayer(torch.nn.Module): # normalize before and after the attention mechanism\n",
    "    def __init__(self):\n",
    "        super().__init__(); self.self_attn = GemmaAttention(); self.input_layernorm = RMSNorm(); self.post_attention_layernorm = RMSNorm(); self.gate_proj = torch.nn.Linear(hidden_size, intermediate_size); self.up_proj = torch.nn.Linear(hidden_size, intermediate_size); self.down_proj = torch.nn.Linear(intermediate_size, hidden_size) # mlp\n",
    "    def forward(self, hidden_states: torch.Tensor) -> torch.Tensor:  # input_size = (B, T, hidden_size)\n",
    "        residual = hidden_states # Self Attention Block\n",
    "        hidden_states = self.input_layernorm(hidden_states); hidden_states = self.self_attn(hidden_states=hidden_states)\n",
    "        hidden_states = residual + hidden_states\n",
    "        residual = hidden_states # MLP Block\n",
    "        hidden_states = self.post_attention_layernorm(hidden_states); gate = torch.nn.functional.gelu(self.gate_proj(hidden_states)); up = self.up_proj(hidden_states); fuse = gate * up; hidden_states = self.down_proj(fuse) # mlp\n",
    "        return residual + hidden_states\n",
    "\n",
    "class minGemma(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__(); self.embedder = torch.nn.Embedding(vocab_size, hidden_size); self.layers = torch.nn.ModuleList(GemmaDecoderLayer() for _ in range(num_hidden_layers)); self.norm = RMSNorm();\n",
    "    def forward(self, input_token_ids: torch.Tensor) -> torch.Tensor: # (B, T)\n",
    "        hidden_states = self.embedder(input_token_ids[:,:-1]) # (B, T) & (vocab_size, hidden_size) -> (B, T, hidden_size)\n",
    "        hidden_states = hidden_states * (hidden_size**0.5)\n",
    "        for i in range(len(self.layers)):\n",
    "            hidden_states = self.layers[i](hidden_states) # shortened too much???\n",
    "        hidden_states = self.norm(hidden_states) # -> (B, T, hidden_size)        \n",
    "        embedder_weight = self.embedder.weight\n",
    "        logits = torch.matmul(hidden_states, embedder_weight.t()); b,t,v=logits.shape; # (B, T, hidden_size) @ (hidden_size, vocab_size) -> (B, T, vocab_size)\n",
    "        loss = torch.nn.functional.cross_entropy(logits.view(b*t,v), input_token_ids[:,1:].reshape(b*t)) #, weight=None, ignore_index=-100, reduction='mean')\n",
    "        return loss, logits # logits, loss\n",
    "\n",
    "def map_to_array5(ix):\n",
    "    common = torch.stack([torch.from_numpy((train_data[i[0]:i[0]+T+1]).astype(np.int64)) for i in ix]); return {'input_token_ids': common}\n",
    "def map_to_array_Val(ix):\n",
    "    common = torch.stack([torch.from_numpy((val_data[i[0]:i[0]+T+1]).astype(np.int64)) for i in ix]); return {'input_token_ids': common}\n",
    "\n",
    "train_data = np.memmap('train_BabyLM_10M.bin', dtype=np.uint16, mode='r'); val_data = np.memmap('val_BabyLM.bin', dtype=np.uint16, mode='r')\n",
    "T=1024; B=12; N_step=12000; print(T * B * N_step / 1000000) # 0.01 B-tokens being calculated # n_steps=N_step;\n",
    "model = minGemma().to(device); print(f'L{num_hidden_layers}' f' att{num_attention_heads}' f' kv_heads{num_key_value_heads}' f' hidden{hidden_size}' f' intermediate{intermediate_size}' f' head_dim{head_dim}' f' T{T}')\n",
    "\n",
    "# Normal # lr_scheduler_type=\"linear\" can be omitted\n",
    "training_args = TrainingArguments(learning_rate=24.0e-4, weight_decay=1.2, num_train_epochs=1, logging_strategy='epoch', output_dir='./', bf16=True, per_device_train_batch_size=B, per_device_eval_batch_size=B, eval_strategy='no', save_strategy='no', report_to='none', remove_unused_columns=False, dataloader_pin_memory=True) #, dataloader_num_workers=4\n",
    "trainer = Trainer(model=model, args=training_args, train_dataset=torch.utils.data.TensorDataset(torch.randint(len(train_data)-T-1, (B*N_step,))), data_collator=map_to_array5);\n",
    "result = trainer.train(); tloss=result[2][\"train_loss\"] # trainer = Trainer(model=model, args=training_args, eval_dataset=torch.utils.data.TensorDataset(torch.randint(len(val_data)-T-1, (B*400*4,))), data_collator=map_to_array_Val); trainer.can_return_loss = True; loss_current = trainer.evaluate()[\"eval_loss\"]\n",
    "\n",
    "loss = []; model.eval(); B2=16; B2=12; torch.cuda.empty_cache();\n",
    "for k in range(5000): #4000 # std=0.0056 for 1000 with 89sec\n",
    "    val_ind = torch.randint(len(val_data)-T-1, (B2,)); common = (torch.stack([torch.from_numpy((val_data[i:i+T+1]).astype(np.int64)) for i in val_ind]))\n",
    "    loss += [model(common.to('cuda', non_blocking=True))[0].item()]\n",
    "if torch.Tensor(loss).mean() < 3.0256:\n",
    "    torch.save(model.state_dict(), f'{model.__class__.__name__}' f'-hidden_layers{num_hidden_layers}' f'-att_heads{num_attention_heads}' f'-kv_heads{num_key_value_heads}' f'-hidden{hidden_size}' f'-intermediate{intermediate_size}' f'-head_dim{head_dim}' f'-T{T}' f'--{time.strftime(\"%Y-%m-%d-%H-%M\")}.pth')\n",
    "model.train(); del common; print(f'[ {num_hidden_layers}, {num_attention_heads}, {num_key_value_heads}, {hidden_size}, {intermediate_size}, {head_dim}, {sum(p.numel() for p in model.parameters()) / 10**6:.1f}, {tloss:.4f}, {torch.Tensor(loss).mean():.4f}, {N_step}],')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a2e19c1-ccfb-4d2b-b899-e61699a0b966",
   "metadata": {},
   "source": [
    "# L40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba30e86-8764-4b39-b74a-45138c5b6006",
   "metadata": {},
   "outputs": [],
   "source": [
    "# L30 Normal Model T1024 (default: x4 B12 lr24e-4 WD1.2 N12000) w/ Grad_Acc\n",
    "# Best model for each number of heads:  3(1):3.0202, 3(3):3.0275\n",
    "\n",
    "# local best for H3(3): 3.0275  (very bad)\n",
    "[ 40, 3, 3, 768, 3072, 224, 404.6, 3.6622, 3.0464, 28000], # 4.9h 23.1G\n",
    "[ 40, 3, 3, 768, 3072, 208, 398.7, 3.7223, 3.0506, 28000], # 4.9h 22.7G\n",
    "[ 40, 3, 3, 768, 3072, 192, 392.8, 3.6217, 3.0494, 28000], # 4.7h 22.9G\n",
    "[ 40, 3, 3, 768, 3072, 176, 386.9, 3.6279, 3.0431, 28000], # 4.6h\n",
    "[ 40, 3, 3, 768, 3072, 160, 381.0, 3.7817, 3.0528, 28000], # 4.5h\n",
    "\n",
    "[ 40, 3, 3, 720, 2880, 240, 368.3, 3.5501, 3.0399, 28000], # 4.9h 22.6G\n",
    "[ 40, 3, 3, 720, 2880, 224, 362.7, 3.7644, 3.0536, 28000], # 4.8h\n",
    "[ 40, 3, 3, 720, 2880, 208, 357.2, 3.7752, 3.0725, 28000], # 4.7h 22.3G\n",
    "[ 40, 3, 3, 720, 2880, 192, 351.7, 3.6188, 3.0450, 28000], # 4.6h\n",
    "[ 40, 3, 3, 720, 2880, 176, 346.2, 3.5768, 3.0444, 28000], # 4.4h\n",
    "[ 40, 3, 3, 720, 2880, 160, 340.6, 3.6757, 3.0441, 28000], # 4.3h\n",
    "\n",
    "[ 40, 3, 3, 672, 2688, 256, 333.4, 3.5583, 3.0423, 28000], # 4.8h 21.8G\n",
    "[ 40, 3, 3, 672, 2688, 240, 328.2, 3.6621, 3.0502, 28000], # 4.7h\n",
    "[ 40, 3, 3, 672, 2688, 224, 323.1, 3.5269, 3.0375, 28000], # 4.6h 21.6G\n",
    "[ 40, 3, 3, 672, 2688, 224, 323.1, 3.6929, 3.0391,  25000],# 4.1h\n",
    "[ 40, 3, 3, 672, 2688, 224, 323.1, 3.7076,+3.0310,  24000],# 3.9h\n",
    "[ 40, 3, 3, 672, 2688, 224, 323.1, 3.6421,+3.0303,  23000],# 3.7h\n",
    "[ 40, 3, 3, 672, 2688, 224, 323.1, 3.8644, 3.0599,  22000],# 3.6h\n",
    "[ 40, 3, 3, 672, 2688, 208, 317.9, 3.5164, 3.0360,  30000],# 4.8h\n",
    "[ 40, 3, 3, 672, 2688, 208, 317.9, 3.4860,+3.0292,  29000],# 4.7h\n",
    "[ 40, 3, 3, 672, 2688, 208, 317.9, 3.5128,+3.0285, 28000], # 4.5h\n",
    "[ 40, 3, 3, 672, 2688, 208, 317.9, 3.6803, 3.0431,  27000],# 4.3h\n",
    "[ 40, 3, 3, 672, 2688, 208, 317.9, 3.5111,+3.0291,  26000],# 4.1h\n",
    "[ 40, 3, 3, 672, 2688, 208, 317.9, 3.5908, 3.0383,  25000],# 4.0h\n",
    "[ 40, 3, 3, 672, 2688, 208, 317.9, 3.5536,+3.0306,  24000],# 3.8h\n",
    "[ 40, 3, 3, 672, 2688, 208, 317.9, 3.6314, 3.0358,  23000],# 3.7h\n",
    "[ 40, 3, 3, 672, 2688, 192, 312.8, 3.5709, 3.0366, 28000], # 4.3h\n",
    "[ 40, 3, 3, 672, 2688, 192, 312.8, 3.6077, 3.0323,  24000],# 3.7h 20.3G\n",
    "[ 40, 3, 3, 672, 2688, 176, 307.6, 3.4989, 3.0354, 28000], # 4.2h\n",
    "[ 40, 3, 3, 672, 2688, 160, 302.4, 3.5727, 3.0369, 28000], # 4.1h\n",
    "\n",
    "[ 40, 3, 3, 624, 2496, 256, 295.2, 3.4472, 3.0331, 28000], # 4.4h\n",
    "[ 40, 3, 3, 624, 2496, 240, 290.4, 3.4269, 3.0338, 28000], # 4.3h 20.4G\n",
    "[ 40, 3, 3, 624, 2496, 224, 285.6, 3.4844, 3.0366, 28000], # 4.2h\n",
    "[ 40, 3, 3, 624, 2496, 208, 280.8, 3.5273, 3.0360, 28000], # 4.1h\n",
    "[ 40, 3, 3, 624, 2496, 192, 276.0, 3.6416, 3.0441, 28000], # 4.0h\n",
    "[ 40, 3, 3, 624, 2496, 176, 271.3, 3.4121, 3.0334, 28000], # 3.9h\n",
    "[ 40, 3, 3, 624, 2496, 160, 266.5, 3.4713, 3.0393, 28000], # 3.8h\n",
    "\n",
    "[ 40, 3, 3, 576, 2304, 288, 268.1, 3.4723, 3.0320, 28000], # 4.6h 19.5G\n",
    "[ 40, 3, 3, 576, 2304, 288, 268.1, 3.5576, 3.0407,  24000],# 4.0h\n",
    "[ 40, 3, 3, 576, 2304, 272, 263.7, 3.4297, 3.0348,  29000],# 4.7h\n",
    "[ 40, 3, 3, 576, 2304, 272, 263.7, 3.4087,+3.0304, 28000], # 4.6h\n",
    "[ 40, 3, 3, 576, 2304, 272, 263.7, 3.4603,+3.0306,  27000],# 4.4h\n",
    "[ 40, 3, 3, 576, 2304, 272, 263.7, 3.4536, 3.0313,  26000],# 4.2h\n",
    "[ 40, 3, 3, 576, 2304, 272, 263.7, 3.4879,+3.0302,  25000],# 4.1h\n",
    "[ 40, 3, 3, 576, 2304, 272, 263.7, 3.5322, 3.0354,  24000],# 3.9h\n",
    "[ 40, 3, 3, 576, 2304, 256, 259.2, 3.4609, 3.0364,  30000],# 4.5h\n",
    "[ 40, 3, 3, 576, 2304, 256, 259.2, 3.3664, 3.0303,  29000],# 4.3h\n",
    "[+40, 3, 3, 576, 2304, 256, 259.2, 3.4285,+3.0275, 28000], # 4.1h\n",
    "[ 40, 3, 3, 576, 2304, 256, 259.2, 3.5705, 3.0472,  27000],# 4.0h\n",
    "[ 40, 3, 3, 576, 2304, 256, 259.2, 3.4774, 3.0327,  24000],# 3.6h 19.8G\n",
    "[ 40, 3, 3, 576, 2304, 240, 254.8, 3.4498, 3.0343, 28000], # 4.1h 19.4G\n",
    "[ 40, 3, 3, 576, 2304, 240, 254.8, 3.4542, 3.0413,  25000],# 3.6h\n",
    "[ 40, 3, 3, 576, 2304, 240, 254.8, 3.5154,+3.0303,  24000],# 3.5h\n",
    "[ 40, 3, 3, 576, 2304, 240, 254.8, 3.5026, 3.0334,  23000],# 3.3h\n",
    "[ 40, 3, 3, 576, 2304, 224, 250.4, 3.4172, 3.0339, 28000], # 4.0h\n",
    "[ 40, 3, 3, 576, 2304, 224, 250.4, 3.6027, 3.0485,  26000],# 3.7h\n",
    "[ 40, 3, 3, 576, 2304, 224, 250.4, 3.4689, 3.0312,  25000],# 3.6h\n",
    "[ 40, 3, 3, 576, 2304, 224, 250.4, 3.5048, 3.0309,  24000],# 3.4h\n",
    "[ 40, 3, 3, 576, 2304, 224, 250.4, 3.5291, 3.0363,  23000],# 3.3h\n",
    "[ 40, 3, 3, 576, 2304, 208, 246.0, 3.4025, 3.0354, 28000], # 3.9h\n",
    "[ 40, 3, 3, 576, 2304, 208, 246.0, 3.6424, 3.0444,  24000],# 3.3h 19.1G\n",
    "[ 40, 3, 3, 576, 2304, 192, 241.5, 3.4531, 3.0338, 28000], # 3.7h\n",
    "[ 40, 3, 3, 576, 2304, 176, 237.1, 3.5138, 3.0374, 28000], # 3.7h\n",
    "[ 40, 3, 3, 576, 2304, 160, 232.7, 3.5345, 3.0430, 28000], # 3.6h 18.2G\n",
    "\n",
    "[ 40, 3, 3, 528, 2112, 288, 233.6, 3.4125, 3.0425, 28000], # 4.5h\n",
    "[ 40, 3, 3, 528, 2112, 272, 229.5, 3.4078, 3.0389,  29000],# 4.6h\n",
    "[ 40, 3, 3, 528, 2112, 272, 229.5, 3.3723, 3.0303, 28000], # 4.4h\n",
    "[ 40, 3, 3, 528, 2112, 272, 229.5, 3.3742, 3.0343,  27000],# 4.3h 18.7G\n",
    "[ 40, 3, 3, 528, 2112, 272, 229.5, 3.4207, 3.0342,  24000],# 3.8h 18.8G\n",
    "[ 40, 3, 3, 528, 2112, 256, 225.5, 3.3968, 3.0324,  28000],# 4.0h 17.5G\n",
    "[ 40, 3, 3, 528, 2112, 256, 225.5, 3.4147, 3.0334,  24000],# 3.5h\n",
    "[ 40, 3, 3, 528, 2112, 240, 221.4, 3.5308, 3.0536,  29000],# 4.1h\n",
    "[ 40, 3, 3, 528, 2112, 240, 221.4, 3.3593, 3.0315, 28000], # 4.0h\n",
    "[ 40, 3, 3, 528, 2112, 240, 221.4, 3.4081, 3.0339,  27000],# 3.8h\n",
    "[ 40, 3, 3, 528, 2112, 240, 221.4, 3.6428, 3.0603,  24000],# 3.4h\n",
    "[ 40, 3, 3, 528, 2112, 224, 217.4, 3.3515, 3.0352, 28000], # 3.9h\n",
    "[ 40, 3, 3, 528, 2112, 208, 213.3, 3.4888, 3.0464, 28000], # 3.8h\n",
    "[ 40, 3, 3, 528, 2112, 192, 209.2, 3.4107, 3.0361, 28000], # 3.6h\n",
    "[ 40, 3, 3, 528, 2112, 176, 205.2, 3.3712, 3.0375, 28000], # 3.5h\n",
    "[ 40, 3, 3, 528, 2112, 160, 201.1, 3.3816, 3.0369, 28000], # 3.4h 16.5G\n",
    "\n",
    "\n",
    "# local best for H3(1): 3.0202\n",
    "[ 40, 3, 1, 720, 2880, 288, 351.7, 3.6055, 3.0414, 28000], # 5.2h 22.1G\n",
    "[ 40, 3, 1, 720, 2880, 288, 351.7, 3.6126, 3.0435,  27000],# 5.0h 22.2G\n",
    "[ 40, 3, 1, 720, 2880, 288, 351.7, 3.6945, 3.0411,  26000],# 4.8h\n",
    "[ 40, 3, 1, 720, 2880, 288, 351.7, 3.6382, 3.0468,  25000],# 4.7h\n",
    "[ 40, 3, 1, 720, 2880, 288, 351.7, 3.7470, 3.0474,  24000],# 4.4h\n",
    "[ 40, 3, 1, 720, 2880, 272, 348.0, 3.5207, 3.0409, 28000], # 5.1h\n",
    "[ 40, 3, 1, 720, 2880, 272, 348.0, 3.6275,+3.0298,  27000],# 4.9h\n",
    "[ 40, 3, 1, 720, 2880, 272, 348.0, 3.6615, 3.0399,  26000],# 4.7h\n",
    "[ 40, 3, 1, 720, 2880, 272, 348.0, 3.7206, 3.0526,  25000],# 4.5h\n",
    "[ 40, 3, 1, 720, 2880, 272, 348.0, 3.6723, 3.0475,  24000],# 4.3h 22.5G\n",
    "[ 40, 3, 1, 720, 2880, 256, 344.3, 3.5690, 3.0337, 28000], # 4.8h\n",
    "[ 40, 3, 1, 720, 2880, 256, 344.3, 3.6540, 3.0458,  27000],# 4.6h\n",
    "[ 40, 3, 1, 720, 2880, 256, 344.3, 3.5945, 3.0311,  26000],# 4.4h\n",
    "[ 40, 3, 1, 720, 2880, 256, 344.3, 3.5966,+3.0275,  25000],# 4.2h\n",
    "[ 40, 3, 1, 720, 2880, 256, 344.3, 3.8645, 3.0652,  24000],# 4.1h\n",
    "[ 40, 3, 1, 720, 2880, 240, 340.6, 3.5827, 3.0373, 28000], # 4.7h\n",
    "[ 40, 3, 1, 720, 2880, 240, 340.6, 3.5389, 3.0332,  27000],# 4.5h\n",
    "[ 40, 3, 1, 720, 2880, 240, 340.6, 3.6390, 3.0354,  26000],# 4.4h\n",
    "[ 40, 3, 1, 720, 2880, 240, 340.6, 3.6153, 3.0309,  25000],# 4.2h\n",
    "[ 40, 3, 1, 720, 2880, 240, 340.6, 3.6748,+3.0292,  24000],# 4.0h\n",
    "[ 40, 3, 1, 720, 2880, 240, 340.6, 3.6457, 3.0418,  23000],# 3.8h\n",
    "[ 40, 3, 1, 720, 2880, 224, 336.9, 3.4543, 3.0348,  29000],# 4.7h 21.1G\n",
    "[ 40, 3, 1, 720, 2880, 224, 336.9, 3.5145,+3.0274, 28000], # 4.6h\n",
    "[ 40, 3, 1, 720, 2880, 224, 336.9, 3.6384,+3.0282,  27000],# 4.4h\n",
    "[ 40, 3, 1, 720, 2880, 224, 336.9, 3.6306, 3.0337,  26000],# 4.2h\n",
    "[ 40, 3, 1, 720, 2880, 224, 336.9, 3.6958, 3.0372,  25000],# 4.1h\n",
    "[ 40, 3, 1, 720, 2880, 224, 336.9, 3.6793, 3.0385,  24000],# 3.9h\n",
    "[ 40, 3, 1, 720, 2880, 208, 333.3, 3.5606, 3.0339, 28000], # 4.5h\n",
    "[ 40, 3, 1, 720, 2880, 208, 333.3, 3.6633, 3.0416,  27000],# 4.4h 21.6G\n",
    "[ 40, 3, 1, 720, 2880, 208, 333.3, 3.6726,+3.0297,  26000],# 4.2h\n",
    "[ 40, 3, 1, 720, 2880, 208, 333.3, 3.6652,+3.0292,  25000],# 4.0h\n",
    "[ 40, 3, 1, 720, 2880, 208, 333.3, 3.6401, 3.0302,  24000],# 3.9h\n",
    "[ 40, 3, 1, 720, 2880, 208, 333.3, 3.6916, 3.0338,  23000],# 3.7h\n",
    "[ 40, 3, 1, 720, 2880, 192, 329.6, 3.5544, 3.0391,  30000],# 4.7h\n",
    "[ 40, 3, 1, 720, 2880, 192, 329.6, 3.4819,+3.0233,  29000],# 4.5h 21.7G\n",
    "[ 40, 3, 1, 720, 2880, 192, 329.6, 3.6141,+3.0292, 28000], # 4.4h\n",
    "[ 40, 3, 1, 720, 2880, 192, 329.6, 3.5636, 3.0410,  27000],# 4.2h 21.9G\n",
    "[ 40, 3, 1, 720, 2880, 192, 329.6, 3.5269,+3.0285,  26000],# 4.1h\n",
    "[ 40, 3, 1, 720, 2880, 192, 329.6, 3.6598, 3.0335,  25000],# 3.9h 21.5G\n",
    "[ 40, 3, 1, 720, 2880, 192, 329.6, 3.6924, 3.0329,  24000],# 3.7h\n",
    "[ 40, 3, 1, 720, 2880, 176, 325.9, 3.7237, 3.0510, 28000], # 4.3h\n",
    "[ 40, 3, 1, 720, 2880, 176, 325.9, 3.6255, 3.0396,  27000],# 4.2h\n",
    "[ 40, 3, 1, 720, 2880, 176, 325.9, 3.5727, 3.0305,  26000],# 4.0h\n",
    "[ 40, 3, 1, 720, 2880, 176, 325.9, 3.6048,+3.0216,  25000],# 3.9h\n",
    "[ 40, 3, 1, 720, 2880, 176, 325.9, 3.5317,+3.0229,  24000],# 3.7h\n",
    "[ 40, 3, 1, 720, 2880, 176, 325.9, 3.8654, 3.0529,  23000],# 3.5h\n",
    "[ 40, 3, 1, 720, 2880, 160, 322.2, 3.7237, 3.0628, 28000], # 4.2h\n",
    "[ 40, 3, 1, 720, 2880, 160, 322.2, 3.6198, 3.0385,  27000],# 4.0h\n",
    "[ 40, 3, 1, 720, 2880, 160, 322.2, 3.6775, 3.0354,  26000],# 3.9h\n",
    "[ 40, 3, 1, 720, 2880, 160, 322.2, 3.5815, 3.0338,  25000],# 3.7h 21.6G\n",
    "[ 40, 3, 1, 720, 2880, 160, 322.2, 3.8103, 3.0442,  24000],# 3.6h\n",
    "\n",
    "[ 40, 3, 1, 672, 2688, 288, 312.8, 3.5216, 3.0348, 28000], # 5.0h 20.3G\n",
    "[ 40, 3, 1, 672, 2688, 288, 312.8, 3.5444, 3.0399,  27000],# 4.8h\n",
    "[ 40, 3, 1, 672, 2688, 288, 312.8, 3.7984, 3.0708,  26000],# 4.6h 21.2G\n",
    "[ 40, 3, 1, 672, 2688, 288, 312.8, 3.5682,+3.0263,  25000],# 4.4h\n",
    "[ 40, 3, 1, 672, 2688, 288, 312.8, 3.6529, 3.0408,  24000],# 4.3h\n",
    "[ 40, 3, 1, 672, 2688, 272, 309.3, 3.6024, 3.0424, 28000], # 4.9h\n",
    "[ 40, 3, 1, 672, 2688, 272, 309.3, 3.4868, 3.0335,  27000],# 4.7h\n",
    "[ 40, 3, 1, 672, 2688, 272, 309.3, 3.7269, 3.0542,  26000],# 4.5h\n",
    "[ 40, 3, 1, 672, 2688, 272, 309.3, 3.5697, 3.0332,  25000],# 4.4h\n",
    "[ 40, 3, 1, 672, 2688, 272, 309.3, 3.7653, 3.0476,  24000],# 4.2h 21.1G\n",
    "[ 40, 3, 1, 672, 2688, 256, 305.9, 3.3908, 3.0352,  31000],# 5.1h\n",
    "[ 40, 3, 1, 672, 2688, 256, 305.9, 3.4539, 3.0302,  30000],# 4.9h 21.0G\n",
    "[ 40, 3, 1, 672, 2688, 256, 305.9, 3.5882, 3.0338,  29000],# 4.7h\n",
    "[ 40, 3, 1, 672, 2688, 256, 305.9, 3.5537,+3.0275, 28000], # 4.6h\n",
    "[ 40, 3, 1, 672, 2688, 256, 305.9, 3.6548, 3.0519,  27000],# 4.4h\n",
    "[ 40, 3, 1, 672, 2688, 256, 305.9, 3.5263,+3.0260,  26000],# 4.2h\n",
    "[ 40, 3, 1, 672, 2688, 256, 305.9, 3.5915,+3.0266,  25000],# 4.1h 21.1G\n",
    "[ 40, 3, 1, 672, 2688, 256, 305.9, 3.6150, 3.0311,  24000],# 3.9h 20.1G\n",
    "[ 40, 3, 1, 672, 2688, 240, 302.4, 3.6426, 3.0370,  30000],# 4.8h\n",
    "[ 40, 3, 1, 672, 2688, 240, 302.4, 3.5047,+3.0297,  29000],# 4.7h\n",
    "[ 40, 3, 1, 672, 2688, 240, 302.4, 3.5073,+3.0293, 28000], # 4.5h\n",
    "[ 40, 3, 1, 672, 2688, 240, 302.4, 3.5459,+3.0292,  27000],# 4.3h\n",
    "[ 40, 3, 1, 672, 2688, 240, 302.4, 3.4990,+3.0267,  26000],# 4.2h\n",
    "[ 40, 3, 1, 672, 2688, 240, 302.4, 3.6074, 3.0409,  25000],# 4.0h\n",
    "[ 40, 3, 1, 672, 2688, 240, 302.4, 3.5801,+3.0273,  24000],# 3.8h\n",
    "[ 40, 3, 1, 672, 2688, 240, 302.4, 3.5946, 3.0325,  23000],# 3.7h\n",
    "[ 40, 3, 1, 672, 2688, 240, 302.4, 3.6442, 3.0335,  22000],# 3.5h\n",
    "[ 40, 3, 1, 672, 2688, 224, 299.0, 3.5636, 3.0406,  30000],# 4.7h 19.6G\n",
    "[ 40, 3, 1, 672, 2688, 224, 299.0, 3.5037,+3.0283,  29000],# 4.5h\n",
    "[ 40, 3, 1, 672, 2688, 224, 299.0, 3.5357,+3.0204,+28000], # 4.4h  minGemma-hidden_layers40-att_heads3-kv_heads1-hidden672-intermediate2688-head_dim224-T1024--2025-08-26-07-32.pth\n",
    "[ 40, 3, 1, 672, 2688, 224, 299.0, 3.5234, 3.0282,  27000],# 4.2h\n",
    "[ 40, 3, 1, 672, 2688, 224, 299.0, 3.5190, 3.0355,  26000],# 4.1h\n",
    "[ 40, 3, 1, 672, 2688, 224, 299.0, 3.6187, 3.0303,  25000],# 3.9h\n",
    "[ 40, 3, 1, 672, 2688, 224, 299.0, 3.6084, 3.0355,  24000],# 3.7h\n",
    "[ 40, 3, 1, 672, 2688, 224, 299.0, 3.6817,+3.0296,  23000],# 3.6h\n",
    "[ 40, 3, 1, 672, 2688, 224, 299.0, 3.7586, 3.0395,  22000],# 3.4h\n",
    "[ 40, 3, 1, 672, 2688, 208, 295.6, 3.6345, 3.0509, 28000], # 4.3h\n",
    "[ 40, 3, 1, 672, 2688, 208, 295.6, 3.6148, 3.0447,  27000],# 4.1h\n",
    "[ 40, 3, 1, 672, 2688, 208, 295.6, 3.5273,+3.0269,  26000],# 4.0h\n",
    "[ 40, 3, 1, 672, 2688, 208, 295.6, 3.5794, 3.0334,  25000],# 3.8h\n",
    "[ 40, 3, 1, 672, 2688, 208, 295.6, 3.6870,+3.0279,  24000],# 3.7h\n",
    "[ 40, 3, 1, 672, 2688, 208, 295.6, 3.6072,+3.0295,  23000],# 3.5h\n",
    "[ 40, 3, 1, 672, 2688, 208, 295.6, 3.6451,+3.0280,  22000],# 3.4h\n",
    "[ 40, 3, 1, 672, 2688, 208, 295.6, 3.8174, 3.0368,  21000],# 3.2h\n",
    "[ 40, 3, 1, 672, 2688, 192, 292.1, 3.6064, 3.0431, 28000], # 4.2h\n",
    "[ 40, 3, 1, 672, 2688, 192, 292.1, 3.5968, 3.0456,  27000],# 4.0h\n",
    "[ 40, 3, 1, 672, 2688, 192, 292.1, 3.5173,+3.0215,  26000],# 3.9h\n",
    "[ 40, 3, 1, 672, 2688, 192, 292.1, 3.6061,+3.0247,  25000],# 3.7h\n",
    "[ 40, 3, 1, 672, 2688, 192, 292.1, 3.5837, 3.0372,  24000],# 3.6h\n",
    "[ 40, 3, 1, 672, 2688, 176, 288.7, 3.5926, 3.0347,  28000],# 4.1h 19.5G\n",
    "[ 40, 3, 1, 672, 2688, 176, 288.7, 3.5957, 3.0350,  27000],# 3.9h 19.5G\n",
    "[ 40, 3, 1, 672, 2688, 176, 288.7, 3.6770, 3.0376,  26000],# 3.8h\n",
    "[ 40, 3, 1, 672, 2688, 176, 288.7, 3.5296,+3.0241,  25000],# 3.7h\n",
    "[ 40, 3, 1, 672, 2688, 176, 288.7, 3.5949, 3.0332,  24000],# 3.5h\n",
    "[ 40, 3, 1, 672, 2688, 160, 285.2, 3.6971, 3.0582, 28000], # 4.0h\n",
    "[ 40, 3, 1, 672, 2688, 160, 285.2, 3.6165, 3.0394,  27000],# 3.8h\n",
    "[ 40, 3, 1, 672, 2688, 160, 285.2, 3.5633,+3.0292,  26000],# 3.7h\n",
    "[ 40, 3, 1, 672, 2688, 160, 285.2, 3.7500, 3.0761,  25000],# 3.6h\n",
    "[ 40, 3, 1, 672, 2688, 160, 285.2, 3.6840, 3.0353,  24000],# 3.4h\n",
    "\n",
    "[ 40, 3, 1, 624, 2496, 304, 279.2, 3.4423, 3.0373, 28000], # 4.7h\n",
    "[ 40, 3, 1, 624, 2496, 304, 279.2, 3.4837, 3.0367,  27000],# 4.5h\n",
    "[ 40, 3, 1, 624, 2496, 304, 279.2, 3.6782, 3.0592,  26000],# 4.4h 19.7G\n",
    "[ 40, 3, 1, 624, 2496, 304, 279.2, 3.6114, 3.0340,  25000],# 4.2h 19.7G\n",
    "[ 40, 3, 1, 624, 2496, 304, 279.2, 3.6104, 3.0435,  24000],# 4.0h 19.6G\n",
    "#\n",
    "# under construction\n",
    "#\n",
    "[ 40, 3, 1, 624, 2496, 272, 272.8, 3.4195, 3.0359,  30000],# 4.9h 19.4G\n",
    "[ 40, 3, 1, 624, 2496, 272, 272.8, 3.4282,+3.0302,  29000],# 4.7h 19.2G\n",
    "[ 40, 3, 1, 624, 2496, 272, 272.8, 3.4178,+3.0298, 28000], # 4.5h\n",
    "[ 40, 3, 1, 624, 2496, 272, 272.8, 3.4846,+3.0303,  27000],# 4.4h\n",
    "[ 40, 3, 1, 624, 2496, 272, 272.8, 3.6141, 3.0557,  26000],# 4.2h\n",
    "[ 40, 3, 1, 624, 2496, 272, 272.8, 3.4941,+3.0300,  25000],# 4.0h\n",
    "[ 40, 3, 1, 624, 2496, 272, 272.8, 3.7764, 3.0634,  24000],# 3.9h\n",
    "[ 40, 3, 1, 624, 2496, 256, 269.7, 3.4882, 3.0331, 28000], # 4.2h 19.3G\n",
    "[ 40, 3, 1, 624, 2496, 256, 269.7, 3.5662, 3.0355,  27000],# 4.0h\n",
    "[ 40, 3, 1, 624, 2496, 256, 269.7, 3.8038, 3.0715,  26000],# 3.9h\n",
    "[ 40, 3, 1, 624, 2496, 256, 269.7, 3.6610, 3.0428,  25000],# 3.7h\n",
    "[ 40, 3, 1, 624, 2496, 256, 269.7, 3.6892, 3.0402,  24000],# 3.6h\n",
    "[ 40, 3, 1, 624, 2496, 240, 266.5, 3.6042, 3.0603,  30000],# 4.4h\n",
    "[ 40, 3, 1, 624, 2496, 240, 266.5, 3.3997,+3.0291,  29000],# 4.3h\n",
    "[ 40, 3, 1, 624, 2496, 240, 266.5, 3.4082,+3.0286, 28000], # 4.1h\n",
    "[ 40, 3, 1, 624, 2496, 240, 266.5, 3.5950, 3.0457,  27000],# 4.0h 19.3G\n",
    "[ 40, 3, 1, 624, 2496, 240, 266.5, 3.4478,+3.0290,  26000],# 3.8h\n",
    "[ 40, 3, 1, 624, 2496, 240, 266.5, 3.5986, 3.0312,  25000],# 3.7h\n",
    "[ 40, 3, 1, 624, 2496, 240, 266.5, 3.5056, 3.0337,  24000],# 3.5h\n",
    "[ 40, 3, 1, 624, 2496, 224, 263.3, 3.3968, 3.0338, 28000], # 4.1h\n",
    "[ 40, 3, 1, 624, 2496, 224, 263.3, 3.4500,+3.0227,  27000],# 3.9h\n",
    "[ 40, 3, 1, 624, 2496, 224, 263.3, 3.5348, 3.0306,  26000],# 3.8h\n",
    "[ 40, 3, 1, 624, 2496, 224, 263.3, 3.5119,+3.0221,  25000],# 3.6h\n",
    "[ 40, 3, 1, 624, 2496, 224, 263.3, 3.6105,+3.0296,  24000],# 3.5h\n",
    "[ 40, 3, 1, 624, 2496, 224, 263.3, 3.5209,+3.0277,  23000],# 3.3h\n",
    "[ 40, 3, 1, 624, 2496, 224, 263.3, 3.6434,+3.0280,  22000],# 3.2h\n",
    "[ 40, 3, 1, 624, 2496, 224, 263.3, 3.6155, 3.0336,  21000],# 3.0h\n",
    "#\n",
    "# under construction\n",
    "#\n",
    "[ 40, 3, 1, 624, 2496, 176, 253.7, 3.5774, 3.0403,  29000],# 3.9h\n",
    "[ 40, 3, 1, 624, 2496, 176, 253.7, 3.4724,+3.0299, 28000], # 3.8h 18.7G\n",
    "[ 40, 3, 1, 624, 2496, 176, 253.7, 3.5489, 3.0325,  27000],# 3.6h 18.7G\n",
    "[ 40, 3, 1, 624, 2496, 176, 253.7, 3.5281,+3.0275,  26000],# 3.5h\n",
    "[ 40, 3, 1, 624, 2496, 176, 253.7, 3.6777, 3.0538,  25000],# 3.3h\n",
    "[ 40, 3, 1, 624, 2496, 176, 253.7, 3.5651, 3.0396,  24000],# 3.2h\n",
    "[ 40, 3, 1, 624, 2496, 160, 250.5, 3.4979, 3.0379, 28000], # 3.6h\n",
    "[ 40, 3, 1, 624, 2496, 160, 250.5, 3.5082, 3.0335,  27000],# 3.5h 18.7G\n",
    "[ 40, 3, 1, 624, 2496, 160, 250.5, 3.5288,+3.0271,  26000],# 3.4h\n",
    "[ 40, 3, 1, 624, 2496, 160, 250.5, 3.4901,+3.0293,  25000],# 3.3h\n",
    "[ 40, 3, 1, 624, 2496, 160, 250.5, 3.5872, 3.0300,  24000],# 3.1h\n",
    "[ 40, 3, 1, 624, 2496, 160, 250.5, 3.5708, 3.0306,  23000],# 3.0h\n",
    "[ 40, 3, 1, 624, 2496, 160, 250.5, 3.6322, 3.0339,  22000],# 2.9h\n",
    "\n",
    "[ 40, 3, 1, 576, 2304, 288, 241.5, 3.3774, 3.0326,  29000],# 4.5h\n",
    "[ 40, 3, 1, 576, 2304, 288, 241.5, 3.3566, 3.0307, 28000], # 4.4h\n",
    "[ 40, 3, 1, 576, 2304, 288, 241.5, 3.4734,+3.0243,  27000],# 4.2h\n",
    "[ 40, 3, 1, 576, 2304, 288, 241.5, 3.5112,+3.0219,  26000],# 4.1h\n",
    "[ 40, 3, 1, 576, 2304, 288, 241.5, 3.4380,+3.0233,  25000],# 3.9h 18.8G\n",
    "[ 40, 3, 1, 576, 2304, 288, 241.5, 3.4672,+3.0243,  24000],# 3.8h\n",
    "[ 40, 3, 1, 576, 2304, 288, 241.5, 3.6560, 3.0325,  23000],# 3.6h\n",
    "[ 40, 3, 1, 576, 2304, 272, 238.6, 3.3363, 3.0383,  32000],# 4.9h\n",
    "[ 40, 3, 1, 576, 2304, 272, 238.6, 3.5156,+3.0235,  31000],# 4.8h\n",
    "[ 40, 3, 1, 576, 2304, 272, 238.6, 3.3758,+3.0249,  30000],# 4.6h\n",
    "[ 40, 3, 1, 576, 2304, 272, 238.6, 3.3691,+3.0230,  29000],# 4.5h\n",
    "[ 40, 3, 1, 576, 2304, 272, 238.6, 3.3833,+3.0250, 28000], # 4.3h\n",
    "[ 40, 3, 1, 576, 2304, 272, 238.6, 3.5617, 3.0448,  27000],# 4.2h\n",
    "[ 40, 3, 1, 576, 2304, 272, 238.6, 3.4581, 3.0324,  26000],# 4.0h\n",
    "[ 40, 3, 1, 576, 2304, 272, 238.6, 3.5289,+3.0247,  25000],# 3.8h\n",
    "[ 40, 3, 1, 576, 2304, 272, 238.6, 3.4824,+3.0293,  24000],# 3.7h 19.0G\n",
    "[ 40, 3, 1, 576, 2304, 272, 238.6, 3.5085, 3.0302,  23000],# 3.5h\n",
    "[ 40, 3, 1, 576, 2304, 272, 238.6, 3.5304, 3.0321,  22000],# 3.4h\n",
    "[ 40, 3, 1, 576, 2304, 256, 235.6, 3.4551, 3.0344,  29000],# 4.1h\n",
    "[ 40, 3, 1, 576, 2304, 256, 235.6, 3.4140,+3.0239, 28000], # 4.0h\n",
    "[ 40, 3, 1, 576, 2304, 256, 235.6, 3.5662, 3.0533,  27000],# 3.8h\n",
    "[ 40, 3, 1, 576, 2304, 256, 235.6, 3.4371,+3.0287,  26000],# 3.7h\n",
    "[ 40, 3, 1, 576, 2304, 256, 235.6, 3.4940, 3.0323,  25000],# 3.5h\n",
    "[ 40, 3, 1, 576, 2304, 256, 235.6, 3.5788, 3.0397,  24000],# 3.4h\n",
    "[ 40, 3, 1, 576, 2304, 240, 232.7, 3.3982, 3.0396,  29000],# 4.1h\n",
    "[ 40, 3, 1, 576, 2304, 240, 232.7, 3.4091,+3.0287, 28000], # 3.9h\n",
    "[ 40, 3, 1, 576, 2304, 240, 232.7, 3.4629, 3.0338,  27000],# 3.8h 18.5G\n",
    "[ 40, 3, 1, 576, 2304, 240, 232.7, 3.4100,+3.0229,  26000],# 3.6h\n",
    "[ 40, 3, 1, 576, 2304, 240, 232.7, 3.4415,+3.0211,  25000],# 3.5h\n",
    "[ 40, 3, 1, 576, 2304, 240, 232.7, 3.5143, 3.0330,  24000],# 3.4h\n",
    "[ 40, 3, 1, 576, 2304, 224, 229.7, 3.4336, 3.0341, 28000], # 3.8h\n",
    "[ 40, 3, 1, 576, 2304, 224, 229.7, 3.4741,+3.0309,  27000],# 3.7h\n",
    "[ 40, 3, 1, 576, 2304, 224, 229.7, 3.6089, 3.0841,  26000],# 3.6h\n",
    "[ 40, 3, 1, 576, 2304, 224, 229.7, 3.4595, 3.0328,  25000],# 3.4h\n",
    "[ 40, 3, 1, 576, 2304, 224, 229.7, 3.5228,+3.0247,  24000],# 3.3h\n",
    "[ 40, 3, 1, 576, 2304, 224, 229.7, 3.6610, 3.0453,  23000],# 3.1h\n",
    "[ 40, 3, 1, 576, 2304, 208, 226.8, 3.3105, 3.0423,  32000],# 4.3h\n",
    "[ 40, 3, 1, 576, 2304, 208, 226.8, 3.3423,+3.0278,  31000],# 4.2h\n",
    "[ 40, 3, 1, 576, 2304, 208, 226.8, 3.4931, 3.0310,  30000],# 4.0h 18.6G\n",
    "[ 40, 3, 1, 576, 2304, 208, 226.8, 3.3541,+3.0275,  29000],# 3.9h\n",
    "[ 40, 3, 1, 576, 2304, 208, 226.8, 3.3781,+3.0242, 28000], # 3.7h\n",
    "[ 40, 3, 1, 576, 2304, 208, 226.8, 3.4678,+3.0265,  27000],# 3.6h\n",
    "[ 40, 3, 1, 576, 2304, 208, 226.8, 3.5000,+3.0265,  26000],# 3.5h\n",
    "[ 40, 3, 1, 576, 2304, 208, 226.8, 3.4289, 3.0305,  25000],# 3.3h\n",
    "[ 40, 3, 1, 576, 2304, 208, 226.8, 3.4199,+3.0245,  24000],# 3.2h\n",
    "[ 40, 3, 1, 576, 2304, 208, 226.8, 3.5086, 3.0302,  23000],# 3.1h\n",
    "[ 40, 3, 1, 576, 2304, 208, 226.8, 3.5277,+3.0287,  22000],# 3.0h 18.5G\n",
    "[ 40, 3, 1, 576, 2304, 208, 226.8, 3.6290,+3.0309,  21000],# 2.9h\n",
    "[ 40, 3, 1, 576, 2304, 208, 226.8, 3.6701, 3.0406,  20000],# 2.7h\n",
    "[ 40, 3, 1, 576, 2304, 192, 223.8, 3.5421, 3.0508, 28000], # 3.6h\n",
    "[ 40, 3, 1, 576, 2304, 192, 223.8, 3.4347,+3.0263,  27000],# 3.5h\n",
    "[ 40, 3, 1, 576, 2304, 192, 223.8, 3.6894, 3.0793,  26000],# 3.3h\n",
    "[ 40, 3, 1, 576, 2304, 192, 223.8, 3.4459,+3.0266,  25000],# 3.2h\n",
    "[ 40, 3, 1, 576, 2304, 192, 223.8, 3.4649, 3.0364,  24000],# 3.1h\n",
    "[ 40, 3, 1, 576, 2304, 176, 220.9, 3.5255, 3.0545,  32000],# 4.1h\n",
    "[ 40, 3, 1, 576, 2304, 176, 220.9, 3.4806, 3.0463,  31000],# 3.9h\n",
    "[ 40, 3, 1, 576, 2304, 176, 220.9, 3.4181,+3.0295,  30000],# 3.8h\n",
    "[ 40, 3, 1, 576, 2304, 176, 220.9, 3.3751, 3.0336,  29000],# 3.7h 17.7G\n",
    "[ 40, 3, 1, 576, 2304, 176, 220.9, 3.5273,+3.0295, 28000], # 2.2h 17.8G\n",
    "[ 40, 3, 1, 576, 2304, 176, 220.9, 3.4933, 3.0342,  27000],# 3.4h\n",
    "[ 40, 3, 1, 576, 2304, 176, 220.9, 3.5213, 3.0346,  26000],# 3.3h\n",
    "[ 40, 3, 1, 576, 2304, 176, 220.9, 3.4245,+3.0265,  25000],# 3.2h\n",
    "[ 40, 3, 1, 576, 2304, 176, 220.9, 3.4639, 3.0312,  24000],# 3.0h\n",
    "[ 40, 3, 1, 576, 2304, 176, 220.9, 3.5055, 3.0320,  23000],# 2.9h\n",
    "[ 40, 3, 1, 576, 2304, 160, 217.9, 3.3810, 3.0372,  29000],# 3.6h\n",
    "[ 40, 3, 1, 576, 2304, 160, 217.9, 3.4614,+3.0293, 28000], # 3.4h 17.6G\n",
    "[ 40, 3, 1, 576, 2304, 160, 217.9, 3.4191, 3.0364,  27000],# 3.3h\n",
    "[ 40, 3, 1, 576, 2304, 160, 217.9, 3.5163, 3.0392,  26000],# 3.2h\n",
    "[ 40, 3, 1, 576, 2304, 160, 217.9, 3.6207, 3.0641,  25000],# 3.1h\n",
    "[ 40, 3, 1, 576, 2304, 160, 217.9, 3.4338, 3.0371,  24000],# 2.9h 17.7G\n",
    "\n",
    "[ 40, 3, 1, 528, 2112, 288, 209.2, 3.5094, 3.0361, 28000], # 4.3h\n",
    "[ 40, 3, 1, 528, 2112, 288, 209.2, 3.3778,+3.0282,  27000],# 4.1h 16.9G\n",
    "[ 40, 3, 1, 528, 2112, 288, 209.2, 3.3860,+3.0277,  26000],# 4.0h 16.8G\n",
    "[ 40, 3, 1, 528, 2112, 288, 209.2, 3.6145, 3.0595,  25000],# 3.9h 17.2G\n",
    "[ 40, 3, 1, 528, 2112, 288, 209.2, 3.6431, 3.0756,  24000],# 3.6h\n",
    "[ 40, 3, 1, 528, 2112, 272, 206.5, 3.3763, 3.0318, 28000], # 4.2h\n",
    "[ 40, 3, 1, 528, 2112, 272, 206.5, 3.3572,+3.0276,  27000],# 4.0h\n",
    "[ 40, 3, 1, 528, 2112, 272, 206.5, 3.4238, 3.0354,  26000],# 3.9h\n",
    "[ 40, 3, 1, 528, 2112, 272, 206.5, 3.4324,+3.0293,  25000],# 3.7h\n",
    "[ 40, 3, 1, 528, 2112, 272, 206.5, 3.4964, 3.0367,  24000],# 3.6h\n",
    "[ 40, 3, 1, 528, 2112, 256, 203.8, 3.3675, 3.0393,  31000],# 4.3h\n",
    "[ 40, 3, 1, 528, 2112, 256, 203.8, 3.3525,+3.0269,  30000],# 4.1h\n",
    "[ 40, 3, 1, 528, 2112, 256, 203.8, 3.3056,+3.0265,  29000],# 4.0h\n",
    "[ 40, 3, 1, 528, 2112, 256, 203.8, 3.3319,+3.0281, 28000], # 3.8h\n",
    "[ 40, 3, 1, 528, 2112, 256, 203.8, 3.5015, 3.0453,  27000],# 3.7h 16.8G\n",
    "[ 40, 3, 1, 528, 2112, 256, 203.8, 3.3739,+3.0242,  26000],# 3.6h 17.0G\n",
    "[ 40, 3, 1, 528, 2112, 256, 203.8, 3.4269, 3.0351,  25000],# 3.4h\n",
    "[ 40, 3, 1, 528, 2112, 256, 203.8, 3.3989,+3.0268,  24000],# 3.3h\n",
    "[ 40, 3, 1, 528, 2112, 256, 203.8, 3.8218, 3.1082,  23000],# 3.1h\n",
    "[ 40, 3, 1, 528, 2112, 240, 201.1, 3.3324, 3.0348, 28000], # 3.8h\n",
    "[ 40, 3, 1, 528, 2112, 240, 201.1, 3.3936, 3.0308,  27000],# 3.7h\n",
    "[ 40, 3, 1, 528, 2112, 240, 201.1, 3.4122, 3.0308,  26000],# 3.5h\n",
    "[ 40, 3, 1, 528, 2112, 240, 201.1, 3.4131,+3.0291,  25000],# 3.4h\n",
    "[ 40, 3, 1, 528, 2112, 240, 201.1, 3.4441, 3.0342,  24000],# 3.2h\n",
    "[ 40, 3, 1, 528, 2112, 224, 198.4, 3.3297, 3.0361, 28000], # 3.7h 16.3G\n",
    "[ 40, 3, 1, 528, 2112, 224, 198.4, 3.3242, 3.0328,  27000],# 3.5h\n",
    "[ 40, 3, 1, 528, 2112, 224, 198.4, 3.4288, 3.0318,  26000],# 3.4h\n",
    "[ 40, 3, 1, 528, 2112, 224, 198.4, 3.4417, 3.0343,  25000],# 3.3h\n",
    "[ 40, 3, 1, 528, 2112, 224, 198.4, 3.5730, 3.0412,  24000],# 3.1h\n",
    "[ 40, 3, 1, 528, 2112, 208, 195.7, 3.3871, 3.0352, 28000], # 3.6h\n",
    "[ 40, 3, 1, 528, 2112, 208, 195.7, 3.3539, 3.0325,  27000],# 3.5h\n",
    "[ 40, 3, 1, 528, 2112, 208, 195.7, 3.3841, 3.0317,  26000],# 3.4h\n",
    "[ 40, 3, 1, 528, 2112, 208, 195.7, 3.4080, 3.0362,  25000],# 3.2h\n",
    "[ 40, 3, 1, 528, 2112, 208, 195.7, 3.5307, 3.0338,  24000],# 3.1h 16.5G\n",
    "[ 40, 3, 1, 528, 2112, 192, 193.0, 3.4091, 3.0390, 28000], # 3.5h\n",
    "[ 40, 3, 1, 528, 2112, 192, 193.0, 3.3256, 3.0399,  27000],# 3.3h\n",
    "[ 40, 3, 1, 528, 2112, 192, 193.0, 3.3901, 3.0384,  26000],# 3.2h\n",
    "[ 40, 3, 1, 528, 2112, 192, 193.0, 3.4032, 3.0354,  25000],# 3.2h\n",
    "[ 40, 3, 1, 528, 2112, 192, 193.0, 3.4227, 3.0382,  24000],# 3.0h\n",
    "[ 40, 3, 1, 528, 2112, 176, 190.3, 3.4411, 3.0412, 28000], # 3.4h\n",
    "[ 40, 3, 1, 528, 2112, 176, 190.3, 3.4121, 3.0406,  27000],# 3.3h\n",
    "[ 40, 3, 1, 528, 2112, 176, 190.3, 3.3925,+3.0263,  26000],# 3.2h\n",
    "[ 40, 3, 1, 528, 2112, 176, 190.3, 3.4531, 3.0399,  25000],# 3.1h 16.3G\n",
    "[ 40, 3, 1, 528, 2112, 176, 190.3, 3.4630, 3.0391,  24000],# 2.9h 16.2G\n",
    "[ 40, 3, 1, 528, 2112, 160, 187.6, 3.3330, 3.0322, 28000], # 3.3h 15.9G\n",
    "[ 40, 3, 1, 528, 2112, 160, 187.6, 3.5535, 3.0606,  27000],# 3.2h\n",
    "[ 40, 3, 1, 528, 2112, 160, 187.6, 3.5204, 3.0373,  26000],# 3.1h\n",
    "[ 40, 3, 1, 528, 2112, 160, 187.6, 3.3579, 3.0311,  25000],# 3.0h\n",
    "[ 40, 3, 1, 528, 2112, 160, 187.6, 3.4059, 3.0362,  24000],# 2.8h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "61012c64-5489-4092-8c82-af57746c9fec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178.176\n",
      "L40 att3 kv_heads1 hidden624 intermediate2496 head_dim288 T1024\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='14500' max='14500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [14500/14500 4:49:20, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>14500</td>\n",
       "      <td>3.466200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 40, 3, 1, 624, 2496, 288, 276.0, 3.4662, 3.0202, 29000],\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt; import numpy as np; import time, torch; device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "from transformers import AutoTokenizer, TrainingArguments, DefaultDataCollator, Trainer\n",
    "vocab_size = 50257 # =tokenizer.vocab_size  # FIX!!! # G256128    ### T=256 for minGemma # G8192 for real Gemma\n",
    "num_hidden_layers =  40 # 8 # G28 G18 #blocks\n",
    "num_attention_heads = 3 # 4 # G16 G8\n",
    "num_key_value_heads = 1 # 4 # G16 G1\n",
    "hidden_size = num_attention_heads*208 # 128 # G3072 G2048 # embedding dimension\n",
    "intermediate_size = hidden_size*4 # x4 or x8 # time limiting factor #512 # G24576 G16384  # MLP inner dim\n",
    "head_dim = 288 # 32 # G256 # dim in attention # Doesn't affect time\n",
    "rms_norm_eps = 1e-6 # 1e-6\n",
    "rope_theta = 1000.0 # scale freq is small for S-model. 1000 might work too # G10000.0\n",
    "\n",
    "def apply_rotary_emb(x: torch.Tensor, dim: int) -> torch.Tensor: # seq_len = x.size(1) # N\n",
    "    freqs = 1.0 / (rope_theta ** (torch.arange(0, dim, 2, device=device).float() / dim)) # Dynamically compute frequency cis\n",
    "    t = torch.arange(x.size(1), device=device); freqs = torch.outer(t, freqs).float(); freqs_cis = torch.polar(torch.ones_like(freqs), freqs)  # complex64\n",
    "    x_ = torch.view_as_complex(torch.stack(torch.chunk(x.transpose(1, 2).float(), 2, dim=-1), dim=-1))\n",
    "    x_out = torch.view_as_real(x_ * freqs_cis.unsqueeze(0)).type_as(x)  # Ensure batch dimension is handled\n",
    "    x_out = torch.cat(torch.chunk(x_out, 2, dim=-1), dim=-2)\n",
    "    return x_out.reshape(x_out.shape[0], x_out.shape[1], x_out.shape[2], -1).transpose(1, 2)\n",
    "\n",
    "class RMSNorm(torch.nn.Module): # RMS:4.326552, RMS_no_weight:4.410741 # RMS':4.554899\n",
    "    def __init__(self, dim: int = hidden_size):\n",
    "        super().__init__(); self.weight = torch.nn.Parameter(torch.zeros(dim)) # one weight per feature to be learned\n",
    "    def _norm(self, x): # mean square for each feature (across the last dimension)\n",
    "        return x * torch.rsqrt(x.pow(2).mean(-1, keepdim=True) + rms_norm_eps)\n",
    "    def forward(self, x): # ensure the data type matches the input.\n",
    "        return self._norm(x.float()).type_as(x) * (1 + self.weight)\n",
    "        \n",
    "class GemmaAttention(torch.nn.Module): # MQA = K,V shared by 4Qs\n",
    "    def __init__(self):\n",
    "        super().__init__(); self.qkv_proj = torch.nn.Linear(hidden_size, (num_attention_heads + 2 * num_key_value_heads) * head_dim, bias=False); self.o_proj = torch.nn.Linear(num_attention_heads * head_dim, hidden_size, bias=False) # concatenated attention outputs back to the hidden size.\n",
    "    def forward(self, hidden_states: torch.Tensor,) -> torch.Tensor:  # in=(B, T, hidden_size)\n",
    "        batch_size, input_len, _ = hidden_states.shape\n",
    "        qkv = self.qkv_proj(hidden_states)\n",
    "        xq, xk, xv = qkv.split([num_attention_heads * head_dim, num_key_value_heads * head_dim, num_key_value_heads * head_dim],dim=-1)\n",
    "        xq = xq.view(batch_size, -1, num_attention_heads, head_dim); xk = xk.view(batch_size, -1, num_key_value_heads, head_dim); xv = xv.view(batch_size, -1, num_key_value_heads, head_dim)\n",
    "        xq = apply_rotary_emb(xq, head_dim); xk = apply_rotary_emb(xk, head_dim)\n",
    "        if num_key_value_heads != num_attention_heads:  # Q/KV multiples of K and V to match Q\n",
    "            xk = torch.repeat_interleave(xk, num_attention_heads // num_key_value_heads, dim=2) # [B, T, n_local_heads, head_dim]\n",
    "            xv = torch.repeat_interleave(xv, num_attention_heads // num_key_value_heads, dim=2)\n",
    "        q = xq.transpose(1, 2); k = xk.transpose(1, 2); v = xv.transpose(1, 2) # [batch_size, n_local_heads, input_len, head_dim]\n",
    "        output = torch.nn.functional.scaled_dot_product_attention(q, k, v, attn_mask=None, dropout_p=0, is_causal=True) # B nh T hs        \n",
    "        output = output.transpose(1, 2).contiguous().view(batch_size, input_len, -1)  # [B, T, \"hidden_dim\"]\n",
    "        return self.o_proj(output)\n",
    "\n",
    "class GemmaDecoderLayer(torch.nn.Module): # normalize before and after the attention mechanism\n",
    "    def __init__(self):\n",
    "        super().__init__(); self.self_attn = GemmaAttention(); self.input_layernorm = RMSNorm(); self.post_attention_layernorm = RMSNorm(); self.gate_proj = torch.nn.Linear(hidden_size, intermediate_size); self.up_proj = torch.nn.Linear(hidden_size, intermediate_size); self.down_proj = torch.nn.Linear(intermediate_size, hidden_size) # mlp\n",
    "    def forward(self, hidden_states: torch.Tensor) -> torch.Tensor:  # input_size = (B, T, hidden_size)\n",
    "        residual = hidden_states # Self Attention Block\n",
    "        hidden_states = self.input_layernorm(hidden_states); hidden_states = self.self_attn(hidden_states=hidden_states)\n",
    "        hidden_states = residual + hidden_states\n",
    "        residual = hidden_states # MLP Block\n",
    "        hidden_states = self.post_attention_layernorm(hidden_states); gate = torch.nn.functional.gelu(self.gate_proj(hidden_states)); up = self.up_proj(hidden_states); fuse = gate * up; hidden_states = self.down_proj(fuse) # mlp\n",
    "        return residual + hidden_states\n",
    "\n",
    "class minGemma(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__(); self.embedder = torch.nn.Embedding(vocab_size, hidden_size); self.layers = torch.nn.ModuleList(GemmaDecoderLayer() for _ in range(num_hidden_layers)); self.norm = RMSNorm();\n",
    "    def forward(self, input_token_ids: torch.Tensor) -> torch.Tensor: # (B, T)\n",
    "        hidden_states = self.embedder(input_token_ids[:,:-1]) # (B, T) & (vocab_size, hidden_size) -> (B, T, hidden_size)\n",
    "        hidden_states = hidden_states * (hidden_size**0.5)\n",
    "        for i in range(len(self.layers)):\n",
    "            hidden_states = self.layers[i](hidden_states) # shortened too much???\n",
    "        hidden_states = self.norm(hidden_states) # -> (B, T, hidden_size)        \n",
    "        embedder_weight = self.embedder.weight\n",
    "        logits = torch.matmul(hidden_states, embedder_weight.t()); b,t,v=logits.shape; # (B, T, hidden_size) @ (hidden_size, vocab_size) -> (B, T, vocab_size)\n",
    "        loss = torch.nn.functional.cross_entropy(logits.view(b*t,v), input_token_ids[:,1:].reshape(b*t)) #, weight=None, ignore_index=-100, reduction='mean')\n",
    "        return loss, logits # logits, loss\n",
    "\n",
    "def map_to_array5(ix):\n",
    "    common = torch.stack([torch.from_numpy((train_data[i[0]:i[0]+T+1]).astype(np.int64)) for i in ix]); return {'input_token_ids': common}\n",
    "def map_to_array_Val(ix):\n",
    "    common = torch.stack([torch.from_numpy((val_data[i[0]:i[0]+T+1]).astype(np.int64)) for i in ix]); return {'input_token_ids': common}\n",
    "\n",
    "train_data = np.memmap('train_BabyLM_10M.bin', dtype=np.uint16, mode='r'); val_data = np.memmap('val_BabyLM.bin', dtype=np.uint16, mode='r')\n",
    "T=1024; B=12//2; N_step=14500*2; print(T * B * N_step / 1000000) # 0.01 B-tokens being calculated # n_steps=N_step;\n",
    "model = minGemma().to(device); print(f'L{num_hidden_layers}' f' att{num_attention_heads}' f' kv_heads{num_key_value_heads}' f' hidden{hidden_size}' f' intermediate{intermediate_size}' f' head_dim{head_dim}' f' T{T}')\n",
    "\n",
    "# Normal # lr_scheduler_type=\"linear\" can be omitted\n",
    "training_args = TrainingArguments(gradient_accumulation_steps=2, learning_rate=24.0e-4, weight_decay=1.2, num_train_epochs=1, logging_strategy='epoch', output_dir='./', bf16=True, per_device_train_batch_size=B, per_device_eval_batch_size=B, eval_strategy='no', save_strategy='no', report_to='none', remove_unused_columns=False, dataloader_pin_memory=True) #, dataloader_num_workers=4\n",
    "trainer = Trainer(model=model, args=training_args, train_dataset=torch.utils.data.TensorDataset(torch.randint(len(train_data)-T-1, (B*N_step,))), data_collator=map_to_array5);\n",
    "result = trainer.train(); tloss=result[2][\"train_loss\"] # trainer = Trainer(model=model, args=training_args, eval_dataset=torch.utils.data.TensorDataset(torch.randint(len(val_data)-T-1, (B*400*4,))), data_collator=map_to_array_Val); trainer.can_return_loss = True; loss_current = trainer.evaluate()[\"eval_loss\"]\n",
    "\n",
    "loss = []; model.eval(); B2=16; B2=12//2; torch.cuda.empty_cache();\n",
    "for k in range(5000*2): #4000 # std=0.0056 for 1000 with 89sec\n",
    "    val_ind = torch.randint(len(val_data)-T-1, (B2,)); common = (torch.stack([torch.from_numpy((val_data[i:i+T+1]).astype(np.int64)) for i in val_ind]))\n",
    "    loss += [model(common.to('cuda', non_blocking=True))[0].item()]\n",
    "if torch.Tensor(loss).mean() < 3.0202:\n",
    "    torch.save(model.state_dict(), f'{model.__class__.__name__}' f'-hidden_layers{num_hidden_layers}' f'-att_heads{num_attention_heads}' f'-kv_heads{num_key_value_heads}' f'-hidden{hidden_size}' f'-intermediate{intermediate_size}' f'-head_dim{head_dim}' f'-T{T}' f'--{time.strftime(\"%Y-%m-%d-%H-%M\")}.pth')\n",
    "model.train(); del common; print(f'[ {num_hidden_layers}, {num_attention_heads}, {num_key_value_heads}, {hidden_size}, {intermediate_size}, {head_dim}, {sum(p.numel() for p in model.parameters()) / 10**6:.1f}, {tloss:.4f}, {torch.Tensor(loss).mean():.4f}, {N_step}],')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8245fcae-6abf-4ec8-81ab-9833444fb58b",
   "metadata": {},
   "source": [
    "# L30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f781f09-f754-4772-9b05-7233875ecebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# L30 Normal Model T1024 (default: x4 B12 lr24e-4 WD1.2 N12000) w/ Grad_Acc\n",
    "# Best model for each number of heads:  3(3):3.0308, 4(2):3.0207, 5(1):3.0201\n",
    "\n",
    "# local best for H5(1): 3.0201  (best)\n",
    "[ 30, 5, 1, 800, 3200, 288, 353.8, 3.7457, 3.0414, 25000], # 4.9h\n",
    "[ 30, 5, 1, 800, 3200, 272, 349.2, 3.8062, 3.0528, 25000], # 4.8h\n",
    "[ 30, 5, 1, 800, 3200, 256, 344.6, 3.7667, 3.0484, 25000], # 4.5h\n",
    "[ 30, 5, 1, 800, 3200, 240, 340.0, 3.7113, 3.0435, 25000], # 4.4h 20.7G\n",
    "[ 30, 5, 1, 800, 3200, 224, 335.4, 3.7790, 3.0498, 25000], # 4.3h\n",
    "[ 30, 5, 1, 800, 3200, 208, 330.8, 3.6997, 3.0375, 25000], # 4.2h\n",
    "[ 30, 5, 1, 800, 3200, 192, 326.2, 4.0529, 3.2544, 25000], # 4.0h\n",
    "[ 30, 5, 1, 800, 3200, 176, 321.6, 3.7473, 3.0379, 25000], # 3.9h\n",
    "[ 30, 5, 1, 800, 3200, 160, 317.0, 3.6489, 3.0316, 25000], # 3.8h\n",
    "\n",
    "[ 30, 5, 1, 760, 3040, 288, 325.2, 3.7320, 3.0485, 25000], # 4.6h\n",
    "[ 30, 5, 1, 760, 3040, 272, 320.8, 3.7859, 3.0563, 25000], # 4.5h\n",
    "[ 30, 5, 1, 760, 3040, 256, 316.4, 3.5967, 3.0339, 25000], # 4.2h\n",
    "[ 30, 5, 1, 760, 3040, 240, 312.0, 3.6111, 3.0311, 25000], # 4.1h\n",
    "[ 30, 5, 1, 760, 3040, 224, 307.7, 3.7082, 3.0400, 25000], # 4.0h\n",
    "[ 30, 5, 1, 760, 3040, 208, 303.3, 3.9449, 3.2220,  26000],# 4.0h\n",
    "[ 30, 5, 1, 760, 3040, 208, 303.3, 3.6760,+3.0304, 25000], # 3.9h 19.9G\n",
    "[ 30, 5, 1, 760, 3040, 208, 303.3, 3.7152, 3.0345,  24000],# 3.7h\n",
    "[ 30, 5, 1, 760, 3040, 192, 298.9, 3.5821, 3.0367, 25000], # 3.7h\n",
    "[ 30, 5, 1, 760, 3040, 176, 294.5, 3.8826, 3.0843, 25000], # 3.7h\n",
    "[ 30, 5, 1, 760, 3040, 160, 290.2, 3.5928, 3.0378, 25000], # 3.5h\n",
    "\n",
    "[ 30, 5, 1, 720, 2880, 288, 297.7, 3.6471, 3.0358, 25000], # 4.5h\n",
    "[ 30, 5, 1, 720, 2880, 272, 293.5, 3.6382, 3.0312, 25000], # 4.4h 19.1G\n",
    "[ 30, 5, 1, 720, 2880, 256, 289.4, 3.7449, 3.0469, 25000], # 4.1h 18.6G\n",
    "[ 30, 5, 1, 720, 2880, 240, 285.3, 3.6093, 3.0315, 25000], # 4.0h\n",
    "[ 30, 5, 1, 720, 2880, 224, 281.1, 3.7574, 3.0332, 25000], # 3.9h\n",
    "[ 30, 5, 1, 720, 2880, 208, 277.0, 3.5581, 3.0329,  27000],# 4.1h\n",
    "[ 30, 5, 1, 720, 2880, 208, 277.0, 3.6068, 3.0300,  26000],# 3.9h\n",
    "[ 30, 5, 1, 720, 2880, 208, 277.0, 3.6730,+3.0254, 25000], # 3.8h\n",
    "[ 30, 5, 1, 720, 2880, 208, 277.0, 3.7081, 3.0372,  24000],# 3.6h\n",
    "[ 30, 5, 1, 720, 2880, 192, 272.8, 3.6610, 3.0357,  26000],# 3.8h 18.2G\n",
    "[ 30, 5, 1, 720, 2880, 192, 272.8, 3.5395,+3.0299, 25000], # 3.6h\n",
    "[ 30, 5, 1, 720, 2880, 192, 272.8, 3.6070, 3.0321,  24000],# 3.5h\n",
    "[ 30, 5, 1, 720, 2880, 176, 268.7, 3.8839, 3.1503,  26000],# 3.7h\n",
    "[ 30, 5, 1, 720, 2880, 176, 268.7, 3.5466,+3.0302, 25000], # 3.6h 18.3G\n",
    "[ 30, 5, 1, 720, 2880, 176, 268.7, 3.7612, 3.0316,  24000],# 3.4h\n",
    "[ 30, 5, 1, 720, 2880, 176, 268.7, 3.8660, 3.0720,  23000],# 3.3h\n",
    "[ 30, 5, 1, 720, 2880, 160, 264.5, 3.5710, 3.0330,  26000],# 3.6h\n",
    "[ 30, 5, 1, 720, 2880, 160, 264.5, 3.6526,+3.0283, 25000], # 3.4h\n",
    "[ 30, 5, 1, 720, 2880, 160, 264.5, 3.5899, 3.0345,  24000],# 3.3h\n",
    "\n",
    "[ 30, 5, 1, 680, 2720, 288, 271.4, 3.5366, 3.0354, 25000], # 4.4h\n",
    "[ 30, 5, 1, 680, 2720, 272, 267.4, 3.8708, 3.0746,  26000],# 4.5h\n",
    "[ 30, 5, 1, 680, 2720, 272, 267.4, 3.6010,+3.0290, 25000], # 4.3h\n",
    "[ 30, 5, 1, 680, 2720, 272, 267.4, 3.7619, 3.0362,  24000],# 4.1h\n",
    "[ 30, 5, 1, 680, 2720, 256, 263.5, 3.7897, 3.0658, 25000], # 4.0h 18.3G\n",
    "[ 30, 5, 1, 680, 2720, 240, 259.6, 3.6090, 3.0336, 25000], # 3.9h\n",
    "[ 30, 5, 1, 680, 2720, 224, 255.7, 3.5027, 3.0360,  26000],# 3.9h\n",
    "[ 30, 5, 1, 680, 2720, 224, 255.7, 3.5369,+3.0305, 25000], # 3.8h\n",
    "[ 30, 5, 1, 680, 2720, 224, 255.7, 3.5836,+3.0269,  24000],# 3.6h 18.2G\n",
    "[ 30, 5, 1, 680, 2720, 224, 255.7, 3.5683,+3.0297,  23000],# 3.4h\n",
    "[ 30, 5, 1, 680, 2720, 224, 255.7, 3.8199, 3.0530,  22000],# 3.3h\n",
    "[ 30, 5, 1, 680, 2720, 208, 251.8, 3.5812, 3.0430,  27000],# 4.0h\n",
    "[ 30, 5, 1, 680, 2720, 208, 251.8, 3.6219,+3.0250,  26000],# 3.8h\n",
    "[ 30, 5, 1, 680, 2720, 208, 251.8, 3.6122,+3.0297, 25000], # 3.7h\n",
    "[ 30, 5, 1, 680, 2720, 208, 251.8, 3.5468,+3.0265,  24000],# 3.5h\n",
    "[ 30, 5, 1, 680, 2720, 208, 251.8, 3.6764, 3.0342,  23000],# 3.4h\n",
    "[ 30, 5, 1, 680, 2720, 192, 247.9, 3.6102, 3.0384, 25000], # 3.5h\n",
    "[ 30, 5, 1, 680, 2720, 176, 243.9, 3.6093, 3.0345,  26000],# 3.6h\n",
    "[ 30, 5, 1, 680, 2720, 176, 243.9, 3.5342,+3.0250, 25000], # 3.5h\n",
    "[ 30, 5, 1, 680, 2720, 176, 243.9, 3.7536, 3.0508,  24000],# 3.3h\n",
    "[ 30, 5, 1, 680, 2720, 160, 240.0, 3.6328, 3.0346,  26000],# 3.5h\n",
    "[ 30, 5, 1, 680, 2720, 160, 240.0, 3.5206,+3.0241, 25000], # 3.3h\n",
    "[ 30, 5, 1, 680, 2720, 160, 240.0, 3.8507, 3.0801,  24000],# 3.2h\n",
    "\n",
    "[ 30, 5, 1, 640, 2560, 288, 246.2, 3.8783, 3.1025, 25000], # 4.1h 18.1G\n",
    "[ 30, 5, 1, 640, 2560, 272, 242.5, 3.6662, 3.0788,  28000],# 4.5h\n",
    "[ 30, 5, 1, 640, 2560, 272, 242.5, 3.8231, 3.1790,  28000],# 4.5h 18.1G\n",
    "[ 30, 5, 1, 640, 2560, 272, 242.5, 3.4537,+3.0275,  27000],# 4.4h 18.0G\n",
    "[ 30, 5, 1, 640, 2560, 272, 242.5, 3.6114,+3.0244,  26000],# 4.2h\n",
    "[ 30, 5, 1, 640, 2560, 272, 242.5, 3.4934,+3.0256, 25000], # 4.1h\n",
    "[ 30, 5, 1, 640, 2560, 272, 242.5, 3.6401, 3.0341,  24000],# 3.9h\n",
    "[ 30, 5, 1, 640, 2560, 256, 238.8, 3.4962, 3.0338, 25000], # 3.7h\n",
    "[ 30, 5, 1, 640, 2560, 240, 235.1, 3.7235, 3.0598, 25000], # 3.6h\n",
    "[ 30, 5, 1, 640, 2560, 224, 231.4, 3.5928, 3.0344, 25000], # 3.5h\n",
    "[ 30, 5, 1, 640, 2560, 208, 227.8, 3.6040, 3.0391,  26000],# 3.5h 17.1G\n",
    "[ 30, 5, 1, 640, 2560, 208, 227.8, 3.5030,+3.0255, 25000], # 3.4h 17.2G\n",
    "[ 30, 5, 1, 640, 2560, 208, 227.8, 3.5126,+3.0278,  24000],# 3.3h\n",
    "[ 30, 5, 1, 640, 2560, 208, 227.8, 3.5256, 3.0304,  23000],# 3.1h\n",
    "[ 30, 5, 1, 640, 2560, 208, 227.8, 3.6322,+3.0291,  22000],# 3.0h\n",
    "[ 30, 5, 1, 640, 2560, 208, 227.8, 3.7652, 3.0511,  21000],# 2.8h 17.0G\n",
    "[ 30, 5, 1, 640, 2560, 192, 224.1, 3.6158, 3.0330,  27000],# 3.5h\n",
    "[ 30, 5, 1, 640, 2560, 192, 224.1, 3.5486,+3.0297,  26000],# 3.4h\n",
    "[ 30, 5, 1, 640, 2560, 192, 224.1, 3.4572,+3.0287, 25000], # 3.3h\n",
    "[ 30, 5, 1, 640, 2560, 192, 224.1, 3.4758,+3.0253,  24000],# 3.1h\n",
    "[ 30, 5, 1, 640, 2560, 192, 224.1, 3.5120,+3.0260,  23000],# 3.0h\n",
    "[ 30, 5, 1, 640, 2560, 192, 224.1, 3.6018,+3.0298,  22000],# 2.9h\n",
    "[ 30, 5, 1, 640, 2560, 192, 224.1, 3.5829, 3.0327,  21000],# 2.7h 16.9G\n",
    "[ 30, 5, 1, 640, 2560, 192, 224.1, 3.5981,+3.0291,  20000],# 2.6h 17.1G\n",
    "# shorter-N\n",
    "[ 30, 5, 1, 640, 2560, 176, 220.4, 3.5020, 3.0364, 25000], # 3.2h\n",
    "[ 30, 5, 1, 640, 2560, 160, 216.7, 3.7422, 3.0811,  26000],# 3.2h\n",
    "[ 30, 5, 1, 640, 2560, 160, 216.7, 3.5317,+3.0287, 25000], # 3.1h\n",
    "[ 30, 5, 1, 640, 2560, 160, 216.7, 3.4985,+3.0266,  24000],# 2.9h\n",
    "[ 30, 5, 1, 640, 2560, 160, 216.7, 3.5090, 3.0352,  23000],# 2.8h\n",
    "[ 30, 5, 1, 640, 2560, 144, 213.0, 3.7951, 3.0638, 24000], # 2.9h\n",
    "\n",
    "[ 30, 5, 1, 600, 2400, 304, 225.6, 3.6114, 3.0395,  27000],# 4.5h\n",
    "[ 30, 5, 1, 600, 2400, 304, 225.6, 3.5077,+3.0233,  26000],# 4.3h 17.7G\n",
    "[ 30, 5, 1, 600, 2400, 304, 225.6, 3.4409,+3.0261, 25000], # 4.2h\n",
    "[ 30, 5, 1, 600, 2400, 304, 225.6, 3.5077,+3.0264,  24000],# 4.0h\n",
    "[ 30, 5, 1, 600, 2400, 304, 225.6, 3.4778, 3.0305,  23000],# 3.8h\n",
    "[ 30, 5, 1, 600, 2400, 304, 225.6, 3.5215,+3.0292,  22000],# 3.6h 17.6G\n",
    "[ 30, 5, 1, 600, 2400, 304, 225.6, 3.5237, 3.0315,  21000],# 3.5h\n",
    "[ 30, 5, 1, 600, 2400, 304, 225.6, 3.6633, 3.0336,  20000],# 3.3h\n",
    "[ 30, 5, 1, 600, 2400, 288, 222.2, 3.5977, 3.0490,  27000],# 4.4h\n",
    "[ 30, 5, 1, 600, 2400, 288, 222.2, 3.4254,+3.0296,  26000],# 4.2h\n",
    "[ 30, 5, 1, 600, 2400, 288, 222.2, 3.4318,+3.0257, 25000], # 4.1h\n",
    "[ 30, 5, 1, 600, 2400, 288, 222.2, 3.7118, 3.0561,  24000],# 3.9h\n",
    "[ 30, 5, 1, 600, 2400, 272, 218.7, 3.7198, 3.0606, 25000], # 4.0h\n",
    "[ 30, 5, 1, 600, 2400, 256, 215.2, 3.6314, 3.0397, 25000], # 3.6h 17.1G\n",
    "[ 30, 5, 1, 600, 2400, 240, 211.8, 3.4766, 3.0318,  26000],# 3.6h\n",
    "[ 30, 5, 1, 600, 2400, 240, 211.8, 3.4407,+3.0285, 25000], # 3.5h\n",
    "[ 30, 5, 1, 600, 2400, 240, 211.8, 3.4690,+3.0289,  24000],# 3.4h 16.0G\n",
    "[ 30, 5, 1, 600, 2400, 240, 211.8, 3.5273,+3.0228,  23000],# 3.2h\n",
    "[ 30, 5, 1, 600, 2400, 240, 211.8, 3.5225,+3.0253,  22000],# 3.1h\n",
    "[ 30, 5, 1, 600, 2400, 240, 211.8, 3.5522,+3.0290,  21000],# 2.9h\n",
    "[ 30, 5, 1, 600, 2400, 240, 211.8, 3.6434, 3.0356,  20000],# 2.8h\n",
    "[ 30, 5, 1, 600, 2400, 224, 208.3, 3.5065, 3.0343, 25000], # 3.4h\n",
    "[ 30, 5, 1, 600, 2400, 208, 204.9, 3.5695, 3.0313, 25000], # 3.4h\n",
    "[ 30, 5, 1, 600, 2400, 192, 201.4, 3.6596, 3.0673,  26000],# 3.3h\n",
    "[ 30, 5, 1, 600, 2400, 192, 201.4, 3.4716,+3.0272, 25000], # 3.2h\n",
    "[+30, 5, 1, 600, 2400, 192, 201.4, 3.4747,+3.0201,  24000],# 3.1h  minGemma-hidden_layers30-att_heads5-kv_heads1-hidden600-intermediate2400-head_dim192-T1024--2025-10-20-09-41.pth\n",
    "[ 30, 5, 1, 600, 2400, 192, 201.4, 3.4859,+3.0278,  23000],# 2.9h\n",
    "[ 30, 5, 1, 600, 2400, 192, 201.4, 3.5720, 3.0319,  22000],# 2.8h\n",
    "[ 30, 5, 1, 600, 2400, 192, 201.4, 3.5601,+3.0290,  21000],# 2.7h\n",
    "[ 30, 5, 1, 600, 2400, 192, 201.4, 3.5770, 3.0367,  20000],# 2.5h\n",
    "[ 30, 5, 1, 600, 2400, 176, 198.0, 3.5327, 3.0491,  29000],# 3.6h 15.3G\n",
    "[ 30, 5, 1, 600, 2400, 176, 198.0, 3.5216,+3.0299,  28000],# 3.5h\n",
    "[ 30, 5, 1, 600, 2400, 176, 198.0, 3.3942,+3.0246,  27000],# 3.4h\n",
    "[ 30, 5, 1, 600, 2400, 176, 198.0, 3.4947,+3.0295,  26000],# 3.2h\n",
    "[ 30, 5, 1, 600, 2400, 176, 198.0, 3.4181,+3.0290, 25000], # 3.1h\n",
    "[ 30, 5, 1, 600, 2400, 176, 198.0, 3.4843, 3.0354,  24000],# 3.0h\n",
    "[ 30, 5, 1, 600, 2400, 160, 194.5, 3.4817, 3.0315, 25000], # 3.0h\n",
    "\n",
    "[ 30, 5, 1, 560, 2240, 304, 202.5, 3.7379, 3.0917, 25000], # 4.0h\n",
    "[ 30, 5, 1, 560, 2240, 288, 199.3, 3.6145, 3.0792,  27000],# 4.2h\n",
    "[ 30, 5, 1, 560, 2240, 288, 199.3, 3.5049,+3.0282,  26000],# 4.1h\n",
    "[ 30, 5, 1, 560, 2240, 288, 199.3, 3.4193,+3.0254, 25000], # 3.9h 17.1G\n",
    "[ 30, 5, 1, 560, 2240, 288, 199.3, 3.4386,+3.0290,  24000],# 3.8h\n",
    "[ 30, 5, 1, 560, 2240, 288, 199.3, 3.4643,+3.0279,  23000],# 3.6h\n",
    "[ 30, 5, 1, 560, 2240, 288, 199.3, 3.5776, 3.0347,  22000],# 3.4h\n",
    "[ 30, 5, 1, 560, 2240, 272, 196.1, 3.4399, 3.0368,  27000],# 4.2h\n",
    "[ 30, 5, 1, 560, 2240, 272, 196.1, 3.3823,+3.0254,  26000],# 4.0h\n",
    "[ 30, 5, 1, 560, 2240, 272, 196.1, 3.4732,+3.0273, 25000], # 3.9h\n",
    "[ 30, 5, 1, 560, 2240, 272, 196.1, 3.4235,+3.0267,  24000],# 3.7h\n",
    "[ 30, 5, 1, 560, 2240, 272, 196.1, 3.4761, 3.0309,  23000],# 3.5h\n",
    "[ 30, 5, 1, 560, 2240, 272, 196.1, 3.5163,+3.0299,  22000],# 3.4h\n",
    "[ 30, 5, 1, 560, 2240, 272, 196.1, 3.5675, 3.0383,  21000],# 3.2h 16.7G\n",
    "[ 30, 5, 1, 560, 2240, 256, 192.8, 3.4410, 3.0340, 25000], # 3.5h\n",
    "[ 30, 5, 1, 560, 2240, 240, 189.6, 3.4128, 3.0310, 25000], # 3.4h\n",
    "[ 30, 5, 1, 560, 2240, 224, 186.4, 3.4386, 3.0359,  26000],# 3.4h\n",
    "[ 30, 5, 1, 560, 2240, 224, 186.4, 3.4049,+3.0286, 25000], # 3.3h\n",
    "[ 30, 5, 1, 560, 2240, 224, 186.4, 3.4115, 3.0340,  24000],# 3.2h\n",
    "[ 30, 5, 1, 560, 2240, 208, 183.2, 3.7191, 3.0899, 25000], # 3.2h\n",
    "[ 30, 5, 1, 560, 2240, 192, 179.9, 3.6946, 3.0501, 25000], # 3.1h 15.0G\n",
    "[ 30, 5, 1, 560, 2240, 176, 176.7, 3.3745, 3.0316, 25000], # 3.0h\n",
    "[ 30, 5, 1, 560, 2240, 160, 173.5, 3.4337, 3.0353, 25000], # 2.9h\n",
    "\n",
    "[ 30, 5, 1, 520, 2080, 288, 177.6, 3.3648, 3.0322, 25000], # 3.9h\n",
    "[ 30, 5, 1, 520, 2080, 272, 174.6, 3.6803, 3.0718, 25000], # 3.8h\n",
    "[ 30, 5, 1, 520, 2080, 256, 171.6, 3.3638, 3.0394, 25000], # 3.4h\n",
    "[ 30, 5, 1, 520, 2080, 240, 168.6, 3.3749, 3.0382, 25000], # 3.4h 15.0G\n",
    "[ 30, 5, 1, 520, 2080, 224, 165.6, 3.3765, 3.0319, 25000], # 3.2h\n",
    "[ 30, 5, 1, 520, 2080, 208, 162.6, 3.4744, 3.0402, 25000], # 3.1h\n",
    "[ 30, 5, 1, 520, 2080, 192, 159.6, 3.3558, 3.0334, 25000], # 3.0h\n",
    "[ 30, 5, 1, 520, 2080, 176, 156.6, 3.3253, 3.0326,  26000],# 3.0h\n",
    "[ 30, 5, 1, 520, 2080, 176, 156.6, 3.3668,+3.0279, 25000], # 2.9h\n",
    "[ 30, 5, 1, 520, 2080, 176, 156.6, 3.3844, 3.0351,  24000],# 2.8h\n",
    "[ 30, 5, 1, 520, 2080, 160, 153.6, 3.3695, 3.0351, 25000], # 2.8h\n",
    "\n",
    "[ 30, 5, 1, 500, 2000, 176, 147.0, 3.3401, 3.0354, 25000], # 2.8h\n",
    "\n",
    "\n",
    "# local best for H4(2): 3.0207  (2nd best)\n",
    "[ 30, 4, 2, 816, 3264, 288, 365.6, 3.8762, 3.0562,  26000],# 4.8h\n",
    "[ 30, 4, 2, 816, 3264, 288, 365.6, 3.8708, 3.0577, 25000], # 4.6h 21.0G\n",
    "[ 30, 4, 2, 816, 3264, 288, 365.6, 3.9413, 3.0540,  24000],# 4.4h\n",
    "[ 30, 4, 2, 816, 3264, 272, 360.9, 4.0039, 3.0546,  26000],# 4.7h\n",
    "[ 30, 4, 2, 816, 3264, 272, 360.9, 3.9694, 3.0539, 25000], # 4.5h\n",
    "[ 30, 4, 2, 816, 3264, 272, 360.9, 4.2728, 3.3459,  24000],# 4.3h\n",
    "[ 30, 4, 2, 816, 3264, 256, 356.2, 3.9082, 3.0530,  26000],# 4.4h\n",
    "[ 30, 4, 2, 816, 3264, 256, 356.2, 3.7816, 3.0507, 25000], # 4.2h\n",
    "[ 30, 4, 2, 816, 3264, 256, 356.2, 4.2178, 3.1656,  24000],# 4.0h\n",
    "[ 30, 4, 2, 816, 3264, 240, 351.5, 3.8239, 3.0585,  26000],# 4.3h\n",
    "[ 30, 4, 2, 816, 3264, 240, 351.5, 3.8266, 3.0455, 25000], # 4.2h\n",
    "[ 30, 4, 2, 816, 3264, 240, 351.5, 3.8654, 3.0497,  24000],# 4.0h\n",
    "[ 30, 4, 2, 816, 3264, 224, 346.8, 3.8228, 3.0467,  26000],# 4.2h\n",
    "[ 30, 4, 2, 816, 3264, 224, 346.8, 3.8376, 3.0457, 25000], # 4.1h 20.6G\n",
    "[ 30, 4, 2, 816, 3264, 224, 346.8, 4.0832, 3.1100,  24000],# 3.9h\n",
    "[ 30, 4, 2, 816, 3264, 208, 342.1, 3.7703, 3.0428,  26000],# 4.1h\n",
    "[ 30, 4, 2, 816, 3264, 208, 342.1, 3.7205, 3.0423, 25000], # 4.0h\n",
    "[ 30, 4, 2, 816, 3264, 208, 342.1, 3.8238, 3.0482,  24000],# 3.8h\n",
    "[ 30, 4, 2, 816, 3264, 192, 337.4, 3.7205, 3.0392,  26000],# 4.0h\n",
    "[ 30, 4, 2, 816, 3264, 192, 337.4, 4.1027, 3.0593, 25000], # 3.8h\n",
    "[ 30, 4, 2, 816, 3264, 192, 337.4, 4.2657, 3.3427,  24000],# 3.7h\n",
    "[ 30, 4, 2, 816, 3264, 176, 332.7, 3.8522, 3.0501,  26000],# 3.9h\n",
    "[ 30, 4, 2, 816, 3264, 176, 332.7, 3.7897, 3.0502, 25000], # 3.8h\n",
    "[ 30, 4, 2, 816, 3264, 176, 332.7, 4.0827, 3.1254,  24000],# 3.6h\n",
    "[ 30, 4, 2, 816, 3264, 160, 328.0, 3.8948, 3.0651,  26000],# 3.8h\n",
    "[ 30, 4, 2, 816, 3264, 160, 328.0, 3.7539, 3.0408, 25000], # 3.7h\n",
    "[ 30, 4, 2, 816, 3264, 160, 328.0, 3.9204, 3.0577,  24000],# 3.5h\n",
    "\n",
    "[ 30, 4, 2, 768, 3072, 288, 330.8, 3.7860, 3.0558,  26000],# 4.3h\n",
    "[ 30, 4, 2, 768, 3072, 288, 330.8, 3.9647, 3.0688, 25000], # 4.2h\n",
    "[ 30, 4, 2, 768, 3072, 288, 330.8, 3.8730, 3.0571,  24000],# 4.0h\n",
    "[ 30, 4, 2, 768, 3072, 272, 326.4, 3.8165, 3.0432,  26000],# 4.3h\n",
    "[ 30, 4, 2, 768, 3072, 272, 326.4, 3.9635, 3.0563, 25000], # 4.1h\n",
    "[ 30, 4, 2, 768, 3072, 272, 326.4, 3.7804, 3.0443,  24000],# 4.0h\n",
    "[ 30, 4, 2, 768, 3072, 256, 322.0, 3.7355, 3.0479,  26000], # 4.0h 20.0G\n",
    "[ 30, 4, 2, 768, 3072, 256, 322.0, 4.1352, 3.1228, 25000], # 3.8h\n",
    "[ 30, 4, 2, 768, 3072, 256, 322.0, 3.8677, 3.0511,  24000],# 3.7h\n",
    "[ 30, 4, 2, 768, 3072, 240, 317.5, 3.7385, 3.0414,  26000],# 3.9h\n",
    "[ 30, 4, 2, 768, 3072, 240, 317.5, 3.8507, 3.0577, 25000], # 3.8h\n",
    "[ 30, 4, 2, 768, 3072, 240, 317.5, 3.7894, 3.0420,  24000],# 3.6h\n",
    "[ 30, 4, 2, 768, 3072, 224, 313.1, 3.7553, 3.0377,  26000],# 3.8h\n",
    "[ 30, 4, 2, 768, 3072, 224, 313.1, 3.7970, 3.0410, 25000], # 3.7h\n",
    "[ 30, 4, 2, 768, 3072, 224, 313.1, 4.0563, 3.1616,  24000],# 3.5h\n",
    "[ 30, 4, 2, 768, 3072, 208, 308.7, 3.6446, 3.0402,  26000],# 3.7h\n",
    "[ 30, 4, 2, 768, 3072, 208, 308.7, 3.8734, 3.0441, 25000], # 3.6h\n",
    "[ 30, 4, 2, 768, 3072, 208, 308.7, 3.7651, 3.0467,  24000],# 3.4h\n",
    "[ 30, 4, 2, 768, 3072, 192, 304.3, 3.8376, 3.0558,  26000],# 3.6h\n",
    "[ 30, 4, 2, 768, 3072, 192, 304.3, 3.6883, 3.0433, 25000], # 3.4h\n",
    "[ 30, 4, 2, 768, 3072, 192, 304.3, 3.7850, 3.0597,  24000],# 3.3h\n",
    "[ 30, 4, 2, 768, 3072, 176, 299.8, 3.6356, 3.0337,  26000],# 3.5h\n",
    "[ 30, 4, 2, 768, 3072, 176, 299.8, 3.8792, 3.0650, 25000], # 3.4h 18.0G\n",
    "[ 30, 4, 2, 768, 3072, 176, 299.8, 3.8848, 3.0558,  24000],# 3.2h\n",
    "[ 30, 4, 2, 768, 3072, 160, 295.4, 3.8274, 3.0545,  26000],# 3.4h 18.4G\n",
    "[ 30, 4, 2, 768, 3072, 160, 295.4, 3.6566, 3.0386, 25000], # 3.3h 18.4G\n",
    "[ 30, 4, 2, 768, 3072, 160, 295.4, 3.9065, 3.0642,  24000],# 3.2h 18.2G\n",
    "\n",
    "[ 30, 4, 2, 720, 2880, 288, 297.7, 3.6940, 3.0457,  26000],# 4.3h 18.6G\n",
    "[ 30, 4, 2, 720, 2880, 288, 297.7, 3.8599, 3.0468, 25000], # 4.1h 18.6G\n",
    "[ 30, 4, 2, 720, 2880, 288, 297.7, 3.7766, 3.0415,  24000],# 4.0h\n",
    "[ 30, 4, 2, 720, 2880, 272, 293.5, 3.8298, 3.0587,  26000],# 4.2h\n",
    "[ 30, 4, 2, 720, 2880, 272, 293.5, 3.6860, 3.0351, 25000], # 4.0h\n",
    "[ 30, 4, 2, 720, 2880, 272, 293.5, 3.7523, 3.0390,  24000],# 3.9h 18.3G\n",
    "[ 30, 4, 2, 720, 2880, 256, 289.4, 3.7750, 3.0374,  26000],# 3.9h\n",
    "[ 30, 4, 2, 720, 2880, 256, 289.4, 3.8792, 3.1034, 25000], # 3.7h\n",
    "[ 30, 4, 2, 720, 2880, 256, 289.4, 3.8955, 3.0479,  24000],# 3.6h\n",
    "[ 30, 4, 2, 720, 2880, 240, 285.3, 4.0908, 3.2026,  26000],# 3.8h\n",
    "[ 30, 4, 2, 720, 2880, 240, 285.3, 3.7804, 3.0379, 25000], # 3.7h\n",
    "[ 30, 4, 2, 720, 2880, 240, 285.3, 3.7217, 3.0373,  24000],# 3.5h\n",
    "[ 30, 4, 2, 720, 2880, 224, 281.1, 3.8321, 3.0670,  26000],# 3.7h 18.3G\n",
    "[ 30, 4, 2, 720, 2880, 224, 281.1, 3.6763, 3.0494, 25000], # 3.6h\n",
    "[ 30, 4, 2, 720, 2880, 224, 281.1, 3.9543, 3.0811,  24000],# 3.4h\n",
    "[ 30, 4, 2, 720, 2880, 208, 277.0, 3.7287, 3.0435,  27000],# 3.8h\n",
    "[ 30, 4, 2, 720, 2880, 208, 277.0, 3.5757,+3.0277,  26000],# 3.6h\n",
    "[ 30, 4, 2, 720, 2880, 208, 277.0, 3.8424, 3.0633, 25000], # 3.5h 18.2G\n",
    "[ 30, 4, 2, 720, 2880, 208, 277.0, 3.7194, 3.0464,  24000],# 3.3h\n",
    "[ 30, 4, 2, 720, 2880, 192, 272.8, 3.8030, 3.0683,  26000],# 3.5h\n",
    "[ 30, 4, 2, 720, 2880, 192, 272.8, 3.6185, 3.0361, 25000], # 3.4h 17.9G\n",
    "[ 30, 4, 2, 720, 2880, 192, 272.8, 3.6662,+3.0300,  24000],# 3.2h 17.8G\n",
    "[ 30, 4, 2, 720, 2880, 192, 272.8, 3.8119, 3.0454,  23000],# 3.1h\n",
    "[ 30, 4, 2, 720, 2880, 176, 268.7, 3.6077, 3.0347,  26000],# 3.4h\n",
    "[ 30, 4, 2, 720, 2880, 176, 268.7, 3.7007, 3.0354, 25000], # 3.3h\n",
    "[ 30, 4, 2, 720, 2880, 176, 268.7, 3.6418, 3.0385,  24000],# 3.2h\n",
    "[ 30, 4, 2, 720, 2880, 160, 264.5, 3.8209, 3.0803,  26000],# 3.3h\n",
    "[ 30, 4, 2, 720, 2880, 160, 264.5, 3.8900, 3.0959, 25000], # 3.2h\n",
    "[ 30, 4, 2, 720, 2880, 160, 264.5, 3.8775, 3.0673,  24000],# 3.1h\n",
    "\n",
    "[ 30, 4, 2, 672, 2688, 288, 266.2, 3.7142, 3.0380,  26000],# 4.1h\n",
    "[ 30, 4, 2, 672, 2688, 288, 266.2, 3.7211, 3.0445, 25000], # 3.9h\n",
    "[ 30, 4, 2, 672, 2688, 288, 266.2, 3.6483, 3.0397,  24000],# 3.8h\n",
    "#\n",
    "# under construction\n",
    "#\n",
    "[ 30, 4, 2, 672, 2688, 176, 239.1, 3.7242, 3.0511,  27000],# 3.4h\n",
    "[ 30, 4, 2, 672, 2688, 176, 239.1, 3.6078,+3.0282,  26000],# 3.3h\n",
    "[ 30, 4, 2, 672, 2688, 176, 239.1, 3.5489,+3.0257, 25000], # 3.2h\n",
    "[ 30, 4, 2, 672, 2688, 176, 239.1, 3.7421, 3.0404,  24000],# 3.0h\n",
    "[ 30, 4, 2, 672, 2688, 160, 235.3, 3.8065, 3.1095,  26000],# 3.2h\n",
    "[ 30, 4, 2, 672, 2688, 160, 235.3, 3.6502,+3.0274, 25000], # 3.1h\n",
    "[ 30, 4, 2, 672, 2688, 160, 235.3, 3.6192,+3.0275,  24000],# 2.9h\n",
    "[ 30, 4, 2, 672, 2688, 160, 235.3, 3.7454, 3.0438,  23000],# 2.8h\n",
    "[ 30, 4, 2, 672, 2688, 144, 231.4, 3.6309, 3.0353,  27000],# 3.2h\n",
    "[ 30, 4, 2, 672, 2688, 144, 231.4, 3.5721, 3.0311,  26000],# 3.1h\n",
    "[ 30, 4, 2, 672, 2688, 144, 231.4, 3.5029,+3.0265, 25000], # 3.0h\n",
    "[ 30, 4, 2, 672, 2688, 144, 231.4, 3.6097, 3.0325,  24000],# 2.9h\n",
    "\n",
    "\n",
    "# local best for H3(3): 3.0308  (very bad)\n",
    "[ 30, 3, 3, 792, 3168, 288, 348.0, 3.9499, 3.0605, 25000], # 4.2h\n",
    "[ 30, 3, 3, 792, 3168, 272, 343.4, 3.9318, 3.0570, 25000], # 4.1h\n",
    "[ 30, 3, 3, 792, 3168, 256, 338.9, 4.0008, 3.0828, 25000], # 3.8h\n",
    "[ 30, 3, 3, 792, 3168, 240, 334.3, 3.7804, 3.0510, 25000], # 3.8h\n",
    "[ 30, 3, 3, 792, 3168, 224, 329.7, 3.7954, 3.0450, 25000], # 3.7h\n",
    "[ 30, 3, 3, 792, 3168, 208, 325.2, 3.7273, 3.0508, 25000], # 3.6h\n",
    "[ 30, 3, 3, 792, 3168, 192, 320.6, 3.8289, 3.0509, 25000], # 3.5h\n",
    "[ 30, 3, 3, 792, 3168, 176, 316.1, 3.8508, 3.0422, 25000], # 3.4h\n",
    "[ 30, 3, 3, 792, 3168, 160, 311.5, 3.9045, 3.0722, 25000], # 3.4h\n",
    "\n",
    "[ 30, 3, 3, 744, 2976, 288, 314.0, 3.8713, 3.0608, 25000], # 3.8h\n",
    "[ 30, 3, 3, 744, 2976, 272, 309.8, 3.9403, 3.0689, 25000], # 3.7h\n",
    "[ 30, 3, 3, 744, 2976, 256, 305.5, 3.6778, 3.0454, 25000], # 3.5h 19.9G\n",
    "[ 30, 3, 3, 744, 2976, 240, 301.2, 3.6931, 3.0378, 25000], # 3.4h\n",
    "[ 30, 3, 3, 744, 2976, 224, 296.9, 3.6677, 3.0385, 25000], # 3.4h\n",
    "[ 30, 3, 3, 744, 2976, 208, 292.6, 3.7563, 3.0391, 25000], # 3.3h\n",
    "[ 30, 3, 3, 744, 2976, 192, 288.3, 3.6805, 3.0388, 25000], # 3.2h\n",
    "[ 30, 3, 3, 744, 2976, 176, 284.1, 3.8321, 3.0473, 25000], # 3.1h\n",
    "[ 30, 3, 3, 744, 2976, 160, 279.8, 3.7296, 3.0395, 25000], # 3.1h\n",
    "\n",
    "[ 30, 3, 3, 696, 2784, 288, 281.8, 3.8306, 3.0452, 25000], # 3.7h\n",
    "[ 30, 3, 3, 696, 2784, 272, 277.8, 3.7260, 3.0424, 25000], # 3.6h 18.6G\n",
    "[ 30, 3, 3, 696, 2784, 256, 273.7, 3.6928, 3.0402, 25000], # 3.4h\n",
    "[ 30, 3, 3, 696, 2784, 240, 269.7, 3.6876, 3.0383, 25000], # 3.3h\n",
    "[ 30, 3, 3, 696, 2784, 224, 265.7, 3.7737, 3.0405, 25000], # 3.2h\n",
    "[ 30, 3, 3, 696, 2784, 208, 261.7, 3.9422, 3.0901, 25000], # 3.2h\n",
    "[ 30, 3, 3, 696, 2784, 192, 257.7, 3.6383, 3.0345, 25000], # 3.1h\n",
    "[ 30, 3, 3, 696, 2784, 176, 253.7, 3.8285, 3.0886, 25000], # 3.0h\n",
    "[ 30, 3, 3, 696, 2784, 160, 249.7, 3.8597, 3.0782, 25000], # 2.9h 17.4G\n",
    "\n",
    "[ 30, 3, 3, 648, 2592, 288, 251.1, 3.7093, 3.0390, 25000], # 3.6h\n",
    "[ 30, 3, 3, 648, 2592, 272, 247.4, 3.6511, 3.0376, 25000], # 3.5h\n",
    "[ 30, 3, 3, 648, 2592, 256, 243.7, 3.9314, 3.1271, 25000], # 3.3h\n",
    "[ 30, 3, 3, 648, 2592, 240, 239.9, 3.6961, 3.0413, 25000], # 3.2h\n",
    "[ 30, 3, 3, 648, 2592, 224, 236.2, 3.5637, 3.0313, 25000], # 3.1h\n",
    "[ 30, 3, 3, 648, 2592, 208, 232.5, 3.6394, 3.0338, 25000], # 3.1h\n",
    "[ 30, 3, 3, 648, 2592, 192, 228.7, 3.6575, 3.0339, 25000], # 3.0h\n",
    "[ 30, 3, 3, 648, 2592, 176, 225.0, 3.7724, 3.0700, 25000], # 2.9h\n",
    "[ 30, 3, 3, 648, 2592, 160, 221.3, 3.5859, 3.0327, 25000], # 2.8h\n",
    "\n",
    "[ 30, 3, 3, 600, 2400, 288, 222.2, 3.8413, 3.1017, 25000], # 3.3h\n",
    "[ 30, 3, 3, 600, 2400, 272, 218.7, 3.8234, 3.0726, 25000], # 3.2h\n",
    "[ 30, 3, 3, 600, 2400, 256, 215.2, 3.5330, 3.0411, 25000], # 3.0h 16.2G\n",
    "[ 30, 3, 3, 600, 2400, 240, 211.8, 3.8079, 3.0800, 25000], # 2.9h\n",
    "[ 30, 3, 3, 600, 2400, 224, 208.3, 3.6871, 3.0354, 25000], # 2.9h\n",
    "[ 30, 3, 3, 600, 2400, 208, 204.9, 3.8689, 3.1532, 25000], # 2.8h\n",
    "[ 30, 3, 3, 600, 2400, 192, 201.4, 3.7035, 3.0654, 25000], # 2.7h\n",
    "[ 30, 3, 3, 600, 2400, 176, 198.0, 3.7643, 3.0693, 25000], # 2.6h\n",
    "[ 30, 3, 3, 600, 2400, 160, 194.5, 3.7959, 3.1301, 25000], # 2.6h\n",
    "\n",
    "[ 30, 3, 3, 552, 2208, 288, 194.8, 3.4684, 3.0328, 25000], # 3.2h\n",
    "[ 30, 3, 3, 552, 2208, 272, 191.7, 3.4837,+3.0308, 25000], # 3.1h 15.1G\n",
    "[ 30, 3, 3, 552, 2208, 256, 188.5, 3.4555, 3.0384, 25000], # 2.9h\n",
    "[ 30, 3, 3, 552, 2208, 240, 185.3, 3.4647, 3.0349, 25000], # 2.8h\n",
    "[ 30, 3, 3, 552, 2208, 224, 182.1, 3.5664, 3.0343, 25000], # 2.7h\n",
    "[ 30, 3, 3, 552, 2208, 208, 179.0, 3.4848, 3.0404, 25000], # 2.7h\n",
    "[ 30, 3, 3, 552, 2208, 192, 175.8, 3.4837, 3.0361, 25000], # 2.6h\n",
    "[ 30, 3, 3, 552, 2208, 176, 172.6, 3.4571, 3.0397, 25000], # 2.5h\n",
    "[ 30, 3, 3, 552, 2208, 160, 169.4, 3.3870, 3.0366, 25000], # 2.4h\n",
    "\n",
    "[ 30, 3, 3, 504, 2016, 288, 169.2, 3.4180, 3.0375, 25000], # 3.0h\n",
    "[ 30, 3, 3, 504, 2016, 272, 166.3, 3.5784, 3.0652, 25000], # 2.9h\n",
    "[ 30, 3, 3, 504, 2016, 256, 163.4, 3.6884, 3.0694, 25000], # 2.6h\n",
    "[ 30, 3, 3, 504, 2016, 240, 160.5, 3.4033, 3.0344, 25000], # 2.6h\n",
    "[ 30, 3, 3, 504, 2016, 224, 157.6, 3.3930, 3.0418, 25000], # 2.5h\n",
    "[ 30, 3, 3, 504, 2016, 208, 154.7, 3.3974, 3.0422, 25000], # 2.5h 14.2G\n",
    "[ 30, 3, 3, 504, 2016, 192, 151.8, 3.6833, 3.0833, 25000], # 2.4h\n",
    "[ 30, 3, 3, 504, 2016, 176, 148.9, 3.4275, 3.0475, 25000], # 2.3h\n",
    "[ 30, 3, 3, 504, 2016, 160, 146.0, 3.6243, 3.0804, 25000], # 2.2h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "2e07e0e1-1ea5-4af6-a850-11e1adcc598f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "147.456\n",
      "L30 att5 kv_heads1 hidden600 intermediate2400 head_dim192 T1024\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='12000' max='12000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [12000/12000 3:07:35, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>3.474700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 30, 5, 1, 600, 2400, 192, 201.4, 3.4747, 3.0201, 24000],\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt; import numpy as np; import time, torch; device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "from transformers import AutoTokenizer, TrainingArguments, DefaultDataCollator, Trainer\n",
    "vocab_size = 50257 # =tokenizer.vocab_size  # FIX!!! # G256128    ### T=256 for minGemma # G8192 for real Gemma\n",
    "num_hidden_layers =  30 # 8 # G28 G18 #blocks\n",
    "num_attention_heads = 5 # 4 # G16 G8\n",
    "num_key_value_heads = 1 # 4 # G16 G1\n",
    "hidden_size = num_attention_heads*120 # 128 # G3072 G2048 # embedding dimension\n",
    "intermediate_size = hidden_size*4 # x4 or x8 # time limiting factor #512 # G24576 G16384  # MLP inner dim\n",
    "head_dim = 192 # 32 # G256 # dim in attention # Doesn't affect time\n",
    "rms_norm_eps = 1e-6 # 1e-6\n",
    "rope_theta = 1000.0 # scale freq is small for S-model. 1000 might work too # G10000.0\n",
    "\n",
    "def apply_rotary_emb(x: torch.Tensor, dim: int) -> torch.Tensor: # seq_len = x.size(1) # N\n",
    "    freqs = 1.0 / (rope_theta ** (torch.arange(0, dim, 2, device=device).float() / dim)) # Dynamically compute frequency cis\n",
    "    t = torch.arange(x.size(1), device=device); freqs = torch.outer(t, freqs).float(); freqs_cis = torch.polar(torch.ones_like(freqs), freqs)  # complex64\n",
    "    x_ = torch.view_as_complex(torch.stack(torch.chunk(x.transpose(1, 2).float(), 2, dim=-1), dim=-1))\n",
    "    x_out = torch.view_as_real(x_ * freqs_cis.unsqueeze(0)).type_as(x)  # Ensure batch dimension is handled\n",
    "    x_out = torch.cat(torch.chunk(x_out, 2, dim=-1), dim=-2)\n",
    "    return x_out.reshape(x_out.shape[0], x_out.shape[1], x_out.shape[2], -1).transpose(1, 2)\n",
    "\n",
    "class RMSNorm(torch.nn.Module): # RMS:4.326552, RMS_no_weight:4.410741 # RMS':4.554899\n",
    "    def __init__(self, dim: int = hidden_size):\n",
    "        super().__init__(); self.weight = torch.nn.Parameter(torch.zeros(dim)) # one weight per feature to be learned\n",
    "    def _norm(self, x): # mean square for each feature (across the last dimension)\n",
    "        return x * torch.rsqrt(x.pow(2).mean(-1, keepdim=True) + rms_norm_eps)\n",
    "    def forward(self, x): # ensure the data type matches the input.\n",
    "        return self._norm(x.float()).type_as(x) * (1 + self.weight)\n",
    "        \n",
    "class GemmaAttention(torch.nn.Module): # MQA = K,V shared by 4Qs\n",
    "    def __init__(self):\n",
    "        super().__init__(); self.qkv_proj = torch.nn.Linear(hidden_size, (num_attention_heads + 2 * num_key_value_heads) * head_dim, bias=False); self.o_proj = torch.nn.Linear(num_attention_heads * head_dim, hidden_size, bias=False) # concatenated attention outputs back to the hidden size.\n",
    "    def forward(self, hidden_states: torch.Tensor,) -> torch.Tensor:  # in=(B, T, hidden_size)\n",
    "        batch_size, input_len, _ = hidden_states.shape\n",
    "        qkv = self.qkv_proj(hidden_states)\n",
    "        xq, xk, xv = qkv.split([num_attention_heads * head_dim, num_key_value_heads * head_dim, num_key_value_heads * head_dim],dim=-1)\n",
    "        xq = xq.view(batch_size, -1, num_attention_heads, head_dim); xk = xk.view(batch_size, -1, num_key_value_heads, head_dim); xv = xv.view(batch_size, -1, num_key_value_heads, head_dim)\n",
    "        xq = apply_rotary_emb(xq, head_dim); xk = apply_rotary_emb(xk, head_dim)\n",
    "        if num_key_value_heads != num_attention_heads:  # Q/KV multiples of K and V to match Q\n",
    "            xk = torch.repeat_interleave(xk, num_attention_heads // num_key_value_heads, dim=2) # [B, T, n_local_heads, head_dim]\n",
    "            xv = torch.repeat_interleave(xv, num_attention_heads // num_key_value_heads, dim=2)\n",
    "        q = xq.transpose(1, 2); k = xk.transpose(1, 2); v = xv.transpose(1, 2) # [batch_size, n_local_heads, input_len, head_dim]\n",
    "        output = torch.nn.functional.scaled_dot_product_attention(q, k, v, attn_mask=None, dropout_p=0, is_causal=True) # B nh T hs        \n",
    "        output = output.transpose(1, 2).contiguous().view(batch_size, input_len, -1)  # [B, T, \"hidden_dim\"]\n",
    "        return self.o_proj(output)\n",
    "\n",
    "class GemmaDecoderLayer(torch.nn.Module): # normalize before and after the attention mechanism\n",
    "    def __init__(self):\n",
    "        super().__init__(); self.self_attn = GemmaAttention(); self.input_layernorm = RMSNorm(); self.post_attention_layernorm = RMSNorm(); self.gate_proj = torch.nn.Linear(hidden_size, intermediate_size); self.up_proj = torch.nn.Linear(hidden_size, intermediate_size); self.down_proj = torch.nn.Linear(intermediate_size, hidden_size) # mlp\n",
    "    def forward(self, hidden_states: torch.Tensor) -> torch.Tensor:  # input_size = (B, T, hidden_size)\n",
    "        residual = hidden_states # Self Attention Block\n",
    "        hidden_states = self.input_layernorm(hidden_states); hidden_states = self.self_attn(hidden_states=hidden_states)\n",
    "        hidden_states = residual + hidden_states\n",
    "        residual = hidden_states # MLP Block\n",
    "        hidden_states = self.post_attention_layernorm(hidden_states); gate = torch.nn.functional.gelu(self.gate_proj(hidden_states)); up = self.up_proj(hidden_states); fuse = gate * up; hidden_states = self.down_proj(fuse) # mlp\n",
    "        return residual + hidden_states\n",
    "\n",
    "class minGemma(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__(); self.embedder = torch.nn.Embedding(vocab_size, hidden_size); self.layers = torch.nn.ModuleList(GemmaDecoderLayer() for _ in range(num_hidden_layers)); self.norm = RMSNorm();\n",
    "    def forward(self, input_token_ids: torch.Tensor) -> torch.Tensor: # (B, T)\n",
    "        hidden_states = self.embedder(input_token_ids[:,:-1]) # (B, T) & (vocab_size, hidden_size) -> (B, T, hidden_size)\n",
    "        hidden_states = hidden_states * (hidden_size**0.5)\n",
    "        for i in range(len(self.layers)):\n",
    "            hidden_states = self.layers[i](hidden_states) # shortened too much???\n",
    "        hidden_states = self.norm(hidden_states) # -> (B, T, hidden_size)        \n",
    "        embedder_weight = self.embedder.weight\n",
    "        logits = torch.matmul(hidden_states, embedder_weight.t()); b,t,v=logits.shape; # (B, T, hidden_size) @ (hidden_size, vocab_size) -> (B, T, vocab_size)\n",
    "        loss = torch.nn.functional.cross_entropy(logits.view(b*t,v), input_token_ids[:,1:].reshape(b*t)) #, weight=None, ignore_index=-100, reduction='mean')\n",
    "        return loss, logits # logits, loss\n",
    "\n",
    "def map_to_array5(ix):\n",
    "    common = torch.stack([torch.from_numpy((train_data[i[0]:i[0]+T+1]).astype(np.int64)) for i in ix]); return {'input_token_ids': common}\n",
    "def map_to_array_Val(ix):\n",
    "    common = torch.stack([torch.from_numpy((val_data[i[0]:i[0]+T+1]).astype(np.int64)) for i in ix]); return {'input_token_ids': common}\n",
    "\n",
    "train_data = np.memmap('train_BabyLM_10M.bin', dtype=np.uint16, mode='r'); val_data = np.memmap('val_BabyLM.bin', dtype=np.uint16, mode='r')\n",
    "T=1024; B=12//2; N_step=12000*2; print(T * B * N_step / 1000000) # 0.01 B-tokens being calculated # n_steps=N_step;\n",
    "model = minGemma().to(device); print(f'L{num_hidden_layers}' f' att{num_attention_heads}' f' kv_heads{num_key_value_heads}' f' hidden{hidden_size}' f' intermediate{intermediate_size}' f' head_dim{head_dim}' f' T{T}')\n",
    "\n",
    "# Normal # lr_scheduler_type=\"linear\" can be omitted\n",
    "training_args = TrainingArguments(gradient_accumulation_steps=2, learning_rate=24.0e-4, weight_decay=1.2, num_train_epochs=1, logging_strategy='epoch', output_dir='./', bf16=True, per_device_train_batch_size=B, per_device_eval_batch_size=B, eval_strategy='no', save_strategy='no', report_to='none', remove_unused_columns=False, dataloader_pin_memory=True) #, dataloader_num_workers=4\n",
    "trainer = Trainer(model=model, args=training_args, train_dataset=torch.utils.data.TensorDataset(torch.randint(len(train_data)-T-1, (B*N_step,))), data_collator=map_to_array5);\n",
    "result = trainer.train(); tloss=result[2][\"train_loss\"] # trainer = Trainer(model=model, args=training_args, eval_dataset=torch.utils.data.TensorDataset(torch.randint(len(val_data)-T-1, (B*400*4,))), data_collator=map_to_array_Val); trainer.can_return_loss = True; loss_current = trainer.evaluate()[\"eval_loss\"]\n",
    "\n",
    "loss = []; model.eval(); B2=16; B2=12//2; torch.cuda.empty_cache();\n",
    "for k in range(5000*2): #4000 # std=0.0056 for 1000 with 89sec\n",
    "    val_ind = torch.randint(len(val_data)-T-1, (B2,)); common = (torch.stack([torch.from_numpy((val_data[i:i+T+1]).astype(np.int64)) for i in val_ind]))\n",
    "    loss += [model(common.to('cuda', non_blocking=True))[0].item()]\n",
    "if torch.Tensor(loss).mean() < 3.0207:\n",
    "    torch.save(model.state_dict(), f'{model.__class__.__name__}' f'-hidden_layers{num_hidden_layers}' f'-att_heads{num_attention_heads}' f'-kv_heads{num_key_value_heads}' f'-hidden{hidden_size}' f'-intermediate{intermediate_size}' f'-head_dim{head_dim}' f'-T{T}' f'--{time.strftime(\"%Y-%m-%d-%H-%M\")}.pth')\n",
    "model.train(); del common; print(f'[ {num_hidden_layers}, {num_attention_heads}, {num_key_value_heads}, {hidden_size}, {intermediate_size}, {head_dim}, {sum(p.numel() for p in model.parameters()) / 10**6:.1f}, {tloss:.4f}, {torch.Tensor(loss).mean():.4f}, {N_step}],')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ddf74cbe-b92f-41ab-93fd-6e1dfe5294ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "153.6\n",
      "L30 att4 kv_heads2 hidden624 intermediate2496 head_dim176 T1024\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='12500' max='12500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [12500/12500 2:57:47, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>12500</td>\n",
       "      <td>3.498600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 30, 4, 2, 624, 2496, 176, 211.3, 3.4986, 3.0207, 25000],\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt; import numpy as np; import time, torch; device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "from transformers import AutoTokenizer, TrainingArguments, DefaultDataCollator, Trainer\n",
    "vocab_size = 50257 # =tokenizer.vocab_size  # FIX!!! # G256128    ### T=256 for minGemma # G8192 for real Gemma\n",
    "num_hidden_layers =  30 # 8 # G28 G18 #blocks\n",
    "num_attention_heads = 4 # 4 # G16 G8\n",
    "num_key_value_heads = 2 # 4 # G16 G1\n",
    "hidden_size = num_attention_heads*156 # 124 # 88 # 116 # 128 # G3072 G2048 # embedding dimension\n",
    "intermediate_size = hidden_size*4 # x4 or x8 # time limiting factor #512 # G24576 G16384  # MLP inner dim\n",
    "head_dim = 176 # 32 # G256 # dim in attention # Doesn't affect time\n",
    "rms_norm_eps = 1e-6 # 1e-6\n",
    "rope_theta = 1000.0 # scale freq is small for S-model. 1000 might work too # G10000.0\n",
    "\n",
    "def apply_rotary_emb(x: torch.Tensor, dim: int) -> torch.Tensor: # seq_len = x.size(1) # N\n",
    "    freqs = 1.0 / (rope_theta ** (torch.arange(0, dim, 2, device=device).float() / dim)) # Dynamically compute frequency cis\n",
    "    t = torch.arange(x.size(1), device=device); freqs = torch.outer(t, freqs).float(); freqs_cis = torch.polar(torch.ones_like(freqs), freqs)  # complex64\n",
    "    x_ = torch.view_as_complex(torch.stack(torch.chunk(x.transpose(1, 2).float(), 2, dim=-1), dim=-1))\n",
    "    x_out = torch.view_as_real(x_ * freqs_cis.unsqueeze(0)).type_as(x)  # Ensure batch dimension is handled\n",
    "    x_out = torch.cat(torch.chunk(x_out, 2, dim=-1), dim=-2)\n",
    "    return x_out.reshape(x_out.shape[0], x_out.shape[1], x_out.shape[2], -1).transpose(1, 2)\n",
    "\n",
    "class RMSNorm(torch.nn.Module): # RMS:4.326552, RMS_no_weight:4.410741 # RMS':4.554899\n",
    "    def __init__(self, dim: int = hidden_size):\n",
    "        super().__init__(); self.weight = torch.nn.Parameter(torch.zeros(dim)) # one weight per feature to be learned\n",
    "    def _norm(self, x): # mean square for each feature (across the last dimension)\n",
    "        return x * torch.rsqrt(x.pow(2).mean(-1, keepdim=True) + rms_norm_eps)\n",
    "    def forward(self, x): # ensure the data type matches the input.\n",
    "        return self._norm(x.float()).type_as(x) * (1 + self.weight)\n",
    "        \n",
    "class GemmaAttention(torch.nn.Module): # MQA = K,V shared by 4Qs\n",
    "    def __init__(self):\n",
    "        super().__init__(); self.qkv_proj = torch.nn.Linear(hidden_size, (num_attention_heads + 2 * num_key_value_heads) * head_dim, bias=False); self.o_proj = torch.nn.Linear(num_attention_heads * head_dim, hidden_size, bias=False) # concatenated attention outputs back to the hidden size.\n",
    "    def forward(self, hidden_states: torch.Tensor,) -> torch.Tensor:  # in=(B, T, hidden_size)\n",
    "        batch_size, input_len, _ = hidden_states.shape\n",
    "        qkv = self.qkv_proj(hidden_states)\n",
    "        xq, xk, xv = qkv.split([num_attention_heads * head_dim, num_key_value_heads * head_dim, num_key_value_heads * head_dim],dim=-1)\n",
    "        xq = xq.view(batch_size, -1, num_attention_heads, head_dim); xk = xk.view(batch_size, -1, num_key_value_heads, head_dim); xv = xv.view(batch_size, -1, num_key_value_heads, head_dim)\n",
    "        xq = apply_rotary_emb(xq, head_dim); xk = apply_rotary_emb(xk, head_dim)\n",
    "        if num_key_value_heads != num_attention_heads:  # Q/KV multiples of K and V to match Q\n",
    "            xk = torch.repeat_interleave(xk, num_attention_heads // num_key_value_heads, dim=2) # [B, T, n_local_heads, head_dim]\n",
    "            xv = torch.repeat_interleave(xv, num_attention_heads // num_key_value_heads, dim=2)\n",
    "        q = xq.transpose(1, 2); k = xk.transpose(1, 2); v = xv.transpose(1, 2) # [batch_size, n_local_heads, input_len, head_dim]\n",
    "        output = torch.nn.functional.scaled_dot_product_attention(q, k, v, attn_mask=None, dropout_p=0, is_causal=True) # B nh T hs        \n",
    "        output = output.transpose(1, 2).contiguous().view(batch_size, input_len, -1)  # [B, T, \"hidden_dim\"]\n",
    "        return self.o_proj(output)\n",
    "\n",
    "class GemmaDecoderLayer(torch.nn.Module): # normalize before and after the attention mechanism\n",
    "    def __init__(self):\n",
    "        super().__init__(); self.self_attn = GemmaAttention(); self.input_layernorm = RMSNorm(); self.post_attention_layernorm = RMSNorm(); self.gate_proj = torch.nn.Linear(hidden_size, intermediate_size); self.up_proj = torch.nn.Linear(hidden_size, intermediate_size); self.down_proj = torch.nn.Linear(intermediate_size, hidden_size) # mlp\n",
    "    def forward(self, hidden_states: torch.Tensor) -> torch.Tensor:  # input_size = (B, T, hidden_size)\n",
    "        residual = hidden_states # Self Attention Block\n",
    "        hidden_states = self.input_layernorm(hidden_states); hidden_states = self.self_attn(hidden_states=hidden_states)\n",
    "        hidden_states = residual + hidden_states\n",
    "        residual = hidden_states # MLP Block\n",
    "        hidden_states = self.post_attention_layernorm(hidden_states); gate = torch.nn.functional.gelu(self.gate_proj(hidden_states)); up = self.up_proj(hidden_states); fuse = gate * up; hidden_states = self.down_proj(fuse) # mlp\n",
    "        return residual + hidden_states\n",
    "\n",
    "class minGemma(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__(); self.embedder = torch.nn.Embedding(vocab_size, hidden_size); self.layers = torch.nn.ModuleList(GemmaDecoderLayer() for _ in range(num_hidden_layers)); self.norm = RMSNorm();\n",
    "    def forward(self, input_token_ids: torch.Tensor) -> torch.Tensor: # (B, T)\n",
    "        hidden_states = self.embedder(input_token_ids[:,:-1]) # (B, T) & (vocab_size, hidden_size) -> (B, T, hidden_size)\n",
    "        hidden_states = hidden_states * (hidden_size**0.5)\n",
    "        for i in range(len(self.layers)):\n",
    "            hidden_states = self.layers[i](hidden_states) # shortened too much???\n",
    "        hidden_states = self.norm(hidden_states) # -> (B, T, hidden_size)        \n",
    "        embedder_weight = self.embedder.weight\n",
    "        logits = torch.matmul(hidden_states, embedder_weight.t()); b,t,v=logits.shape; # (B, T, hidden_size) @ (hidden_size, vocab_size) -> (B, T, vocab_size)\n",
    "        loss = torch.nn.functional.cross_entropy(logits.view(b*t,v), input_token_ids[:,1:].reshape(b*t)) #, weight=None, ignore_index=-100, reduction='mean')\n",
    "        return loss, logits # logits, loss\n",
    "\n",
    "def map_to_array5(ix):\n",
    "    common = torch.stack([torch.from_numpy((train_data[i[0]:i[0]+T+1]).astype(np.int64)) for i in ix]); return {'input_token_ids': common}\n",
    "def map_to_array_Val(ix):\n",
    "    common = torch.stack([torch.from_numpy((val_data[i[0]:i[0]+T+1]).astype(np.int64)) for i in ix]); return {'input_token_ids': common}\n",
    "\n",
    "train_data = np.memmap('train_BabyLM_10M.bin', dtype=np.uint16, mode='r'); val_data = np.memmap('val_BabyLM.bin', dtype=np.uint16, mode='r')\n",
    "T=1024; B=12//2; N_step=12500*2; print(T * B * N_step / 1000000) # 0.01 B-tokens being calculated # n_steps=N_step;\n",
    "model = minGemma().to(device); print(f'L{num_hidden_layers}' f' att{num_attention_heads}' f' kv_heads{num_key_value_heads}' f' hidden{hidden_size}' f' intermediate{intermediate_size}' f' head_dim{head_dim}' f' T{T}')\n",
    "\n",
    "# Normal # lr_scheduler_type=\"linear\" can be omitted\n",
    "training_args = TrainingArguments(gradient_accumulation_steps=2, learning_rate=24.0e-4, weight_decay=1.2, num_train_epochs=1, logging_strategy='epoch', output_dir='./', bf16=True, per_device_train_batch_size=B, per_device_eval_batch_size=B, eval_strategy='no', save_strategy='no', report_to='none', remove_unused_columns=False, dataloader_pin_memory=True) #, dataloader_num_workers=4\n",
    "trainer = Trainer(model=model, args=training_args, train_dataset=torch.utils.data.TensorDataset(torch.randint(len(train_data)-T-1, (B*N_step,))), data_collator=map_to_array5);\n",
    "result = trainer.train(); tloss=result[2][\"train_loss\"] # trainer = Trainer(model=model, args=training_args, eval_dataset=torch.utils.data.TensorDataset(torch.randint(len(val_data)-T-1, (B*400*4,))), data_collator=map_to_array_Val); trainer.can_return_loss = True; loss_current = trainer.evaluate()[\"eval_loss\"]\n",
    "\n",
    "loss = []; model.eval(); B2=16; B2=12//2; torch.cuda.empty_cache();\n",
    "for k in range(5000*2): #4000 # std=0.0056 for 1000 with 89sec\n",
    "    val_ind = torch.randint(len(val_data)-T-1, (B2,)); common = (torch.stack([torch.from_numpy((val_data[i:i+T+1]).astype(np.int64)) for i in val_ind]))\n",
    "    loss += [model(common.to('cuda', non_blocking=True))[0].item()]\n",
    "if torch.Tensor(loss).mean() < 3.0207:\n",
    "    torch.save(model.state_dict(), f'{model.__class__.__name__}' f'-hidden_layers{num_hidden_layers}' f'-att_heads{num_attention_heads}' f'-kv_heads{num_key_value_heads}' f'-hidden{hidden_size}' f'-intermediate{intermediate_size}' f'-head_dim{head_dim}' f'-T{T}' f'--{time.strftime(\"%Y-%m-%d-%H-%M\")}.pth')\n",
    "model.train(); del common; print(f'[ {num_hidden_layers}, {num_attention_heads}, {num_key_value_heads}, {hidden_size}, {intermediate_size}, {head_dim}, {sum(p.numel() for p in model.parameters()) / 10**6:.1f}, {tloss:.4f}, {torch.Tensor(loss).mean():.4f}, {N_step}],')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "888579b3-70b7-4b66-946c-1ea24132ef69",
   "metadata": {},
   "source": [
    "# L24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7715d789-fcda-42b3-9960-896b015a887c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# L24 Normal Model T1024 (default: x4 B12 lr24e-4 WD1.2 N13000) w/ Grad_Acc\n",
    "# Best model for each number of heads:  4(2):3.0235, 5(1):3.0241, 6(3):3.0223\n",
    "\n",
    "# local best for H6(3): 3.0223  (best)\n",
    "[ 24, 6, 3, 816, 3264, 288, 334.5, 3.9983, 3.0591,  26000],# 4.7h 20.2G\n",
    "[ 24, 6, 3, 816, 3264, 288, 334.5, 4.1941, 3.0697, 25000], # 4.6h\n",
    "[ 24, 6, 3, 816, 3264, 272, 328.9, 4.0109, 3.0625,  26000],# 4.6h 20.1G\n",
    "[ 24, 6, 3, 816, 3264, 272, 328.9, 3.9619, 3.0572, 25000], # 4.6h 20.1G\n",
    "[ 24, 6, 3, 816, 3264, 256, 323.2, 4.1747, 3.1126,  26000],# 4.3h 19.4G\n",
    "[ 24, 6, 3, 816, 3264, 256, 323.2, 3.9990, 3.0566, 25000], # 4.2h\n",
    "[ 24, 6, 3, 816, 3264, 240, 317.6, 3.7689, 3.0506,  26000],# 4.2h 19.1G\n",
    "[ 24, 6, 3, 816, 3264, 240, 317.6, 3.7719, 3.0505, 25000], # 4.1h\n",
    "[ 24, 6, 3, 816, 3264, 224, 312.0, 3.7479, 3.0403,  26000],# 4.1h\n",
    "[ 24, 6, 3, 816, 3264, 224, 312.0, 3.9161, 3.0430, 25000], # 3.9h\n",
    "[ 24, 6, 3, 816, 3264, 208, 306.3, 3.8767, 3.0579,  26000],# 4.0h\n",
    "[ 24, 6, 3, 816, 3264, 208, 306.3, 3.8659, 3.0468, 25000], # 3.8h\n",
    "[ 24, 6, 3, 816, 3264, 192, 300.7, 3.7265, 3.0409,  26000],# 3.8h\n",
    "[ 24, 6, 3, 816, 3264, 192, 300.7, 3.9532, 3.0656, 25000], # 3.6h\n",
    "[ 24, 6, 3, 816, 3264, 176, 295.0, 3.7506, 3.0423,  26000],# 3.7h\n",
    "[ 24, 6, 3, 816, 3264, 176, 295.0, 3.7971, 3.0426, 25000], # 3.6h\n",
    "[ 24, 6, 3, 816, 3264, 160, 289.4, 3.6959, 3.0323,  26000],# 3.6h\n",
    "[ 24, 6, 3, 816, 3264, 160, 289.4, 3.8412, 3.0417, 25000], # 3.5h\n",
    "\n",
    "[ 24, 6, 3, 768, 3072, 288, 304.2, 3.8473, 3.0515,  26000],# 4.4h\n",
    "[ 24, 6, 3, 768, 3072, 288, 304.2, 3.9027, 3.0484, 25000], # 4.3h\n",
    "[ 24, 6, 3, 768, 3072, 272, 298.9, 3.9591, 3.0547,  26000],# 4.3h 19.4G\n",
    "[ 24, 6, 3, 768, 3072, 272, 298.9, 3.8969, 3.0396, 25000], # 4.2h\n",
    "[ 24, 6, 3, 768, 3072, 256, 293.6, 3.9518, 3.0567,  26000],# 3.9h\n",
    "[ 24, 6, 3, 768, 3072, 256, 293.6, 4.0620, 3.0668, 25000], # 3.8h\n",
    "[ 24, 6, 3, 768, 3072, 240, 288.3, 3.7785, 3.0483,  26000],# 3.8h\n",
    "[ 24, 6, 3, 768, 3072, 240, 288.3, 3.9151, 3.0553, 25000], # 3.7h 17.3G\n",
    "[ 24, 6, 3, 768, 3072, 224, 283.0, 3.7836, 3.0458,  26000],# 3.7h\n",
    "[ 24, 6, 3, 768, 3072, 224, 283.0, 3.9745, 3.0594, 25000], # 3.7h\n",
    "[ 24, 6, 3, 768, 3072, 208, 277.7, 3.8972, 3.0543,  26000],# 3.6h 17.1G\n",
    "[ 24, 6, 3, 768, 3072, 208, 277.7, 3.8785, 3.0398, 25000], # 3.6h\n",
    "[ 24, 6, 3, 768, 3072, 192, 272.4, 3.6984, 3.0403,  26000],# 3.5h\n",
    "[ 24, 6, 3, 768, 3072, 192, 272.4, 3.8026, 3.0428, 25000], # 3.4h\n",
    "[ 24, 6, 3, 768, 3072, 176, 267.1, 3.7186, 3.0356,  26000],# 3.4h\n",
    "[ 24, 6, 3, 768, 3072, 176, 267.1, 3.8143, 3.0404, 25000], # 3.3h\n",
    "[ 24, 6, 3, 768, 3072, 160, 261.8, 3.6987, 3.0378,  26000],# 3.3h\n",
    "[ 24, 6, 3, 768, 3072, 160, 261.8, 3.6856, 3.0344, 25000], # 3.2h 16.5G\n",
    "\n",
    "[ 24, 6, 3, 720, 2880, 288, 275.3, 3.8927, 3.0512,  26000],# 4.3h\n",
    "[ 24, 6, 3, 720, 2880, 288, 275.3, 3.8157, 3.0551, 25000], # 4.2h 17.9G\n",
    "[ 24, 6, 3, 720, 2880, 272, 270.3, 3.6742, 3.0342,  26000],# 4.2h\n",
    "[ 24, 6, 3, 720, 2880, 272, 270.3, 3.7448, 3.0417, 25000], # 4.1h\n",
    "[ 24, 6, 3, 720, 2880, 256, 265.3, 3.8378, 3.0546,  26000],# 3.9h\n",
    "[ 24, 6, 3, 720, 2880, 256, 265.3, 3.7627, 3.0485, 25000], # 3.8h\n",
    "[ 24, 6, 3, 720, 2880, 240, 260.3, 3.6635, 3.0339,  26000],# 3.8h\n",
    "[ 24, 6, 3, 720, 2880, 240, 260.3, 3.7032, 3.0374, 25000], # 3.7h\n",
    "[ 24, 6, 3, 720, 2880, 224, 255.3, 3.6787, 3.0334,  26000],# 3.7h\n",
    "[ 24, 6, 3, 720, 2880, 224, 255.3, 3.7445, 3.0406, 25000], # 3.6h\n",
    "[ 24, 6, 3, 720, 2880, 208, 250.4, 3.6505, 3.0390,  26000],# 3.6h\n",
    "[ 24, 6, 3, 720, 2880, 208, 250.4, 3.6940, 3.0470, 25000], # 3.4h\n",
    "[ 24, 6, 3, 720, 2880, 192, 245.4, 3.6593, 3.0402,  26000],# 3.4h 16.5G\n",
    "[ 24, 6, 3, 720, 2880, 192, 245.4, 3.6733, 3.0372, 25000], # 3.3h 16.4G\n",
    "[ 24, 6, 3, 720, 2880, 176, 240.4, 3.6982, 3.0489,  28000],# 3.6h\n",
    "[ 24, 6, 3, 720, 2880, 176, 240.4, 3.6099,+3.0277,  27000],# 3.5h\n",
    "[ 24, 6, 3, 720, 2880, 176, 240.4, 3.5450,+3.0275,  26000],# 3.3h\n",
    "[ 24, 6, 3, 720, 2880, 176, 240.4, 3.6182, 3.0344, 25000], # 3.3h\n",
    "[ 24, 6, 3, 720, 2880, 160, 235.4, 3.8428, 3.0656,  26000],# 3.2h\n",
    "[ 24, 6, 3, 720, 2880, 160, 235.4, 3.5986,+3.0300, 25000], # 3.1h\n",
    "[ 24, 6, 3, 720, 2880, 160, 235.4, 3.6510, 3.0315,  24000],# 3.0h\n",
    "[ 24, 6, 3, 720, 2880, 160, 235.4, 3.7425, 3.0382,  23000],# 2.8h\n",
    "[ 24, 6, 3, 720, 2880, 144, 230.5, 3.5277, 3.0345,  26000],# 3.2h\n",
    "[ 24, 6, 3, 720, 2880, 144, 230.5, 3.7156, 3.0316, 25000], # 3.1h\n",
    "[ 24, 6, 3, 720, 2880, 144, 230.5, 3.6010, 3.0377,  24000],# 2.9h\n",
    "\n",
    "[ 24, 6, 3, 696, 2784, 288, 261.3, 3.5979, 3.0349,  30000],# 5.0h\n",
    "[ 24, 6, 3, 696, 2784, 288, 261.3, 3.6515, 3.0374,  26000],# 4.3h\n",
    "[ 24, 6, 3, 696, 2784, 288, 261.3, 3.7553, 3.0413, 25000], # 4.1h\n",
    "[ 24, 6, 3, 696, 2784, 272, 256.5, 3.5365, 3.0382,  30000],# 4.9h\n",
    "[ 24, 6, 3, 696, 2784, 272, 256.5, 3.7572, 3.0447,  26000],# 4.2h 17.6G\n",
    "[ 24, 6, 3, 696, 2784, 272, 256.5, 3.5917,+3.0271, 25000], # 4.0h\n",
    "[ 24, 6, 3, 696, 2784, 272, 256.5, 3.7461, 3.0389,  24000],# 3.9h\n",
    "[ 24, 6, 3, 696, 2784, 256, 251.6, 3.5989, 3.0424,  30000],# 2.8h\n",
    "[ 24, 6, 3, 696, 2784, 256, 251.6, 3.6143, 3.0356,  26000],# 3.8h\n",
    "[ 24, 6, 3, 696, 2784, 256, 251.6, 3.6384, 3.0358, 25000], # 3.7h\n",
    "[ 24, 6, 3, 696, 2784, 240, 246.8, 3.5525, 3.0349,  30000],# 2.7h\n",
    "[ 24, 6, 3, 696, 2784, 240, 246.8, 3.7356, 3.0401,  26000],# 3.7h\n",
    "[ 24, 6, 3, 696, 2784, 240, 246.8, 3.6694, 3.0323, 25000], # 3.6h\n",
    "[ 24, 6, 3, 696, 2784, 224, 242.0, 3.7319, 3.0554,  30000],# 2.6h\n",
    "[ 24, 6, 3, 696, 2784, 224, 242.0, 3.5672, 3.0357,  26000],# 3.6h 17.0G\n",
    "[ 24, 6, 3, 696, 2784, 224, 242.0, 3.6371, 3.0374, 25000], # 3.5h\n",
    "[ 24, 6, 3, 696, 2784, 208, 237.2, 3.6356, 3.0487,  30000],# 2.5h\n",
    "[ 24, 6, 3, 696, 2784, 208, 237.2, 3.8677, 3.1083,  27000],# 3.7h\n",
    "[ 24, 6, 3, 696, 2784, 208, 237.2, 3.5233,+3.0236,  26000],# 3.5h\n",
    "[ 24, 6, 3, 696, 2784, 208, 237.2, 3.7898, 3.0528, 25000], # 3.4h 16.3G\n",
    "[ 24, 6, 3, 696, 2784, 192, 232.4, 3.4751, 3.0349,  30000],# 2.4h\n",
    "[ 24, 6, 3, 696, 2784, 192, 232.4, 3.7925, 3.0518,  26000],# 3.3h\n",
    "[ 24, 6, 3, 696, 2784, 192, 232.4, 3.6843, 3.0388, 25000], # 3.2h\n",
    "[ 24, 6, 3, 696, 2784, 176, 227.6, 3.4493, 3.0321,  32000],# 2.5h\n",
    "[ 24, 6, 3, 696, 2784, 176, 227.6, 3.5778, 3.0404,  31000],# 2.4h\n",
    "[ 24, 6, 3, 696, 2784, 176, 227.6, 3.5154,+3.0292,  30000],# 2.4h\n",
    "[ 24, 6, 3, 696, 2784, 176, 227.6, 3.4391, 3.0339,  29000],# 2.3h\n",
    "[ 24, 6, 3, 696, 2784, 176, 227.6, 3.5107,+3.0258,  28000],# 2.2h\n",
    "[ 24, 6, 3, 696, 2784, 176, 227.6, 3.6709, 3.0377,  27000],# 2.1h\n",
    "[ 24, 6, 3, 696, 2784, 176, 227.6, 3.6555, 3.0315,  26000],# 2.0h\n",
    "[ 24, 6, 3, 696, 2784, 176, 227.6, 3.5910,+3.0297, 25000], # 3.2h 16.1G\n",
    "[ 24, 6, 3, 696, 2784, 176, 227.6, 3.6049, 3.0322,  24000],# 3.0h\n",
    "[ 24, 6, 3, 696, 2784, 160, 222.8, 3.4983, 3.0349,  30000],# 2.3h\n",
    "[ 24, 6, 3, 696, 2784, 160, 222.8, 3.5856, 3.0360,  26000],# 3.2h\n",
    "[ 24, 6, 3, 696, 2784, 160, 222.8, 3.8163, 3.0703, 25000], # 3.0h\n",
    "\n",
    "[ 24, 6, 3, 648, 2592, 304, 238.8, 3.5024, 3.0376,  30000],# 5.0h\n",
    "[ 24, 6, 3, 648, 2592, 304, 238.8, 3.6257, 3.0452,  26000],# 4.3h\n",
    "[ 24, 6, 3, 648, 2592, 304, 238.8, 3.5539,+3.0275, 25000], # 4.2h\n",
    "[ 24, 6, 3, 648, 2592, 304, 238.8, 3.8417, 3.0403,  24000],# 3.9h\n",
    "[ 24, 6, 3, 648, 2592, 288, 234.3, 3.5433, 3.0356,  31000],# 5.0h\n",
    "[ 24, 6, 3, 648, 2592, 288, 234.3, 3.4638, 3.0311,  30000],# 4.9h\n",
    "[ 24, 6, 3, 648, 2592, 288, 234.3, 3.5110, 3.0357,  29000],# 4.7h\n",
    "[ 24, 6, 3, 648, 2592, 288, 234.3, 3.5653, 3.0329,  26000],# 4.2h\n",
    "[ 24, 6, 3, 648, 2592, 288, 234.3, 3.7757, 3.0643, 25000], # 4.1h\n",
    "[ 24, 6, 3, 648, 2592, 272, 229.8, 3.5601, 3.0364,  30000],# 4.7h 16.8G\n",
    "[ 24, 6, 3, 648, 2592, 272, 229.8, 3.5612, 3.0335,  27000],# 4.3h\n",
    "[ 24, 6, 3, 648, 2592, 272, 229.8, 3.5441,+3.0231,  26000],# 4.1h\n",
    "[ 24, 6, 3, 648, 2592, 272, 229.8, 3.5922,+3.0291, 25000], # 4.0h\n",
    "[ 24, 6, 3, 648, 2592, 272, 229.8, 3.6278, 3.0335,  24000],# 3.8h\n",
    "[ 24, 6, 3, 648, 2592, 256, 225.3, 3.4675, 3.0332,  30000],# 2.7h\n",
    "[ 24, 6, 3, 648, 2592, 256, 225.3, 3.5167, 3.0351,  29000],# 4.2h\n",
    "[ 24, 6, 3, 648, 2592, 256, 225.3, 3.4935, 3.0327,  28000],# 4.1h\n",
    "[ 24, 6, 3, 648, 2592, 256, 225.3, 3.5332, 3.0295,  27000],# 3.9h 16.2G\n",
    "[ 24, 6, 3, 648, 2592, 256, 225.3, 3.6104,+3.0229,  26000],# 3.7h  minGemma-hidden_layers24-att_heads6-kv_heads3-hidden648-intermediate2592-head_dim256-T1024--2025-09-21-08-38.pth\n",
    "[ 24, 6, 3, 648, 2592, 256, 225.3, 3.5297,+3.0279, 25000], # 3.6h\n",
    "[ 24, 6, 3, 648, 2592, 256, 225.3, 3.6713, 3.0339,  24000],# 3.4h\n",
    "[ 24, 6, 3, 648, 2592, 240, 220.9, 3.6905, 3.0754,  30000],# 2.7h\n",
    "[ 24, 6, 3, 648, 2592, 240, 220.9, 3.5758, 3.0320,  27000],# 3.8h\n",
    "[ 24, 6, 3, 648, 2592, 240, 220.9, 3.5494,+3.0301,  26000],# 3.6h\n",
    "[ 24, 6, 3, 648, 2592, 240, 220.9, 3.6544, 3.0313, 25000], # 3.5h\n",
    "[ 24, 6, 3, 648, 2592, 240, 220.9, 3.6157, 3.0317,  24000],# 3.3h\n",
    "[ 24, 6, 3, 648, 2592, 240, 220.9, 3.6069, 3.0306,  23000],# 3.2h\n",
    "[ 24, 6, 3, 648, 2592, 240, 220.9, 3.6486, 3.0336,  22000],# 3.1h\n",
    "[ 24, 6, 3, 648, 2592, 224, 216.4, 3.3874, 3.0287,  31000],# 2.6h\n",
    "[ 24, 6, 3, 648, 2592, 224, 216.4, 3.5121, 3.0327,  30000],# 2.5h\n",
    "[ 24, 6, 3, 648, 2592, 224, 216.4, 3.4391,+3.0290,  30000],# again\n",
    "[ 24, 6, 3, 648, 2592, 224, 216.4, 3.4468,+3.0283,  29000],# 2.4h\n",
    "[ 24, 6, 3, 648, 2592, 224, 216.4, 3.6388, 3.0564,  28000],# 2.3h\n",
    "[ 24, 6, 3, 648, 2592, 224, 216.4, 3.5540,+3.0244,  27000],# 2.3h\n",
    "[ 24, 6, 3, 648, 2592, 224, 216.4, 3.7050, 3.0509,  26000],# 2.2h\n",
    "[ 24, 6, 3, 648, 2592, 224, 216.4, 3.4749,+3.0244, 25000], # 2.1h\n",
    "[ 24, 6, 3, 648, 2592, 224, 216.4, 3.8283, 3.1427,  24000],# 2.0h\n",
    "[ 24, 6, 3, 648, 2592, 224, 216.4, 3.5570, 3.0378,  24000],# again\n",
    "[ 24, 6, 3, 648, 2592, 224, 216.4, 3.5942, 3.0331,  23000],# 1.9h\n",
    "[ 24, 6, 3, 648, 2592, 208, 211.9, 3.4745, 3.0330,  30000],# 2.5h\n",
    "[ 24, 6, 3, 648, 2592, 208, 211.9, 3.5496, 3.0343,  27000],# 3.6h\n",
    "[ 24, 6, 3, 648, 2592, 208, 211.9, 3.4753,+3.0273,  26000],# 3.5h\n",
    "[ 24, 6, 3, 648, 2592, 208, 211.9, 3.6584, 3.0385, 25000], # 3.3h\n",
    "[ 24, 6, 3, 648, 2592, 192, 207.4, 3.7913, 3.0387,  28000],# 3.5h\n",
    "[ 24, 6, 3, 648, 2592, 192, 207.4, 3.4842,+3.0254,  27000],# 3.4h\n",
    "[+24, 6, 3, 648, 2592, 192, 207.4, 3.4755,+3.0223,  26000],# 3.3h  minGemma-hidden_layers24-att_heads6-kv_heads3-hidden648-intermediate2592-head_dim192-T1024--2025-10-21-09-47.pth\n",
    "[ 24, 6, 3, 648, 2592, 192, 207.4, 3.5175, 3.0414, 25000], # 3.2h\n",
    "[ 24, 6, 3, 648, 2592, 176, 202.9, 3.6315, 3.0623,  30000],# 3.7h\n",
    "[ 24, 6, 3, 648, 2592, 176, 202.9, 3.4535,+3.0280,  29000],# 3.5h 15.4G\n",
    "[ 24, 6, 3, 648, 2592, 176, 202.9, 3.5515, 3.0315,  28000],# 3.4h 15.5G\n",
    "[ 24, 6, 3, 648, 2592, 176, 202.9, 3.4565,+3.0266,  27000],# 3.3h\n",
    "[ 24, 6, 3, 648, 2592, 176, 202.9, 3.5158, 3.0308,  26000],# 3.2h\n",
    "[ 24, 6, 3, 648, 2592, 176, 202.9, 3.5952,+3.0275, 25000], # 3.1h\n",
    "[ 24, 6, 3, 648, 2592, 176, 202.9, 3.5423,+3.0266,  24000],# 3.0h\n",
    "[ 24, 6, 3, 648, 2592, 176, 202.9, 3.7397, 3.0517,  23000],# 2.8h 14.5G\n",
    "[ 24, 6, 3, 648, 2592, 160, 198.5, 3.7170, 3.0566,  27000],# 3.2h\n",
    "[ 24, 6, 3, 648, 2592, 160, 198.5, 3.5103,+3.0266,  26000],# 3.1h\n",
    "[ 24, 6, 3, 648, 2592, 160, 198.5, 3.5228, 3.0335, 25000], # 3.0h\n",
    "\n",
    "[ 24, 6, 3, 600, 2400, 288, 208.6, 3.4888, 3.0343,  27000],# 4.1h\n",
    "[ 24, 6, 3, 600, 2400, 288, 208.6, 3.4928,+3.0301,  26000],# 3.9h\n",
    "[ 24, 6, 3, 600, 2400, 288, 208.6, 3.5373, 3.0344, 25000], # 3.8h\n",
    "[ 24, 6, 3, 600, 2400, 272, 204.5, 3.6742, 3.0849,  29000],# 4.3h\n",
    "[ 24, 6, 3, 600, 2400, 272, 204.5, 3.4142, 3.0305,  28000],# 4.1h\n",
    "[ 24, 6, 3, 600, 2400, 272, 204.5, 3.4649, 3.0314,  27000],# 4.0h\n",
    "[ 24, 6, 3, 600, 2400, 272, 204.5, 3.4640, 3.0305,  26000],# 3.8h\n",
    "[ 24, 6, 3, 600, 2400, 272, 204.5, 3.4794, 3.0317, 25000], # 3.7h 15.3G\n",
    "[ 24, 6, 3, 600, 2400, 256, 200.3, 3.4523, 3.0340,  27000],# 3.6h\n",
    "[ 24, 6, 3, 600, 2400, 256, 200.3, 3.4384,+3.0289,  26000],# 3.5h 15.6G\n",
    "[ 24, 6, 3, 600, 2400, 256, 200.3, 3.5011, 3.0357, 25000], # 3.3h\n",
    "[ 24, 6, 3, 600, 2400, 240, 196.2, 3.7229, 3.1082,  27000],# 3.6h\n",
    "[ 24, 6, 3, 600, 2400, 240, 196.2, 3.4862, 3.0309,  26000],# 3.5h\n",
    "[ 24, 6, 3, 600, 2400, 240, 196.2, 3.5377,+3.0287, 25000], # 3.3h\n",
    "[ 24, 6, 3, 600, 2400, 240, 196.2, 3.4952, 3.0317,  24000],# 3.2h\n",
    "[ 24, 6, 3, 600, 2400, 224, 192.1, 3.6787, 3.0893,  26000],# 3.3h\n",
    "[ 24, 6, 3, 600, 2400, 224, 192.1, 3.5426, 3.0348, 25000], # 3.2h\n",
    "[ 24, 6, 3, 600, 2400, 208, 187.9, 3.4767, 3.0334,  26000],# 3.2h\n",
    "[ 24, 6, 3, 600, 2400, 208, 187.9, 3.4585, 3.0320, 25000], # 3.1h\n",
    "[ 24, 6, 3, 600, 2400, 192, 183.8, 3.5544, 3.0351,  26000],# 3.0h\n",
    "[ 24, 6, 3, 600, 2400, 192, 183.8, 3.4983, 3.0319, 25000], # 2.9h\n",
    "[ 24, 6, 3, 600, 2400, 176, 179.6, 3.5521, 3.0389,  27000],# 3.1h\n",
    "[ 24, 6, 3, 600, 2400, 176, 179.6, 3.4519,+3.0250,  26000],# 2.9h\n",
    "[ 24, 6, 3, 600, 2400, 176, 179.6, 3.5452, 3.0324, 25000], # 2.8h\n",
    "[ 24, 6, 3, 600, 2400, 160, 175.5, 3.4522, 3.0322,  26000],# 2.9h\n",
    "[ 24, 6, 3, 600, 2400, 160, 175.5, 3.5109, 3.0303, 25000],\n",
    "[ 24, 6, 3, 600, 2400, 160, 175.5, 3.5010, 3.0304,  24000],# 2.6h 13.8G\n",
    "[ 24, 6, 3, 600, 2400, 160, 175.5, 3.4968, 3.0305,  23000],# 2.5h\n",
    "[ 24, 6, 3, 600, 2400, 160, 175.5, 3.5619, 3.0361,  22000],# 2.4h\n",
    "[ 24, 6, 3, 600, 2400, 144, 171.3, 3.4472, 3.0333, 25000], # 2.7h\n",
    "\n",
    "# 336 running\n",
    "[ 24, 6, 3, 552, 2208, 320, 192.0, 3.3756, 3.0395,  28000],# 4.3h 14.9G\n",
    "[ 24, 6, 3, 552, 2208, 320, 192.0, 3.3915, 3.0311,  27000],# 4.1h\n",
    "[ 24, 6, 3, 552, 2208, 320, 192.0, 3.4453,+3.0290, 26000], # 4.0h\n",
    "[ 24, 6, 3, 552, 2208, 320, 192.0, 3.4716,+3.0277,  25000],# 3.8h\n",
    "[ 24, 6, 3, 552, 2208, 320, 192.0, 3.4861, 3.0382,  24000],# 3.7h\n",
    "[ 24, 6, 3, 552, 2208, 304, 188.1, 3.5921, 3.0579,  28000],# 4.2h\n",
    "[ 24, 6, 3, 552, 2208, 304, 188.1, 3.3703,+3.0278, 27000], # 4.1h\n",
    "[ 24, 6, 3, 552, 2208, 304, 188.1, 3.4372,+3.0299, 26000], # 3.9h\n",
    "[ 24, 6, 3, 552, 2208, 304, 188.1, 3.4703, 3.0372,  25000],# 3.8h 14.9G\n",
    "[ 24, 6, 3, 552, 2208, 288, 184.3, 3.6930, 3.0630,  27000],# 4.0h\n",
    "[ 24, 6, 3, 552, 2208, 288, 184.3, 3.4049,+3.0292,  26000],# 3.8h\n",
    "[ 24, 6, 3, 552, 2208, 288, 184.3, 3.4491, 3.0350, 25000], # 3.7h 14.7G\n",
    "[ 24, 6, 3, 552, 2208, 272, 180.5, 3.4315, 3.0323,  26000],# 3.7h\n",
    "[ 24, 6, 3, 552, 2208, 272, 180.5, 3.6310, 3.0618, 25000], # 3.6h\n",
    "[ 24, 6, 3, 552, 2208, 256, 176.7, 3.5464, 3.0525,  27000],# 3.5h\n",
    "[ 24, 6, 3, 552, 2208, 256, 176.7, 3.4199, 3.0313,  26000],# 3.4h\n",
    "[ 24, 6, 3, 552, 2208, 256, 176.7, 3.4531,+3.0300, 25000], # 3.3h\n",
    "[ 24, 6, 3, 552, 2208, 256, 176.7, 3.4757, 3.0372,  24000],# 3.2h\n",
    "[ 24, 6, 3, 552, 2208, 240, 172.9, 3.3835, 3.0318,  27000],# 3.4h\n",
    "[ 24, 6, 3, 552, 2208, 240, 172.9, 3.3957, 3.0307,  26000],# 3.3h\n",
    "[ 24, 6, 3, 552, 2208, 240, 172.9, 3.4132,+3.0271, 25000], # 3.2h\n",
    "[ 24, 6, 3, 552, 2208, 240, 172.9, 3.4325,+3.0284,  24000],# 3.1h\n",
    "[ 24, 6, 3, 552, 2208, 240, 172.9, 3.5200, 3.0371,  23000],# 2.9h\n",
    "#\n",
    "# under construction (224)\n",
    "#\n",
    "[ 24, 6, 3, 552, 2208, 208, 165.2, 3.5625, 3.0910,  28000],# 3.3h\n",
    "[ 24, 6, 3, 552, 2208, 208, 165.2, 3.3543, 3.0315,  27000],# 3.2h\n",
    "[ 24, 6, 3, 552, 2208, 208, 165.2, 3.4024,+3.0296,  26000],# 3.1h\n",
    "[ 24, 6, 3, 552, 2208, 208, 165.2, 3.5917, 3.0588, 25000], # 3.0h\n",
    "[ 24, 6, 3, 552, 2208, 192, 161.4, 3.4378, 3.0361,  28000],# 3.1h\n",
    "[ 24, 6, 3, 552, 2208, 192, 161.4, 3.3821,+3.0295,  27000],# 3.0h\n",
    "[ 24, 6, 3, 552, 2208, 192, 161.4, 3.3854,+3.0289,  26000],# 2.9h 13.5G\n",
    "[ 24, 6, 3, 552, 2208, 192, 161.4, 3.4361, 3.0317, 25000], # 2.8h 13.4G\n",
    "[ 24, 6, 3, 552, 2208, 176, 157.6, 3.6110, 3.0858,  26000],# 2.8h\n",
    "[ 24, 6, 3, 552, 2208, 176, 157.6, 3.4508, 3.0372, 25000], # 2.8h\n",
    "[ 24, 6, 3, 552, 2208, 160, 153.8, 3.3916, 3.0349,  26000],# 2.8h\n",
    "[ 24, 6, 3, 552, 2208, 160, 153.8, 3.3996,+3.0294, 25000], # 2.6h\n",
    "[ 24, 6, 3, 552, 2208, 160, 153.8, 3.4622, 3.0395,  24000],# 2.5h\n",
    "[ 24, 6, 3, 552, 2208, 144, 150.0, 3.4077, 3.0340,  26000],# 2.6h\n",
    "[ 24, 6, 3, 552, 2208, 144, 150.0, 3.4122, 3.0348, 25000], # 2.6h 13.0G\n",
    "\n",
    "[ 24, 6, 3, 504, 2016, 288, 161.3, 3.3786, 3.0446,  26000],# 3.6h\n",
    "[ 24, 6, 3, 504, 2016, 288, 161.3, 3.4053, 3.0395, 25000], # 3.5h\n",
    "[ 24, 6, 3, 504, 2016, 272, 157.8, 3.3846, 3.0345,  26000],# 3.6h\n",
    "[ 24, 6, 3, 504, 2016, 272, 157.8, 3.3678, 3.0307, 25000], # 3.4h\n",
    "[ 24, 6, 3, 504, 2016, 272, 157.8, 3.4561, 3.0339,  24000],# 3.3h\n",
    "[ 24, 6, 3, 504, 2016, 256, 154.4, 3.3755, 3.0446,  26000],# 3.2h\n",
    "[ 24, 6, 3, 504, 2016, 256, 154.4, 3.3971, 3.0329, 25000], # 3.1h\n",
    "[ 24, 6, 3, 504, 2016, 240, 150.9, 3.3864, 3.0382,  26000],# 3.1h\n",
    "[ 24, 6, 3, 504, 2016, 240, 150.9, 3.3461, 3.0307, 25000], # 3.0h\n",
    "[ 24, 6, 3, 504, 2016, 240, 150.9, 3.3879, 3.0361,  24000],# 2.9h\n",
    "[ 24, 6, 3, 504, 2016, 224, 147.4, 3.4087, 3.0391,  26000],# 3.0h\n",
    "[ 24, 6, 3, 504, 2016, 224, 147.4, 3.3778, 3.0345, 25000], # 2.9h 13.1G\n",
    "[ 24, 6, 3, 504, 2016, 208, 143.9, 3.4110, 3.0399,  26000],# 2.9h 13.0G\n",
    "[ 24, 6, 3, 504, 2016, 208, 143.9, 3.3591, 3.0357, 25000], # 2.8h\n",
    "[ 24, 6, 3, 504, 2016, 192, 140.4, 3.4878, 3.0474,  26000],# 2.8h\n",
    "[ 24, 6, 3, 504, 2016, 192, 140.4, 3.3518, 3.0399, 25000], # 2.6h\n",
    "[ 24, 6, 3, 504, 2016, 176, 136.9, 3.3742, 3.0385,  26000],# 2.7h\n",
    "[ 24, 6, 3, 504, 2016, 176, 136.9, 3.4051, 3.0386, 25000], # 2.6h\n",
    "[ 24, 6, 3, 504, 2016, 160, 133.5, 3.5473, 3.0718,  26000],# 2.5h\n",
    "[ 24, 6, 3, 504, 2016, 160, 133.5, 3.3527, 3.0317, 25000], # 2.5h\n",
    "\n",
    "# old param w/ Grad-Acc\n",
    "[ 24, 6, 3, 648, 2592, 240, 220.9, 3.0116, 3.3005, 39200], # B12 lr13.5e-4 WD1.0 5.5h 15.5G\n",
    "[ 24, 6, 3, 648, 2592, 240, 220.9, 3.5835, 3.1109, 20000], # B12 lr13.5e-4 WD1.0 2.8h\n",
    "\n",
    "\n",
    "# local best for H5(1): 3.0241  (bad, but no 5(2) or 5(3) and 5(5) also seems bad?)\n",
    "[ 24, 5, 1, 800, 3200, 288, 291.1, 3.9791, 3.0675, 25000], # 4.0h\n",
    "[ 24, 5, 1, 800, 3200, 272, 287.4, 3.7111, 3.0348, 25000], # 3.9h\n",
    "[ 24, 5, 1, 800, 3200, 256, 283.7, 3.7590, 3.0450,  26000],# 3.7h\n",
    "[ 24, 5, 1, 800, 3200, 256, 283.7, 3.7142,+3.0307, 25000], # 3.6h 17.4G\n",
    "[ 24, 5, 1, 800, 3200, 256, 283.7, 3.7283, 3.0373,  24000],# 3.4h\n",
    "[ 24, 5, 1, 800, 3200, 240, 280.0, 3.6521, 3.0391, 25000], # 3.5h\n",
    "[ 24, 5, 1, 800, 3200, 224, 276.3, 3.7273, 3.0428, 25000], # 3.4h\n",
    "[ 24, 5, 1, 800, 3200, 208, 272.7, 3.8250, 3.0559, 25000], # 3.4h\n",
    "[ 24, 5, 1, 800, 3200, 192, 269.0, 3.8883, 3.0659, 25000], # 3.2h\n",
    "[ 24, 5, 1, 800, 3200, 176, 265.3, 3.8772, 3.0694, 25000], # 3.2h\n",
    "[ 24, 5, 1, 800, 3200, 160, 261.6, 3.8706, 3.0623, 25000], # 3.1h\n",
    "\n",
    "[ 24, 5, 1, 760, 3040, 288, 267.8, 3.7706, 3.0436, 25000], # 3.7h\n",
    "[ 24, 5, 1, 760, 3040, 272, 264.3, 3.6970, 3.0470, 25000], # 3.6h\n",
    "[ 24, 5, 1, 760, 3040, 256, 260.8, 3.6709, 3.0390, 25000], # 3.3h\n",
    "[ 24, 5, 1, 760, 3040, 240, 257.3, 3.8985, 3.0548, 25000], # 3.3h\n",
    "[ 24, 5, 1, 760, 3040, 224, 253.8, 3.6482, 3.0310, 25000], # 3.2h\n",
    "[ 24, 5, 1, 760, 3040, 208, 250.3, 3.7163, 3.0427, 25000], # 3.1h\n",
    "[ 24, 5, 1, 760, 3040, 192, 246.8, 3.5932, 3.0338, 25000], # 3.0h 16.5G\n",
    "[ 24, 5, 1, 760, 3040, 176, 243.3, 3.8094, 3.0788, 25000], # 2.9h\n",
    "[ 24, 5, 1, 760, 3040, 160, 239.8, 3.5559, 3.0367, 25000], # 2.8h\n",
    "[ 24, 5, 1, 760, 3040, 144, 236.3, 3.5618, 3.0360, 25000], # 2.8h\n",
    "\n",
    "[ 24, 5, 1, 720, 2880, 288, 245.4, 3.5367, 3.0328, 25000], # 3.6h\n",
    "[ 24, 5, 1, 720, 2880, 272, 242.1, 3.7251, 3.0342, 25000], # 3.6h\n",
    "[ 24, 5, 1, 720, 2880, 256, 238.8, 3.8633, 3.0655, 25000], # 3.3h\n",
    "[ 24, 5, 1, 720, 2880, 240, 235.4, 3.7989, 3.0536,  26000],# 3.4h 16.5G\n",
    "[ 24, 5, 1, 720, 2880, 240, 235.4, 3.6030,+3.0298, 25000], # 3.2h\n",
    "[ 24, 5, 1, 720, 2880, 240, 235.4, 3.9382, 3.1176,  24000],# 3.1h\n",
    "[ 24, 5, 1, 720, 2880, 224, 232.1, 3.6438, 3.0435, 25000], # 3.1h\n",
    "[ 24, 5, 1, 720, 2880, 208, 228.8, 3.9508, 3.1494, 25000], # 3.1h\n",
    "[ 24, 5, 1, 720, 2880, 192, 225.5, 3.5713, 3.0333,  27000],# 3.2h\n",
    "[ 24, 5, 1, 720, 2880, 192, 225.5, 3.5642,+3.0273,  26000],# 3.1h\n",
    "[ 24, 5, 1, 720, 2880, 192, 225.5, 3.5719,+3.0287, 25000], # 2.9h\n",
    "[ 24, 5, 1, 720, 2880, 192, 225.5, 3.5915,+3.0297,  24000],# 2.8h\n",
    "[ 24, 5, 1, 720, 2880, 192, 225.5, 3.6735, 3.0396,  23000],# 2.7h\n",
    "[ 24, 5, 1, 720, 2880, 176, 222.2, 3.7280, 3.0520, 25000], # 2.9h\n",
    "[ 24, 5, 1, 720, 2880, 160, 218.9, 3.4985, 3.0338,  26000],# 2.9h\n",
    "[ 24, 5, 1, 720, 2880, 160, 218.9, 3.5316,+3.0282, 25000],\n",
    "[ 24, 5, 1, 720, 2880, 160, 218.9, 3.5872, 3.0306,  24000],# 2.7h\n",
    "[ 24, 5, 1, 720, 2880, 160, 218.9, 3.6218, 3.0332,  23000],# 2.5h\n",
    "[ 24, 5, 1, 720, 2880, 144, 215.5, 3.6452, 3.0364,  26000],# 2.8h\n",
    "[ 24, 5, 1, 720, 2880, 144, 215.5, 3.5876,+3.0268, 25000], # 2.7h 15.9G\n",
    "[ 24, 5, 1, 720, 2880, 144, 215.5, 3.6391, 3.0374,  24000],# 2.6h\n",
    "[ 24, 5, 1, 720, 2880, 128, 212.2, 3.5824, 3.0359, 25000], # 2.2h\n",
    "\n",
    "[ 24, 5, 1, 680, 2720, 288, 223.9, 3.6240, 3.0350, 25000], # 3.5h\n",
    "[ 24, 5, 1, 680, 2720, 272, 220.8, 3.5919, 3.0319, 25000], # 3.5h\n",
    "[ 24, 5, 1, 680, 2720, 256, 217.7, 3.6395, 3.0379, 25000], # 3.2h\n",
    "[ 24, 5, 1, 680, 2720, 240, 214.5, 3.5936, 3.0332,  27000],# 3.4h 15.8G\n",
    "[ 24, 5, 1, 680, 2720, 240, 214.5, 3.5227,+3.0259,  26000],# 3.3h\n",
    "[ 24, 5, 1, 680, 2720, 240, 214.5, 3.5600, 3.0303, 25000], # 3.2h\n",
    "[ 24, 5, 1, 680, 2720, 240, 214.5, 3.7393, 3.0593,  24000],# 3.0h\n",
    "[ 24, 5, 1, 680, 2720, 224, 211.4, 3.5097, 3.0310,  26000],# 3.1h 14.9G\n",
    "[ 24, 5, 1, 680, 2720, 224, 211.4, 3.5378,+3.0285, 25000], # 3.0h\n",
    "[ 24, 5, 1, 680, 2720, 224, 211.4, 3.5354, 3.0337,  24000],# 2.9h\n",
    "[ 24, 5, 1, 680, 2720, 208, 208.3, 3.5149, 3.0319,  26000],# 3.1h\n",
    "[ 24, 5, 1, 680, 2720, 208, 208.3, 3.5257,+3.0305, 25000], # 3.0h\n",
    "[ 24, 5, 1, 680, 2720, 208, 208.3, 3.5889, 3.0335,  24000],# 2.9h\n",
    "[ 24, 5, 1, 680, 2720, 192, 205.1, 3.7785, 3.0806,  26000],# 3.0h\n",
    "[ 24, 5, 1, 680, 2720, 192, 205.1, 3.5343,+3.0254, 25000], # 2.8h\n",
    "[ 24, 5, 1, 680, 2720, 192, 205.1, 3.5610, 3.0340,  24000],# 2.7h\n",
    "[ 24, 5, 1, 680, 2720, 176, 202.0, 3.6771, 3.0338, 25000], # 2.8h\n",
    "[ 24, 5, 1, 680, 2720, 160, 198.9, 3.5421, 3.0326, 25000], # 2.7h\n",
    "[ 24, 5, 1, 680, 2720, 144, 195.7, 3.5942, 3.0360, 25000], # 2.6h\n",
    "\n",
    "[ 24, 5, 1, 640, 2560, 288, 203.4, 3.8216, 3.0762, 25000], # 3.3h 16.1G\n",
    "[ 24, 5, 1, 640, 2560, 272, 200.4, 3.7825, 3.0865, 25000], # 3.3h 15.0G\n",
    "[ 24, 5, 1, 640, 2560, 256, 197.5, 3.4309, 3.0320, 25000], # 2.9h\n",
    "[ 24, 5, 1, 640, 2560, 240, 194.5, 3.8498, 3.2166,  26000],# 3.0h 14.3G\n",
    "[ 24, 5, 1, 640, 2560, 240, 194.5, 3.5126,+3.0293, 25000], # 2.9h\n",
    "[ 24, 5, 1, 640, 2560, 240, 194.5, 3.5366, 3.0320,  24000],# 2.8h\n",
    "[ 24, 5, 1, 640, 2560, 224, 191.6, 3.6997, 3.0770, 25000], # 2.8h\n",
    "[ 24, 5, 1, 640, 2560, 208, 188.6, 3.6423, 3.0472,  26000],# 2.9h 14.1G\n",
    "[ 24, 5, 1, 640, 2560, 208, 188.6, 3.5014,+3.0255, 25000], # 2.8h\n",
    "[ 24, 5, 1, 640, 2560, 208, 188.6, 3.5262, 3.0318,  24000],# 2.6h\n",
    "[ 24, 5, 1, 640, 2560, 192, 185.7, 3.8805, 3.0709, 25000], # 2.6h\n",
    "[ 24, 5, 1, 640, 2560, 176, 182.7, 3.7612, 3.0580, 25000], # 2.6h 14.0G\n",
    "[ 24, 5, 1, 640, 2560, 160, 179.8, 3.5146, 3.0383, 25000], # 2.5h\n",
    "\n",
    "[ 24, 5, 1, 600, 2400, 288, 183.8, 3.4966, 3.0351, 25000], # 3.3h\n",
    "[ 24, 5, 1, 600, 2400, 272, 181.0, 3.5749, 3.0446,  26000],# 3.3h\n",
    "[ 24, 5, 1, 600, 2400, 272, 181.0, 3.4482,+3.0292, 25000], # 3.2h\n",
    "[ 24, 5, 1, 600, 2400, 272, 181.0, 3.4980,+3.0298,  24000],# 3.1h\n",
    "[ 24, 5, 1, 600, 2400, 272, 181.0, 3.5000,+3.0241,  23000],# 3.0h  minGemma-hidden_layers24-att_heads5-kv_heads1-hidden600-intermediate2400-head_dim272-T1024--2025-09-19-13-11.pth\n",
    "[ 24, 5, 1, 600, 2400, 272, 181.0, 3.6401,+3.0263,  22000],# 2.8h\n",
    "[ 24, 5, 1, 600, 2400, 272, 181.0, 3.5115,+3.0294,  21000],# 2.7h\n",
    "[ 24, 5, 1, 600, 2400, 272, 181.0, 3.6574, 3.0409,  20000],# 2.5h\n",
    "[ 24, 5, 1, 600, 2400, 256, 178.2, 3.5230, 3.0349,  27000],# 3.1h\n",
    "[ 24, 5, 1, 600, 2400, 256, 178.2, 3.4200,+3.0271,  26000],# 3.0h\n",
    "[ 24, 5, 1, 600, 2400, 256, 178.2, 3.4381,+3.0295, 25000], # 2.9h\n",
    "[ 24, 5, 1, 600, 2400, 256, 178.2, 3.5948, 3.0437,  24000],# 2.8h\n",
    "[ 24, 5, 1, 600, 2400, 240, 175.5, 3.6023, 3.0423, 25000], # 2.8h\n",
    "[ 24, 5, 1, 600, 2400, 224, 172.7, 3.4819, 3.0354, 25000], # 2.8h\n",
    "[ 24, 5, 1, 600, 2400, 208, 169.9, 3.4861, 3.0337, 25000], # 2.7h\n",
    "[ 24, 5, 1, 600, 2400, 192, 167.2, 3.4922, 3.0319, 25000], # 2.6h 13.8G\n",
    "[ 24, 5, 1, 600, 2400, 176, 164.4, 3.4979, 3.0364,  26000],# 2.6h\n",
    "[ 24, 5, 1, 600, 2400, 176, 164.4, 3.4489, 3.0309, 25000], # 2.5h\n",
    "[ 24, 5, 1, 600, 2400, 176, 164.4, 3.4704, 3.0371,  24000],# 2.4h\n",
    "[ 24, 5, 1, 600, 2400, 160, 161.6, 3.5132, 3.0382, 25000], # 2.4h\n",
    "\n",
    "[ 24, 5, 1, 560, 2240, 288, 165.1, 3.4936, 3.0402, 25000], # 3.2h\n",
    "[ 24, 5, 1, 560, 2240, 272, 162.5, 3.5683, 3.0445, 25000], # 3.1h\n",
    "[ 24, 5, 1, 560, 2240, 256, 159.9, 3.4096, 3.0325,  26000],# 2.9h\n",
    "[ 24, 5, 1, 560, 2240, 256, 159.9, 3.3913, 3.0306, 25000], # 2.8h\n",
    "[ 24, 5, 1, 560, 2240, 256, 159.9, 3.6746, 3.0831,  24000],# 2.7h\n",
    "[ 24, 5, 1, 560, 2240, 240, 157.3, 3.4098, 3.0362,  27000],# 3.0h\n",
    "[ 24, 5, 1, 560, 2240, 240, 157.3, 3.3852,+3.0258,  26000],# 2.9h 13.7G\n",
    "[ 24, 5, 1, 560, 2240, 240, 157.3, 3.4426,+3.0282, 25000], # 2.8h\n",
    "[ 24, 5, 1, 560, 2240, 240, 157.3, 3.5236, 3.0326,  24000],# 2.6h 13.7G\n",
    "[ 24, 5, 1, 560, 2240, 224, 154.7, 3.4693, 3.0346, 25000], # 2.7h 13.5G\n",
    "[ 24, 5, 1, 560, 2240, 208, 152.2, 3.4195, 3.0343,  26000],# 2.7h 13.5G\n",
    "[ 24, 5, 1, 560, 2240, 208, 152.2, 3.4431, 3.0300, 25000], # 2.6h\n",
    "[ 24, 5, 1, 560, 2240, 208, 152.2, 3.4582, 3.0330,  24000],# 2.5h\n",
    "[ 24, 5, 1, 560, 2240, 192, 149.6, 3.3976, 3.0327, 25000], # 2.5h\n",
    "[ 24, 5, 1, 560, 2240, 176, 147.0, 3.4049, 3.0352,  26000],# 2.5h\n",
    "[ 24, 5, 1, 560, 2240, 176, 147.0, 3.4134,+3.0303, 25000], # 2.4h\n",
    "[ 24, 5, 1, 560, 2240, 176, 147.0, 3.4541, 3.0377,  24000],# 2.3h\n",
    "[ 24, 5, 1, 560, 2240, 160, 144.4, 3.3543, 3.0360,  28000],# 2.6h\n",
    "[ 24, 5, 1, 560, 2240, 160, 144.4, 3.4125,+3.0298,  27000],# 2.5h\n",
    "[ 24, 5, 1, 560, 2240, 160, 144.4, 3.3894,+3.0296,  26000],# 2.4h 12.9G\n",
    "[ 24, 5, 1, 560, 2240, 160, 144.4, 3.3967,+3.0283, 25000], # 2.3h\n",
    "[ 24, 5, 1, 560, 2240, 160, 144.4, 3.4682, 3.0361,  24000],# 2.2h\n",
    "[ 24, 5, 1, 560, 2240, 144, 141.8, 3.3849, 3.0428, 25000], # 2.3h\n",
    "\n",
    "[ 24, 5, 1, 520, 2080, 288, 147.3, 3.3508, 3.0346, 25000], # 3.1h 13.7G\n",
    "[ 24, 5, 1, 520, 2080, 272, 144.9, 3.3645, 3.0373, 25000], # 3.0h\n",
    "[ 24, 5, 1, 520, 2080, 256, 142.5, 3.3926, 3.0331, 25000], # 2.7h\n",
    "[ 24, 5, 1, 520, 2080, 240, 140.1, 3.3763, 3.0330, 25000], # 2.7h\n",
    "[ 24, 5, 1, 520, 2080, 224, 137.7, 3.3710, 3.0342, 25000], # 2.6h\n",
    "[ 24, 5, 1, 520, 2080, 208, 135.3, 3.3520, 3.0360, 25000], # 2.5h\n",
    "[ 24, 5, 1, 520, 2080, 192, 132.9, 3.3354, 3.0341, 25000], # 2.4h\n",
    "[ 24, 5, 1, 520, 2080, 176, 130.5, 3.4435, 3.0350, 25000], # 2.3h\n",
    "[ 24, 5, 1, 520, 2080, 160, 128.1, 3.4048, 3.0418, 25000], # 2.3h\n",
    "\n",
    "\n",
    "# local best for H4(2): 3.0235  (bad?)\n",
    "[ 24, 4, 2, 800, 3200, 288, 291.1, 3.9223, 3.0512, 25000], # 3.7h\n",
    "[ 24, 4, 2, 800, 3200, 272, 287.4, 3.8167, 3.0459, 25000], # 3.6h\n",
    "[ 24, 4, 2, 800, 3200, 256, 283.7, 3.8187, 3.0420, 25000], # 3.4h\n",
    "[ 24, 4, 2, 800, 3200, 240, 280.0, 4.0450, 3.0717, 25000], # 3.3h\n",
    "[ 24, 4, 2, 800, 3200, 224, 276.3, 3.7516, 3.0414, 25000], # 3.2h\n",
    "[ 24, 4, 2, 800, 3200, 208, 272.7, 3.7550, 3.0336, 25000], # 3.2h\n",
    "[ 24, 4, 2, 800, 3200, 192, 269.0, 3.7400, 3.0377, 25000], # 3.1h\n",
    "[ 24, 4, 2, 800, 3200, 176, 265.3, 3.7143, 3.0363, 25000], # 3.0h\n",
    "[ 24, 4, 2, 800, 3200, 160, 261.6, 3.7170, 3.0511, 25000], # 2.9h\n",
    "\n",
    "[ 24, 4, 2, 760, 3040, 288, 267.8, 3.8127, 3.0506, 25000], # 3.4h 16.8G\n",
    "[ 24, 4, 2, 760, 3040, 272, 264.3, 3.9319, 3.0903, 25000], # 3.3h\n",
    "[ 24, 4, 2, 760, 3040, 256, 260.8, 4.0003, 3.0728, 25000], # 3.1h\n",
    "[ 24, 4, 2, 760, 3040, 240, 257.3, 3.7127, 3.0435, 25000], # 3.1h\n",
    "[ 24, 4, 2, 760, 3040, 224, 253.8, 3.7847, 3.0399, 25000], # 3.0h\n",
    "[ 24, 4, 2, 760, 3040, 208, 250.3, 3.6594, 3.0343, 25000], # 2.9h\n",
    "[ 24, 4, 2, 760, 3040, 192, 246.8, 3.7715, 3.0478, 25000], # 2.8h\n",
    "[ 24, 4, 2, 760, 3040, 176, 243.3, 3.6788, 3.0408, 25000], # 2.7h\n",
    "[ 24, 4, 2, 760, 3040, 160, 239.8, 3.6272, 3.0333, 25000], # 2.7h 16.1G\n",
    "\n",
    "[ 24, 4, 2, 720, 2880, 288, 245.4, 3.6749, 3.0365, 25000], # 3.3h\n",
    "[ 24, 4, 2, 720, 2880, 272, 242.1, 3.9077, 3.0820, 25000], # 3.3h\n",
    "[ 24, 4, 2, 720, 2880, 256, 238.8, 3.6597, 3.0412, 25000], # 3.0h\n",
    "[ 24, 4, 2, 720, 2880, 240, 235.4, 3.7243, 3.0438, 25000], # 3.0h\n",
    "[ 24, 4, 2, 720, 2880, 224, 232.1, 3.6413, 3.0332, 25000], # 2.9h\n",
    "[ 24, 4, 2, 720, 2880, 208, 228.8, 3.8105, 3.0627,  26000],# 2.9h  # N24000,N26000 starts\n",
    "[ 24, 4, 2, 720, 2880, 208, 228.8, 3.6268,+3.0295, 25000], # 2.8h\n",
    "[ 24, 4, 2, 720, 2880, 208, 228.8, 3.7351, 3.0378,  24000],# 2.7h\n",
    "[ 24, 4, 2, 720, 2880, 192, 225.5, 3.6379, 3.0338,  26000],# 2.8h\n",
    "[ 24, 4, 2, 720, 2880, 192, 225.5, 3.7899, 3.0612, 25000], # 2.7h\n",
    "[ 24, 4, 2, 720, 2880, 192, 225.5, 3.6430, 3.0330,  24000],# 2.6h\n",
    "[ 24, 4, 2, 720, 2880, 176, 222.2, 3.6505, 3.0373,  26000],# 2.8h\n",
    "[ 24, 4, 2, 720, 2880, 176, 222.2, 3.6398, 3.0317, 25000], # 2.7h\n",
    "[ 24, 4, 2, 720, 2880, 176, 222.2, 3.6704, 3.0381,  24000],# 2.6h 15.8G\n",
    "[ 24, 4, 2, 720, 2880, 160, 218.9, 3.9013, 3.0966,  26000],# 2.7h 15.6G\n",
    "[ 24, 4, 2, 720, 2880, 160, 218.9, 3.6510, 3.0314, 25000], # 2.6h\n",
    "[ 24, 4, 2, 720, 2880, 160, 218.9, 3.6875, 3.0327,  24000],# 2.5h\n",
    "[ 24, 4, 2, 720, 2880, 144, 215.5, 3.6241, 3.0379, 25000], # 2.6h\n",
    "\n",
    "[ 24, 4, 2, 680, 2720, 288, 223.9, 3.6056, 3.0337,  26000],# 3.3h\n",
    "[ 24, 4, 2, 680, 2720, 288, 223.9, 3.7066, 3.0339, 25000], # 3.2h\n",
    "[ 24, 4, 2, 680, 2720, 288, 223.9, 3.8133, 3.0458,  24000],# 3.1h\n",
    "#\n",
    "# under construction (272)\n",
    "#\n",
    "[ 24, 4, 2, 680, 2720, 256, 217.7, 3.7882, 3.0424,  26000],# 3.0h 15.5G\n",
    "[ 24, 4, 2, 680, 2720, 256, 217.7, 3.6112,+3.0280, 25000], # 3.0h\n",
    "[ 24, 4, 2, 680, 2720, 256, 217.7, 3.6983, 3.0363,  24000],# 2.8h\n",
    "[ 24, 4, 2, 680, 2720, 240, 214.5, 3.9703, 3.1967,  26000],# 3.0h\n",
    "[ 24, 4, 2, 680, 2720, 240, 214.5, 3.6931, 3.0384, 25000], # 2.9h\n",
    "[ 24, 4, 2, 680, 2720, 240, 214.5, 3.5968, 3.0333,  24000],# 2.8h\n",
    "[ 24, 4, 2, 680, 2720, 224, 211.4, 3.5718, 3.0325,  26000],# 2.9h\n",
    "[ 24, 4, 2, 680, 2720, 224, 211.4, 3.5899,+3.0292, 25000], # 2.8h 14.6G\n",
    "[ 24, 4, 2, 680, 2720, 224, 211.4, 3.6444, 3.0365,  24000],# 2.7h\n",
    "[ 24, 4, 2, 680, 2720, 208, 208.3, 3.6587, 3.0349,  26000],# 2.8h\n",
    "[ 24, 4, 2, 680, 2720, 208, 208.3, 3.6247, 3.0364, 25000], # 2.7h\n",
    "[ 24, 4, 2, 680, 2720, 208, 208.3, 3.8928, 3.0983,  24000],# 2.6h\n",
    "[ 24, 4, 2, 680, 2720, 192, 205.1, 3.5762, 3.0447,  26000],# 2.7h 15.3G\n",
    "[ 24, 4, 2, 680, 2720, 192, 205.1, 3.6727, 3.0365, 25000], # 2.7h\n",
    "[ 24, 4, 2, 680, 2720, 192, 205.1, 3.6885, 3.0390,  24000],# 2.5h\n",
    "#\n",
    "# under construction (176)\n",
    "#\n",
    "[ 24, 4, 2, 680, 2720, 160, 198.9, 3.6333, 3.0389,  26000],# 2.6h\n",
    "[ 24, 4, 2, 680, 2720, 160, 198.9, 3.6090,+3.0266, 25000], # 2.5h\n",
    "[ 24, 4, 2, 680, 2720, 160, 198.9, 3.7926, 3.0470,  24000],# 2.4h\n",
    "[ 24, 4, 2, 680, 2720, 144, 195.7, 3.7420, 3.0497, 25000], # 2.5h\n",
    "\n",
    "#\n",
    "# under construction\n",
    "#\n",
    "\n",
    "[ 24, 4, 2, 600, 2400, 192, 167.2, 3.4815, 3.0320,  26000],# 2.5h\n",
    "[ 24, 4, 2, 600, 2400, 192, 167.2, 3.8295, 3.1725, 25000], # 2.4h\n",
    "[ 24, 4, 2, 600, 2400, 192, 167.2, 3.5299, 3.0333,  24000],# 2.3h\n",
    "[ 24, 4, 2, 600, 2400, 176, 164.4, 3.4776, 3.0343,  26000],# 2.4h\n",
    "[ 24, 4, 2, 600, 2400, 176, 164.4, 3.5053, 3.0302, 25000], # 2.3h\n",
    "[ 24, 4, 2, 600, 2400, 176, 164.4, 3.5141, 3.0359,  24000],# 2.2h\n",
    "[ 24, 4, 2, 600, 2400, 160, 161.6, 3.5064, 3.0334,  27000],# 2.4h\n",
    "[ 24, 4, 2, 600, 2400, 160, 161.6, 3.4618, 3.0311,  26000],# 2.3h\n",
    "[ 24, 4, 2, 600, 2400, 160, 161.6, 3.7082, 3.0532, 25000], # 2.3h\n",
    "[ 24, 4, 2, 600, 2400, 160, 161.6, 3.5508, 3.0382,  24000],# 2.2h\n",
    "\n",
    "[ 24, 4, 2, 560, 2240, 288, 165.1, 3.4326, 3.0349,  26000],# 2.9h\n",
    "[ 24, 4, 2, 560, 2240, 288, 165.1, 3.6335, 3.0649, 25000], # 2.9h\n",
    "[ 24, 4, 2, 560, 2240, 288, 165.1, 3.4592, 3.0321,  24000],# 2.7h\n",
    "[ 24, 4, 2, 560, 2240, 272, 162.5, 3.4243, 3.0331,  27000],# 3.0h\n",
    "[+24, 4, 2, 560, 2240, 272, 162.5, 3.4573,+3.0235,  26000],# 2.9h # minGemma-hidden_layers24-att_heads4-kv_heads2-hidden560-intermediate2240-head_dim272-T1024--2025-11-07-11-48.pth\n",
    "[ 24, 4, 2, 560, 2240, 272, 162.5, 3.5070, 3.0330, 25000], # 2.8h\n",
    "[ 24, 4, 2, 560, 2240, 272, 162.5, 3.4587, 3.0328,  24000],# 2.7h\n",
    "[ 24, 4, 2, 560, 2240, 256, 159.9, 3.4529, 3.0344,  26000],# 2.6h\n",
    "[ 24, 4, 2, 560, 2240, 256, 159.9, 3.5653, 3.0359, 25000], # 2.6h\n",
    "[ 24, 4, 2, 560, 2240, 256, 159.9, 3.5232, 3.0332,  24000],# 2.4h\n",
    "[ 24, 4, 2, 560, 2240, 240, 157.3, 3.5273, 3.0338,  26000],# 2.6h\n",
    "[ 24, 4, 2, 560, 2240, 240, 157.3, 3.4567,+3.0284, 25000], # 2.5h\n",
    "[ 24, 4, 2, 560, 2240, 240, 157.3, 3.5641, 3.0347,  24000],# 2.4h\n",
    "[ 24, 4, 2, 560, 2240, 224, 154.7, 3.4477, 3.0360,  26000],# 2.5h\n",
    "[ 24, 4, 2, 560, 2240, 224, 154.7, 3.5527, 3.0406, 25000], # 2.5h 13.3G\n",
    "[ 24, 4, 2, 560, 2240, 224, 154.7, 3.7516, 3.1076,  24000],# 2.3h\n",
    "[ 24, 4, 2, 560, 2240, 208, 152.2, 3.3997, 3.0338,  26000],# 2.5h\n",
    "[ 24, 4, 2, 560, 2240, 208, 152.2, 3.4400, 3.0333, 25000], # 2.4h\n",
    "[ 24, 4, 2, 560, 2240, 208, 152.2, 3.4738, 3.0440,  24000],# 2.3h\n",
    "[ 24, 4, 2, 560, 2240, 192, 149.6, 3.5405, 3.0443,  26000],# 2.4h\n",
    "[ 24, 4, 2, 560, 2240, 192, 149.6, 3.4239,+3.0290, 25000], # 2.3h\n",
    "[ 24, 4, 2, 560, 2240, 192, 149.6, 3.4409, 3.0336,  24000],# 2.2h\n",
    "[ 24, 4, 2, 560, 2240, 176, 147.0, 3.4026, 3.0328,  26000],# 2.3h\n",
    "[ 24, 4, 2, 560, 2240, 176, 147.0, 3.4617, 3.0310, 25000], # 2.2h\n",
    "[ 24, 4, 2, 560, 2240, 176, 147.0, 3.4726, 3.0331,  24000],# 2.1h\n",
    "[ 24, 4, 2, 560, 2240, 160, 144.4, 3.3794, 3.0330,  27000],# 2.3h\n",
    "[ 24, 4, 2, 560, 2240, 160, 144.4, 3.4529, 3.0314,  26000],# 2.2h\n",
    "[ 24, 4, 2, 560, 2240, 160, 144.4, 3.4880, 3.0332, 25000], # 2.2h\n",
    "[ 24, 4, 2, 560, 2240, 160, 144.4, 3.4517, 3.0368,  24000],# 2.1h\n",
    "\n",
    "[ 24, 4, 2, 520, 2080, 288, 147.3, 3.3764, 3.0353,  26000],# 2.9h\n",
    "[ 24, 4, 2, 520, 2080, 288, 147.3, 3.4136, 3.0350, 25000], # 2.8h\n",
    "[ 24, 4, 2, 520, 2080, 288, 147.3, 3.3940, 3.0335,  24000],# 2.7h\n",
    "[ 24, 4, 2, 520, 2080, 272, 144.9, 3.3707, 3.0327,  26000],# 2.8h\n",
    "[ 24, 4, 2, 520, 2080, 272, 144.9, 3.4147,+3.0278, 25000], # 2.8h\n",
    "[ 24, 4, 2, 520, 2080, 272, 144.9, 3.4398, 3.0391,  24000],# 2.6h # N24000,N26000 ends\n",
    "[ 24, 4, 2, 520, 2080, 256, 142.5, 3.4066, 3.0332, 25000], # 2.5h\n",
    "[ 24, 4, 2, 520, 2080, 240, 140.1, 3.4627, 3.0385, 25000], # 2.5h\n",
    "[ 24, 4, 2, 520, 2080, 224, 137.7, 3.3814, 3.0347, 25000], # 2.4h 13.0G\n",
    "[ 24, 4, 2, 520, 2080, 208, 135.3, 3.3854, 3.0403, 25000], # 2.3h\n",
    "[ 24, 4, 2, 520, 2080, 192, 132.9, 3.3814, 3.0364, 25000], # 2.2h\n",
    "[ 24, 4, 2, 520, 2080, 176, 130.5, 3.3965, 3.0399, 25000], # 2.2h\n",
    "[ 24, 4, 2, 520, 2080, 160, 128.1, 3.4082, 3.0423, 25000], # 2.1h\n",
    "\n",
    "[ 24, 4, 2, 500, 2000, 272, 136.4, 3.3986, 3.0368, 25000], # 2.7h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "4bfaea43-206a-411c-9713-35d03ee76d11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "159.744\n",
      "L24 att6 kv_heads3 hidden648 intermediate2592 head_dim192 T1024\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13000' max='13000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13000/13000 3:18:53, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>3.475500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 24, 6, 3, 648, 2592, 192, 207.4, 3.4755, 3.0223, 26000],\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt; import numpy as np; import time, torch; device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "from transformers import AutoTokenizer, TrainingArguments, DefaultDataCollator, Trainer\n",
    "vocab_size = 50257 # =tokenizer.vocab_size  # FIX!!! # G256128    ### T=256 for minGemma # G8192 for real Gemma\n",
    "num_hidden_layers =  24 # 8 # G28 G18 #blocks\n",
    "num_attention_heads = 6 # 4 # G16 G8\n",
    "num_key_value_heads = 3 # 4 # G16 G1\n",
    "hidden_size = num_attention_heads*108 # 128 # G3072 G2048 # embedding dimension\n",
    "intermediate_size = hidden_size*4 # x4 or x8 # time limiting factor #512 # G24576 G16384  # MLP inner dim\n",
    "head_dim = 192 # 32 # G256 # dim in attention # Doesn't affect time\n",
    "rms_norm_eps = 1e-6 # 1e-6\n",
    "rope_theta = 1000.0 # scale freq is small for S-model. 1000 might work too # G10000.0\n",
    "\n",
    "def apply_rotary_emb(x: torch.Tensor, dim: int) -> torch.Tensor: # seq_len = x.size(1) # N\n",
    "    freqs = 1.0 / (rope_theta ** (torch.arange(0, dim, 2, device=device).float() / dim)) # Dynamically compute frequency cis\n",
    "    t = torch.arange(x.size(1), device=device); freqs = torch.outer(t, freqs).float(); freqs_cis = torch.polar(torch.ones_like(freqs), freqs)  # complex64\n",
    "    x_ = torch.view_as_complex(torch.stack(torch.chunk(x.transpose(1, 2).float(), 2, dim=-1), dim=-1))\n",
    "    x_out = torch.view_as_real(x_ * freqs_cis.unsqueeze(0)).type_as(x)  # Ensure batch dimension is handled\n",
    "    x_out = torch.cat(torch.chunk(x_out, 2, dim=-1), dim=-2)\n",
    "    return x_out.reshape(x_out.shape[0], x_out.shape[1], x_out.shape[2], -1).transpose(1, 2)\n",
    "\n",
    "class RMSNorm(torch.nn.Module): # RMS:4.326552, RMS_no_weight:4.410741 # RMS':4.554899\n",
    "    def __init__(self, dim: int = hidden_size):\n",
    "        super().__init__(); self.weight = torch.nn.Parameter(torch.zeros(dim)) # one weight per feature to be learned\n",
    "    def _norm(self, x): # mean square for each feature (across the last dimension)\n",
    "        return x * torch.rsqrt(x.pow(2).mean(-1, keepdim=True) + rms_norm_eps)\n",
    "    def forward(self, x): # ensure the data type matches the input.\n",
    "        return self._norm(x.float()).type_as(x) * (1 + self.weight)\n",
    "        \n",
    "class GemmaAttention(torch.nn.Module): # MQA = K,V shared by 4Qs\n",
    "    def __init__(self):\n",
    "        super().__init__(); self.qkv_proj = torch.nn.Linear(hidden_size, (num_attention_heads + 2 * num_key_value_heads) * head_dim, bias=False); self.o_proj = torch.nn.Linear(num_attention_heads * head_dim, hidden_size, bias=False) # concatenated attention outputs back to the hidden size.\n",
    "    def forward(self, hidden_states: torch.Tensor,) -> torch.Tensor:  # in=(B, T, hidden_size)\n",
    "        batch_size, input_len, _ = hidden_states.shape\n",
    "        qkv = self.qkv_proj(hidden_states)\n",
    "        xq, xk, xv = qkv.split([num_attention_heads * head_dim, num_key_value_heads * head_dim, num_key_value_heads * head_dim],dim=-1)\n",
    "        xq = xq.view(batch_size, -1, num_attention_heads, head_dim); xk = xk.view(batch_size, -1, num_key_value_heads, head_dim); xv = xv.view(batch_size, -1, num_key_value_heads, head_dim)\n",
    "        xq = apply_rotary_emb(xq, head_dim); xk = apply_rotary_emb(xk, head_dim)\n",
    "        if num_key_value_heads != num_attention_heads:  # Q/KV multiples of K and V to match Q\n",
    "            xk = torch.repeat_interleave(xk, num_attention_heads // num_key_value_heads, dim=2) # [B, T, n_local_heads, head_dim]\n",
    "            xv = torch.repeat_interleave(xv, num_attention_heads // num_key_value_heads, dim=2)\n",
    "        q = xq.transpose(1, 2); k = xk.transpose(1, 2); v = xv.transpose(1, 2) # [batch_size, n_local_heads, input_len, head_dim]\n",
    "        output = torch.nn.functional.scaled_dot_product_attention(q, k, v, attn_mask=None, dropout_p=0, is_causal=True) # B nh T hs        \n",
    "        output = output.transpose(1, 2).contiguous().view(batch_size, input_len, -1)  # [B, T, \"hidden_dim\"]\n",
    "        return self.o_proj(output)\n",
    "\n",
    "class GemmaDecoderLayer(torch.nn.Module): # normalize before and after the attention mechanism\n",
    "    def __init__(self):\n",
    "        super().__init__(); self.self_attn = GemmaAttention(); self.input_layernorm = RMSNorm(); self.post_attention_layernorm = RMSNorm(); self.gate_proj = torch.nn.Linear(hidden_size, intermediate_size); self.up_proj = torch.nn.Linear(hidden_size, intermediate_size); self.down_proj = torch.nn.Linear(intermediate_size, hidden_size) # mlp\n",
    "    def forward(self, hidden_states: torch.Tensor) -> torch.Tensor:  # input_size = (B, T, hidden_size)\n",
    "        residual = hidden_states # Self Attention Block\n",
    "        hidden_states = self.input_layernorm(hidden_states); hidden_states = self.self_attn(hidden_states=hidden_states)\n",
    "        hidden_states = residual + hidden_states\n",
    "        residual = hidden_states # MLP Block\n",
    "        hidden_states = self.post_attention_layernorm(hidden_states); gate = torch.nn.functional.gelu(self.gate_proj(hidden_states)); up = self.up_proj(hidden_states); fuse = gate * up; hidden_states = self.down_proj(fuse) # mlp\n",
    "        return residual + hidden_states\n",
    "\n",
    "class minGemma(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__(); self.embedder = torch.nn.Embedding(vocab_size, hidden_size); self.layers = torch.nn.ModuleList(GemmaDecoderLayer() for _ in range(num_hidden_layers)); self.norm = RMSNorm();\n",
    "    def forward(self, input_token_ids: torch.Tensor) -> torch.Tensor: # (B, T)\n",
    "        hidden_states = self.embedder(input_token_ids[:,:-1]) # (B, T) & (vocab_size, hidden_size) -> (B, T, hidden_size)\n",
    "        hidden_states = hidden_states * (hidden_size**0.5)\n",
    "        for i in range(len(self.layers)):\n",
    "            hidden_states = self.layers[i](hidden_states) # shortened too much???\n",
    "        hidden_states = self.norm(hidden_states) # -> (B, T, hidden_size)        \n",
    "        embedder_weight = self.embedder.weight\n",
    "        logits = torch.matmul(hidden_states, embedder_weight.t()); b,t,v=logits.shape; # (B, T, hidden_size) @ (hidden_size, vocab_size) -> (B, T, vocab_size)\n",
    "        loss = torch.nn.functional.cross_entropy(logits.view(b*t,v), input_token_ids[:,1:].reshape(b*t)) #, weight=None, ignore_index=-100, reduction='mean')\n",
    "        return loss, logits # logits, loss\n",
    "\n",
    "def map_to_array5(ix):\n",
    "    common = torch.stack([torch.from_numpy((train_data[i[0]:i[0]+T+1]).astype(np.int64)) for i in ix]); return {'input_token_ids': common}\n",
    "def map_to_array_Val(ix):\n",
    "    common = torch.stack([torch.from_numpy((val_data[i[0]:i[0]+T+1]).astype(np.int64)) for i in ix]); return {'input_token_ids': common}\n",
    "\n",
    "train_data = np.memmap('train_BabyLM_10M.bin', dtype=np.uint16, mode='r'); val_data = np.memmap('val_BabyLM.bin', dtype=np.uint16, mode='r')\n",
    "T=1024; B=12//2; N_step=13000*2; print(T * B * N_step / 1000000) # 0.01 B-tokens being calculated # n_steps=N_step;\n",
    "model = minGemma().to(device); print(f'L{num_hidden_layers}' f' att{num_attention_heads}' f' kv_heads{num_key_value_heads}' f' hidden{hidden_size}' f' intermediate{intermediate_size}' f' head_dim{head_dim}' f' T{T}')\n",
    "\n",
    "# Normal # lr_scheduler_type=\"linear\" can be omitted\n",
    "training_args = TrainingArguments(gradient_accumulation_steps=2, learning_rate=24.0e-4, weight_decay=1.2, num_train_epochs=1, logging_strategy='epoch', output_dir='./', bf16=True, per_device_train_batch_size=B, per_device_eval_batch_size=B, eval_strategy='no', save_strategy='no', report_to='none', remove_unused_columns=False, dataloader_pin_memory=True) #, dataloader_num_workers=4\n",
    "trainer = Trainer(model=model, args=training_args, train_dataset=torch.utils.data.TensorDataset(torch.randint(len(train_data)-T-1, (B*N_step,))), data_collator=map_to_array5);\n",
    "result = trainer.train(); tloss=result[2][\"train_loss\"] # trainer = Trainer(model=model, args=training_args, eval_dataset=torch.utils.data.TensorDataset(torch.randint(len(val_data)-T-1, (B*400*4,))), data_collator=map_to_array_Val); trainer.can_return_loss = True; loss_current = trainer.evaluate()[\"eval_loss\"]\n",
    "\n",
    "loss = []; model.eval(); B2=16; B2=12//2; torch.cuda.empty_cache();\n",
    "for k in range(5000*2): #4000 # std=0.0056 for 1000 with 89sec\n",
    "    val_ind = torch.randint(len(val_data)-T-1, (B2,)); common = (torch.stack([torch.from_numpy((val_data[i:i+T+1]).astype(np.int64)) for i in val_ind]))\n",
    "    loss += [model(common.to('cuda', non_blocking=True))[0].item()]\n",
    "if torch.Tensor(loss).mean() < 3.0223:\n",
    "    torch.save(model.state_dict(), f'{model.__class__.__name__}' f'-hidden_layers{num_hidden_layers}' f'-att_heads{num_attention_heads}' f'-kv_heads{num_key_value_heads}' f'-hidden{hidden_size}' f'-intermediate{intermediate_size}' f'-head_dim{head_dim}' f'-T{T}' f'--{time.strftime(\"%Y-%m-%d-%H-%M\")}.pth')\n",
    "model.train(); del common; print(f'[ {num_hidden_layers}, {num_attention_heads}, {num_key_value_heads}, {hidden_size}, {intermediate_size}, {head_dim}, {sum(p.numel() for p in model.parameters()) / 10**6:.1f}, {tloss:.4f}, {torch.Tensor(loss).mean():.4f}, {N_step}],')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ea1e7f27-07d0-4d9f-9362-c274d38694ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "159.744\n",
      "L24 att6 kv_heads3 hidden648 intermediate2592 head_dim256 T1024\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13000' max='13000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13000/13000 3:46:28, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>3.610400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 24, 6, 3, 648, 2592, 256, 225.3, 3.6104, 3.0229, 26000],\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt; import numpy as np; import time, torch; device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "from transformers import AutoTokenizer, TrainingArguments, DefaultDataCollator, Trainer\n",
    "vocab_size = 50257 # =tokenizer.vocab_size  # FIX!!! # G256128    ### T=256 for minGemma # G8192 for real Gemma\n",
    "num_hidden_layers =  24 # 8 # G28 G18 #blocks\n",
    "num_attention_heads = 6 # 4 # G16 G8\n",
    "num_key_value_heads = 3 # 4 # G16 G1\n",
    "hidden_size = num_attention_heads*108 # 124 # 88 # 116 # 128 # G3072 G2048 # embedding dimension\n",
    "intermediate_size = hidden_size*4 # x4 or x8 # time limiting factor #512 # G24576 G16384  # MLP inner dim\n",
    "head_dim = 256 # 32 # G256 # dim in attention # Doesn't affect time\n",
    "rms_norm_eps = 1e-6 # 1e-6\n",
    "rope_theta = 1000.0 # scale freq is small for S-model. 1000 might work too # G10000.0\n",
    "\n",
    "def apply_rotary_emb(x: torch.Tensor, dim: int) -> torch.Tensor: # seq_len = x.size(1) # N\n",
    "    freqs = 1.0 / (rope_theta ** (torch.arange(0, dim, 2, device=device).float() / dim)) # Dynamically compute frequency cis\n",
    "    t = torch.arange(x.size(1), device=device); freqs = torch.outer(t, freqs).float(); freqs_cis = torch.polar(torch.ones_like(freqs), freqs)  # complex64\n",
    "    x_ = torch.view_as_complex(torch.stack(torch.chunk(x.transpose(1, 2).float(), 2, dim=-1), dim=-1))\n",
    "    x_out = torch.view_as_real(x_ * freqs_cis.unsqueeze(0)).type_as(x)  # Ensure batch dimension is handled\n",
    "    x_out = torch.cat(torch.chunk(x_out, 2, dim=-1), dim=-2)\n",
    "    return x_out.reshape(x_out.shape[0], x_out.shape[1], x_out.shape[2], -1).transpose(1, 2)\n",
    "\n",
    "class RMSNorm(torch.nn.Module): # RMS:4.326552, RMS_no_weight:4.410741 # RMS':4.554899\n",
    "    def __init__(self, dim: int = hidden_size):\n",
    "        super().__init__(); self.weight = torch.nn.Parameter(torch.zeros(dim)) # one weight per feature to be learned\n",
    "    def _norm(self, x): # mean square for each feature (across the last dimension)\n",
    "        return x * torch.rsqrt(x.pow(2).mean(-1, keepdim=True) + rms_norm_eps)\n",
    "    def forward(self, x): # ensure the data type matches the input.\n",
    "        return self._norm(x.float()).type_as(x) * (1 + self.weight)\n",
    "        \n",
    "class GemmaAttention(torch.nn.Module): # MQA = K,V shared by 4Qs\n",
    "    def __init__(self):\n",
    "        super().__init__(); self.qkv_proj = torch.nn.Linear(hidden_size, (num_attention_heads + 2 * num_key_value_heads) * head_dim, bias=False); self.o_proj = torch.nn.Linear(num_attention_heads * head_dim, hidden_size, bias=False) # concatenated attention outputs back to the hidden size.\n",
    "    def forward(self, hidden_states: torch.Tensor,) -> torch.Tensor:  # in=(B, T, hidden_size)\n",
    "        batch_size, input_len, _ = hidden_states.shape\n",
    "        qkv = self.qkv_proj(hidden_states)\n",
    "        xq, xk, xv = qkv.split([num_attention_heads * head_dim, num_key_value_heads * head_dim, num_key_value_heads * head_dim],dim=-1)\n",
    "        xq = xq.view(batch_size, -1, num_attention_heads, head_dim); xk = xk.view(batch_size, -1, num_key_value_heads, head_dim); xv = xv.view(batch_size, -1, num_key_value_heads, head_dim)\n",
    "        xq = apply_rotary_emb(xq, head_dim); xk = apply_rotary_emb(xk, head_dim)\n",
    "        if num_key_value_heads != num_attention_heads:  # Q/KV multiples of K and V to match Q\n",
    "            xk = torch.repeat_interleave(xk, num_attention_heads // num_key_value_heads, dim=2) # [B, T, n_local_heads, head_dim]\n",
    "            xv = torch.repeat_interleave(xv, num_attention_heads // num_key_value_heads, dim=2)\n",
    "        q = xq.transpose(1, 2); k = xk.transpose(1, 2); v = xv.transpose(1, 2) # [batch_size, n_local_heads, input_len, head_dim]\n",
    "        output = torch.nn.functional.scaled_dot_product_attention(q, k, v, attn_mask=None, dropout_p=0, is_causal=True) # B nh T hs        \n",
    "        output = output.transpose(1, 2).contiguous().view(batch_size, input_len, -1)  # [B, T, \"hidden_dim\"]\n",
    "        return self.o_proj(output)\n",
    "\n",
    "class GemmaDecoderLayer(torch.nn.Module): # normalize before and after the attention mechanism\n",
    "    def __init__(self):\n",
    "        super().__init__(); self.self_attn = GemmaAttention(); self.input_layernorm = RMSNorm(); self.post_attention_layernorm = RMSNorm(); self.gate_proj = torch.nn.Linear(hidden_size, intermediate_size); self.up_proj = torch.nn.Linear(hidden_size, intermediate_size); self.down_proj = torch.nn.Linear(intermediate_size, hidden_size) # mlp\n",
    "    def forward(self, hidden_states: torch.Tensor) -> torch.Tensor:  # input_size = (B, T, hidden_size)\n",
    "        residual = hidden_states # Self Attention Block\n",
    "        hidden_states = self.input_layernorm(hidden_states); hidden_states = self.self_attn(hidden_states=hidden_states)\n",
    "        hidden_states = residual + hidden_states\n",
    "        residual = hidden_states # MLP Block\n",
    "        hidden_states = self.post_attention_layernorm(hidden_states); gate = torch.nn.functional.gelu(self.gate_proj(hidden_states)); up = self.up_proj(hidden_states); fuse = gate * up; hidden_states = self.down_proj(fuse) # mlp\n",
    "        return residual + hidden_states\n",
    "\n",
    "class minGemma(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__(); self.embedder = torch.nn.Embedding(vocab_size, hidden_size); self.layers = torch.nn.ModuleList(GemmaDecoderLayer() for _ in range(num_hidden_layers)); self.norm = RMSNorm();\n",
    "    def forward(self, input_token_ids: torch.Tensor) -> torch.Tensor: # (B, T)\n",
    "        hidden_states = self.embedder(input_token_ids[:,:-1]) # (B, T) & (vocab_size, hidden_size) -> (B, T, hidden_size)\n",
    "        hidden_states = hidden_states * (hidden_size**0.5)\n",
    "        for i in range(len(self.layers)):\n",
    "            hidden_states = self.layers[i](hidden_states) # shortened too much???\n",
    "        hidden_states = self.norm(hidden_states) # -> (B, T, hidden_size)        \n",
    "        embedder_weight = self.embedder.weight\n",
    "        logits = torch.matmul(hidden_states, embedder_weight.t()); b,t,v=logits.shape; # (B, T, hidden_size) @ (hidden_size, vocab_size) -> (B, T, vocab_size)\n",
    "        loss = torch.nn.functional.cross_entropy(logits.view(b*t,v), input_token_ids[:,1:].reshape(b*t)) #, weight=None, ignore_index=-100, reduction='mean')\n",
    "        return loss, logits # logits, loss\n",
    "\n",
    "def map_to_array5(ix):\n",
    "    common = torch.stack([torch.from_numpy((train_data[i[0]:i[0]+T+1]).astype(np.int64)) for i in ix]); return {'input_token_ids': common}\n",
    "def map_to_array_Val(ix):\n",
    "    common = torch.stack([torch.from_numpy((val_data[i[0]:i[0]+T+1]).astype(np.int64)) for i in ix]); return {'input_token_ids': common}\n",
    "\n",
    "train_data = np.memmap('train_BabyLM_10M.bin', dtype=np.uint16, mode='r'); val_data = np.memmap('val_BabyLM.bin', dtype=np.uint16, mode='r')\n",
    "T=1024; B=12//2; N_step=13000*2; print(T * B * N_step / 1000000) # 0.01 B-tokens being calculated # n_steps=N_step;\n",
    "model = minGemma().to(device); print(f'L{num_hidden_layers}' f' att{num_attention_heads}' f' kv_heads{num_key_value_heads}' f' hidden{hidden_size}' f' intermediate{intermediate_size}' f' head_dim{head_dim}' f' T{T}')\n",
    "\n",
    "# Normal # lr_scheduler_type=\"linear\" can be omitted\n",
    "training_args = TrainingArguments(gradient_accumulation_steps=2, learning_rate=24.0e-4, weight_decay=1.2, num_train_epochs=1, logging_strategy='epoch', output_dir='./', bf16=True, per_device_train_batch_size=B, per_device_eval_batch_size=B, eval_strategy='no', save_strategy='no', report_to='none', remove_unused_columns=False, dataloader_pin_memory=True) #, dataloader_num_workers=4\n",
    "trainer = Trainer(model=model, args=training_args, train_dataset=torch.utils.data.TensorDataset(torch.randint(len(train_data)-T-1, (B*N_step,))), data_collator=map_to_array5);\n",
    "result = trainer.train(); tloss=result[2][\"train_loss\"] # trainer = Trainer(model=model, args=training_args, eval_dataset=torch.utils.data.TensorDataset(torch.randint(len(val_data)-T-1, (B*400*4,))), data_collator=map_to_array_Val); trainer.can_return_loss = True; loss_current = trainer.evaluate()[\"eval_loss\"]\n",
    "\n",
    "loss = []; model.eval(); B2=16; B2=12//2; torch.cuda.empty_cache();\n",
    "for k in range(5000*2): #4000 # std=0.0056 for 1000 with 89sec\n",
    "    val_ind = torch.randint(len(val_data)-T-1, (B2,)); common = (torch.stack([torch.from_numpy((val_data[i:i+T+1]).astype(np.int64)) for i in val_ind]))\n",
    "    loss += [model(common.to('cuda', non_blocking=True))[0].item()]\n",
    "if torch.Tensor(loss).mean() < 3.0229:\n",
    "    torch.save(model.state_dict(), f'{model.__class__.__name__}' f'-hidden_layers{num_hidden_layers}' f'-att_heads{num_attention_heads}' f'-kv_heads{num_key_value_heads}' f'-hidden{hidden_size}' f'-intermediate{intermediate_size}' f'-head_dim{head_dim}' f'-T{T}' f'--{time.strftime(\"%Y-%m-%d-%H-%M\")}.pth')\n",
    "model.train(); del common; print(f'[ {num_hidden_layers}, {num_attention_heads}, {num_key_value_heads}, {hidden_size}, {intermediate_size}, {head_dim}, {sum(p.numel() for p in model.parameters()) / 10**6:.1f}, {tloss:.4f}, {torch.Tensor(loss).mean():.4f}, {N_step}],')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80b2b3f9-5f23-488e-b2c8-9adf30fa7390",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141.312\n",
      "L24 att5 kv_heads1 hidden600 intermediate2400 head_dim272 T1024\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11500' max='11500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [11500/11500 2:58:34, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>11500</td>\n",
       "      <td>3.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 24, 5, 1, 600, 2400, 272, 181.0, 3.5000, 3.0241, 23000],\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt; import numpy as np; import time, torch; device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "from transformers import AutoTokenizer, TrainingArguments, DefaultDataCollator, Trainer\n",
    "vocab_size = 50257 # =tokenizer.vocab_size  # FIX!!! # G256128    ### T=256 for minGemma # G8192 for real Gemma\n",
    "num_hidden_layers =  24 # 8 # G28 G18 #blocks\n",
    "num_attention_heads = 5 # 4 # G16 G8\n",
    "num_key_value_heads = 1 # 4 # G16 G1\n",
    "hidden_size = num_attention_heads*120 # 128 # G3072 G2048 # embedding dimension\n",
    "intermediate_size = hidden_size*4 # x4 or x8 # time limiting factor #512 # G24576 G16384  # MLP inner dim\n",
    "head_dim = 272 # 32 # G256 # dim in attention # Doesn't affect time\n",
    "rms_norm_eps = 1e-6 # 1e-6\n",
    "rope_theta = 1000.0 # scale freq is small for S-model. 1000 might work too # G10000.0\n",
    "\n",
    "def apply_rotary_emb(x: torch.Tensor, dim: int) -> torch.Tensor: # seq_len = x.size(1) # N\n",
    "    freqs = 1.0 / (rope_theta ** (torch.arange(0, dim, 2, device=device).float() / dim)) # Dynamically compute frequency cis\n",
    "    t = torch.arange(x.size(1), device=device); freqs = torch.outer(t, freqs).float(); freqs_cis = torch.polar(torch.ones_like(freqs), freqs)  # complex64\n",
    "    x_ = torch.view_as_complex(torch.stack(torch.chunk(x.transpose(1, 2).float(), 2, dim=-1), dim=-1))\n",
    "    x_out = torch.view_as_real(x_ * freqs_cis.unsqueeze(0)).type_as(x)  # Ensure batch dimension is handled\n",
    "    x_out = torch.cat(torch.chunk(x_out, 2, dim=-1), dim=-2)\n",
    "    return x_out.reshape(x_out.shape[0], x_out.shape[1], x_out.shape[2], -1).transpose(1, 2)\n",
    "\n",
    "class RMSNorm(torch.nn.Module): # RMS:4.326552, RMS_no_weight:4.410741 # RMS':4.554899\n",
    "    def __init__(self, dim: int = hidden_size):\n",
    "        super().__init__(); self.weight = torch.nn.Parameter(torch.zeros(dim)) # one weight per feature to be learned\n",
    "    def _norm(self, x): # mean square for each feature (across the last dimension)\n",
    "        return x * torch.rsqrt(x.pow(2).mean(-1, keepdim=True) + rms_norm_eps)\n",
    "    def forward(self, x): # ensure the data type matches the input.\n",
    "        return self._norm(x.float()).type_as(x) * (1 + self.weight)\n",
    "        \n",
    "class GemmaAttention(torch.nn.Module): # MQA = K,V shared by 4Qs\n",
    "    def __init__(self):\n",
    "        super().__init__(); self.qkv_proj = torch.nn.Linear(hidden_size, (num_attention_heads + 2 * num_key_value_heads) * head_dim, bias=False); self.o_proj = torch.nn.Linear(num_attention_heads * head_dim, hidden_size, bias=False) # concatenated attention outputs back to the hidden size.\n",
    "    def forward(self, hidden_states: torch.Tensor,) -> torch.Tensor:  # in=(B, T, hidden_size)\n",
    "        batch_size, input_len, _ = hidden_states.shape\n",
    "        qkv = self.qkv_proj(hidden_states)\n",
    "        xq, xk, xv = qkv.split([num_attention_heads * head_dim, num_key_value_heads * head_dim, num_key_value_heads * head_dim],dim=-1)\n",
    "        xq = xq.view(batch_size, -1, num_attention_heads, head_dim); xk = xk.view(batch_size, -1, num_key_value_heads, head_dim); xv = xv.view(batch_size, -1, num_key_value_heads, head_dim)\n",
    "        xq = apply_rotary_emb(xq, head_dim); xk = apply_rotary_emb(xk, head_dim)\n",
    "        if num_key_value_heads != num_attention_heads:  # Q/KV multiples of K and V to match Q\n",
    "            xk = torch.repeat_interleave(xk, num_attention_heads // num_key_value_heads, dim=2) # [B, T, n_local_heads, head_dim]\n",
    "            xv = torch.repeat_interleave(xv, num_attention_heads // num_key_value_heads, dim=2)\n",
    "        q = xq.transpose(1, 2); k = xk.transpose(1, 2); v = xv.transpose(1, 2) # [batch_size, n_local_heads, input_len, head_dim]\n",
    "        output = torch.nn.functional.scaled_dot_product_attention(q, k, v, attn_mask=None, dropout_p=0, is_causal=True) # B nh T hs        \n",
    "        output = output.transpose(1, 2).contiguous().view(batch_size, input_len, -1)  # [B, T, \"hidden_dim\"]\n",
    "        return self.o_proj(output)\n",
    "\n",
    "class GemmaDecoderLayer(torch.nn.Module): # normalize before and after the attention mechanism\n",
    "    def __init__(self):\n",
    "        super().__init__(); self.self_attn = GemmaAttention(); self.input_layernorm = RMSNorm(); self.post_attention_layernorm = RMSNorm(); self.gate_proj = torch.nn.Linear(hidden_size, intermediate_size); self.up_proj = torch.nn.Linear(hidden_size, intermediate_size); self.down_proj = torch.nn.Linear(intermediate_size, hidden_size) # mlp\n",
    "    def forward(self, hidden_states: torch.Tensor) -> torch.Tensor:  # input_size = (B, T, hidden_size)\n",
    "        residual = hidden_states # Self Attention Block\n",
    "        hidden_states = self.input_layernorm(hidden_states); hidden_states = self.self_attn(hidden_states=hidden_states)\n",
    "        hidden_states = residual + hidden_states\n",
    "        residual = hidden_states # MLP Block\n",
    "        hidden_states = self.post_attention_layernorm(hidden_states); gate = torch.nn.functional.gelu(self.gate_proj(hidden_states)); up = self.up_proj(hidden_states); fuse = gate * up; hidden_states = self.down_proj(fuse) # mlp\n",
    "        return residual + hidden_states\n",
    "\n",
    "class minGemma(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__(); self.embedder = torch.nn.Embedding(vocab_size, hidden_size); self.layers = torch.nn.ModuleList(GemmaDecoderLayer() for _ in range(num_hidden_layers)); self.norm = RMSNorm();\n",
    "    def forward(self, input_token_ids: torch.Tensor) -> torch.Tensor: # (B, T)\n",
    "        hidden_states = self.embedder(input_token_ids[:,:-1]) # (B, T) & (vocab_size, hidden_size) -> (B, T, hidden_size)\n",
    "        hidden_states = hidden_states * (hidden_size**0.5)\n",
    "        for i in range(len(self.layers)):\n",
    "            hidden_states = self.layers[i](hidden_states) # shortened too much???\n",
    "        hidden_states = self.norm(hidden_states) # -> (B, T, hidden_size)        \n",
    "        embedder_weight = self.embedder.weight\n",
    "        logits = torch.matmul(hidden_states, embedder_weight.t()); b,t,v=logits.shape; # (B, T, hidden_size) @ (hidden_size, vocab_size) -> (B, T, vocab_size)\n",
    "        loss = torch.nn.functional.cross_entropy(logits.view(b*t,v), input_token_ids[:,1:].reshape(b*t)) #, weight=None, ignore_index=-100, reduction='mean')\n",
    "        return loss, logits # logits, loss\n",
    "\n",
    "def map_to_array5(ix):\n",
    "    common = torch.stack([torch.from_numpy((train_data[i[0]:i[0]+T+1]).astype(np.int64)) for i in ix]); return {'input_token_ids': common}\n",
    "def map_to_array_Val(ix):\n",
    "    common = torch.stack([torch.from_numpy((val_data[i[0]:i[0]+T+1]).astype(np.int64)) for i in ix]); return {'input_token_ids': common}\n",
    "\n",
    "train_data = np.memmap('train_BabyLM_10M.bin', dtype=np.uint16, mode='r'); val_data = np.memmap('val_BabyLM.bin', dtype=np.uint16, mode='r')\n",
    "T=1024; B=12//2; N_step=11500*2; print(T * B * N_step / 1000000) # 0.01 B-tokens being calculated # n_steps=N_step;\n",
    "model = minGemma().to(device); print(f'L{num_hidden_layers}' f' att{num_attention_heads}' f' kv_heads{num_key_value_heads}' f' hidden{hidden_size}' f' intermediate{intermediate_size}' f' head_dim{head_dim}' f' T{T}')\n",
    "\n",
    "# Normal # lr_scheduler_type=\"linear\" can be omitted\n",
    "training_args = TrainingArguments(gradient_accumulation_steps=2, learning_rate=24.0e-4, weight_decay=1.2, num_train_epochs=1, logging_strategy='epoch', output_dir='./', bf16=True, per_device_train_batch_size=B, per_device_eval_batch_size=B, eval_strategy='no', save_strategy='no', report_to='none', remove_unused_columns=False, dataloader_pin_memory=True) #, dataloader_num_workers=4\n",
    "trainer = Trainer(model=model, args=training_args, train_dataset=torch.utils.data.TensorDataset(torch.randint(len(train_data)-T-1, (B*N_step,))), data_collator=map_to_array5);\n",
    "result = trainer.train(); tloss=result[2][\"train_loss\"] # trainer = Trainer(model=model, args=training_args, eval_dataset=torch.utils.data.TensorDataset(torch.randint(len(val_data)-T-1, (B*400*4,))), data_collator=map_to_array_Val); trainer.can_return_loss = True; loss_current = trainer.evaluate()[\"eval_loss\"]\n",
    "\n",
    "loss = []; model.eval(); B2=16; B2=12//2; torch.cuda.empty_cache();\n",
    "for k in range(5000*2): #4000 # std=0.0056 for 1000 with 89sec\n",
    "    val_ind = torch.randint(len(val_data)-T-1, (B2,)); common = (torch.stack([torch.from_numpy((val_data[i:i+T+1]).astype(np.int64)) for i in val_ind]))\n",
    "    loss += [model(common.to('cuda', non_blocking=True))[0].item()]\n",
    "if torch.Tensor(loss).mean() < 3.0241:\n",
    "    torch.save(model.state_dict(), f'{model.__class__.__name__}' f'-hidden_layers{num_hidden_layers}' f'-att_heads{num_attention_heads}' f'-kv_heads{num_key_value_heads}' f'-hidden{hidden_size}' f'-intermediate{intermediate_size}' f'-head_dim{head_dim}' f'-T{T}' f'--{time.strftime(\"%Y-%m-%d-%H-%M\")}.pth')\n",
    "model.train(); del common; print(f'[ {num_hidden_layers}, {num_attention_heads}, {num_key_value_heads}, {hidden_size}, {intermediate_size}, {head_dim}, {sum(p.numel() for p in model.parameters()) / 10**6:.1f}, {tloss:.4f}, {torch.Tensor(loss).mean():.4f}, {N_step}],')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2d63a22e-df69-4768-9f16-8ba2d71f64f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "159.744\n",
      "L24 att4 kv_heads2 hidden560 intermediate2240 head_dim272 T1024\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13000' max='13000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13000/13000 2:56:23, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>3.457300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 24, 4, 2, 560, 2240, 272, 162.5, 3.4573, 3.0235, 26000],\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt; import numpy as np; import time, torch; device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "from transformers import AutoTokenizer, TrainingArguments, DefaultDataCollator, Trainer\n",
    "vocab_size = 50257 # =tokenizer.vocab_size  # FIX!!! # G256128    ### T=256 for minGemma # G8192 for real Gemma\n",
    "num_hidden_layers =  24 # 8 # G28 G18 #blocks\n",
    "num_attention_heads = 4 # 4 # G16 G8\n",
    "num_key_value_heads = 2 # 4 # G16 G1\n",
    "hidden_size = num_attention_heads*140 # 128 # G3072 G2048 # embedding dimension\n",
    "intermediate_size = hidden_size*4 # x4 or x8 # time limiting factor #512 # G24576 G16384  # MLP inner dim\n",
    "head_dim = 272 # 32 # G256 # dim in attention # Doesn't affect time\n",
    "rms_norm_eps = 1e-6 # 1e-6\n",
    "rope_theta = 1000.0 # scale freq is small for S-model. 1000 might work too # G10000.0\n",
    "\n",
    "def apply_rotary_emb(x: torch.Tensor, dim: int) -> torch.Tensor: # seq_len = x.size(1) # N\n",
    "    freqs = 1.0 / (rope_theta ** (torch.arange(0, dim, 2, device=device).float() / dim)) # Dynamically compute frequency cis\n",
    "    t = torch.arange(x.size(1), device=device); freqs = torch.outer(t, freqs).float(); freqs_cis = torch.polar(torch.ones_like(freqs), freqs)  # complex64\n",
    "    x_ = torch.view_as_complex(torch.stack(torch.chunk(x.transpose(1, 2).float(), 2, dim=-1), dim=-1))\n",
    "    x_out = torch.view_as_real(x_ * freqs_cis.unsqueeze(0)).type_as(x)  # Ensure batch dimension is handled\n",
    "    x_out = torch.cat(torch.chunk(x_out, 2, dim=-1), dim=-2)\n",
    "    return x_out.reshape(x_out.shape[0], x_out.shape[1], x_out.shape[2], -1).transpose(1, 2)\n",
    "\n",
    "class RMSNorm(torch.nn.Module): # RMS:4.326552, RMS_no_weight:4.410741 # RMS':4.554899\n",
    "    def __init__(self, dim: int = hidden_size):\n",
    "        super().__init__(); self.weight = torch.nn.Parameter(torch.zeros(dim)) # one weight per feature to be learned\n",
    "    def _norm(self, x): # mean square for each feature (across the last dimension)\n",
    "        return x * torch.rsqrt(x.pow(2).mean(-1, keepdim=True) + rms_norm_eps)\n",
    "    def forward(self, x): # ensure the data type matches the input.\n",
    "        return self._norm(x.float()).type_as(x) * (1 + self.weight)\n",
    "        \n",
    "class GemmaAttention(torch.nn.Module): # MQA = K,V shared by 4Qs\n",
    "    def __init__(self):\n",
    "        super().__init__(); self.qkv_proj = torch.nn.Linear(hidden_size, (num_attention_heads + 2 * num_key_value_heads) * head_dim, bias=False); self.o_proj = torch.nn.Linear(num_attention_heads * head_dim, hidden_size, bias=False) # concatenated attention outputs back to the hidden size.\n",
    "    def forward(self, hidden_states: torch.Tensor,) -> torch.Tensor:  # in=(B, T, hidden_size)\n",
    "        batch_size, input_len, _ = hidden_states.shape\n",
    "        qkv = self.qkv_proj(hidden_states)\n",
    "        xq, xk, xv = qkv.split([num_attention_heads * head_dim, num_key_value_heads * head_dim, num_key_value_heads * head_dim],dim=-1)\n",
    "        xq = xq.view(batch_size, -1, num_attention_heads, head_dim); xk = xk.view(batch_size, -1, num_key_value_heads, head_dim); xv = xv.view(batch_size, -1, num_key_value_heads, head_dim)\n",
    "        xq = apply_rotary_emb(xq, head_dim); xk = apply_rotary_emb(xk, head_dim)\n",
    "        if num_key_value_heads != num_attention_heads:  # Q/KV multiples of K and V to match Q\n",
    "            xk = torch.repeat_interleave(xk, num_attention_heads // num_key_value_heads, dim=2) # [B, T, n_local_heads, head_dim]\n",
    "            xv = torch.repeat_interleave(xv, num_attention_heads // num_key_value_heads, dim=2)\n",
    "        q = xq.transpose(1, 2); k = xk.transpose(1, 2); v = xv.transpose(1, 2) # [batch_size, n_local_heads, input_len, head_dim]\n",
    "        output = torch.nn.functional.scaled_dot_product_attention(q, k, v, attn_mask=None, dropout_p=0, is_causal=True) # B nh T hs        \n",
    "        output = output.transpose(1, 2).contiguous().view(batch_size, input_len, -1)  # [B, T, \"hidden_dim\"]\n",
    "        return self.o_proj(output)\n",
    "\n",
    "class GemmaDecoderLayer(torch.nn.Module): # normalize before and after the attention mechanism\n",
    "    def __init__(self):\n",
    "        super().__init__(); self.self_attn = GemmaAttention(); self.input_layernorm = RMSNorm(); self.post_attention_layernorm = RMSNorm(); self.gate_proj = torch.nn.Linear(hidden_size, intermediate_size); self.up_proj = torch.nn.Linear(hidden_size, intermediate_size); self.down_proj = torch.nn.Linear(intermediate_size, hidden_size) # mlp\n",
    "    def forward(self, hidden_states: torch.Tensor) -> torch.Tensor:  # input_size = (B, T, hidden_size)\n",
    "        residual = hidden_states # Self Attention Block\n",
    "        hidden_states = self.input_layernorm(hidden_states); hidden_states = self.self_attn(hidden_states=hidden_states)\n",
    "        hidden_states = residual + hidden_states\n",
    "        residual = hidden_states # MLP Block\n",
    "        hidden_states = self.post_attention_layernorm(hidden_states); gate = torch.nn.functional.gelu(self.gate_proj(hidden_states)); up = self.up_proj(hidden_states); fuse = gate * up; hidden_states = self.down_proj(fuse) # mlp\n",
    "        return residual + hidden_states\n",
    "\n",
    "class minGemma(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__(); self.embedder = torch.nn.Embedding(vocab_size, hidden_size); self.layers = torch.nn.ModuleList(GemmaDecoderLayer() for _ in range(num_hidden_layers)); self.norm = RMSNorm();\n",
    "    def forward(self, input_token_ids: torch.Tensor) -> torch.Tensor: # (B, T)\n",
    "        hidden_states = self.embedder(input_token_ids[:,:-1]) # (B, T) & (vocab_size, hidden_size) -> (B, T, hidden_size)\n",
    "        hidden_states = hidden_states * (hidden_size**0.5)\n",
    "        for i in range(len(self.layers)):\n",
    "            hidden_states = self.layers[i](hidden_states) # shortened too much???\n",
    "        hidden_states = self.norm(hidden_states) # -> (B, T, hidden_size)        \n",
    "        embedder_weight = self.embedder.weight\n",
    "        logits = torch.matmul(hidden_states, embedder_weight.t()); b,t,v=logits.shape; # (B, T, hidden_size) @ (hidden_size, vocab_size) -> (B, T, vocab_size)\n",
    "        loss = torch.nn.functional.cross_entropy(logits.view(b*t,v), input_token_ids[:,1:].reshape(b*t)) #, weight=None, ignore_index=-100, reduction='mean')\n",
    "        return loss, logits # logits, loss\n",
    "\n",
    "def map_to_array5(ix):\n",
    "    common = torch.stack([torch.from_numpy((train_data[i[0]:i[0]+T+1]).astype(np.int64)) for i in ix]); return {'input_token_ids': common}\n",
    "def map_to_array_Val(ix):\n",
    "    common = torch.stack([torch.from_numpy((val_data[i[0]:i[0]+T+1]).astype(np.int64)) for i in ix]); return {'input_token_ids': common}\n",
    "\n",
    "train_data = np.memmap('train_BabyLM_10M.bin', dtype=np.uint16, mode='r'); val_data = np.memmap('val_BabyLM.bin', dtype=np.uint16, mode='r')\n",
    "T=1024; B=12//2; N_step=13000*2; print(T * B * N_step / 1000000) # 0.01 B-tokens being calculated # n_steps=N_step;\n",
    "model = minGemma().to(device); print(f'L{num_hidden_layers}' f' att{num_attention_heads}' f' kv_heads{num_key_value_heads}' f' hidden{hidden_size}' f' intermediate{intermediate_size}' f' head_dim{head_dim}' f' T{T}')\n",
    "\n",
    "# Normal # lr_scheduler_type=\"linear\" can be omitted\n",
    "training_args = TrainingArguments(gradient_accumulation_steps=2, learning_rate=24.0e-4, weight_decay=1.2, num_train_epochs=1, logging_strategy='epoch', output_dir='./', bf16=True, per_device_train_batch_size=B, per_device_eval_batch_size=B, eval_strategy='no', save_strategy='no', report_to='none', remove_unused_columns=False, dataloader_pin_memory=True) #, dataloader_num_workers=4\n",
    "trainer = Trainer(model=model, args=training_args, train_dataset=torch.utils.data.TensorDataset(torch.randint(len(train_data)-T-1, (B*N_step,))), data_collator=map_to_array5);\n",
    "result = trainer.train(); tloss=result[2][\"train_loss\"] # trainer = Trainer(model=model, args=training_args, eval_dataset=torch.utils.data.TensorDataset(torch.randint(len(val_data)-T-1, (B*400*4,))), data_collator=map_to_array_Val); trainer.can_return_loss = True; loss_current = trainer.evaluate()[\"eval_loss\"]\n",
    "\n",
    "loss = []; model.eval(); B2=16; B2=12//2; torch.cuda.empty_cache();\n",
    "for k in range(5000*2): #4000 # std=0.0056 for 1000 with 89sec\n",
    "    val_ind = torch.randint(len(val_data)-T-1, (B2,)); common = (torch.stack([torch.from_numpy((val_data[i:i+T+1]).astype(np.int64)) for i in val_ind]))\n",
    "    loss += [model(common.to('cuda', non_blocking=True))[0].item()]\n",
    "if torch.Tensor(loss).mean() < 3.0235:\n",
    "    torch.save(model.state_dict(), f'{model.__class__.__name__}' f'-hidden_layers{num_hidden_layers}' f'-att_heads{num_attention_heads}' f'-kv_heads{num_key_value_heads}' f'-hidden{hidden_size}' f'-intermediate{intermediate_size}' f'-head_dim{head_dim}' f'-T{T}' f'--{time.strftime(\"%Y-%m-%d-%H-%M\")}.pth')\n",
    "model.train(); del common; print(f'[ {num_hidden_layers}, {num_attention_heads}, {num_key_value_heads}, {hidden_size}, {intermediate_size}, {head_dim}, {sum(p.numel() for p in model.parameters()) / 10**6:.1f}, {tloss:.4f}, {torch.Tensor(loss).mean():.4f}, {N_step}],')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3385e746-e34b-4478-8c54-b15f91dc4884",
   "metadata": {},
   "source": [
    "# L20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61602478-2ac4-4913-87d7-5ed67a2a27db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# L20 Normal Model T1024 (default: x4 B12 lr24e-4 WD1.2 N13000) w/ Grad_Acc\n",
    "# Best model for each number of heads:  5(1):3.0217, 6(3):3.0236\n",
    "\n",
    "# local best for H6(3): 3.0236  (not best)\n",
    "[ 20, 6, 3, 720, 2880, 256, 227.1, 3.6942, 3.0418, 25000], # 2.6h 15.4G # 272:out-VRAM\n",
    "[ 20, 6, 3, 720, 2880, 240, 223.0, 3.6549, 3.0314, 25000], # 2.5h 15.2G\n",
    "[ 20, 6, 3, 720, 2880, 224, 218.8, 3.6295, 3.0343, 25000], # 2.4h 15.2G\n",
    "[ 20, 6, 3, 720, 2880, 208, 214.7, 3.7463, 3.0344, 25000], # 2.4h\n",
    "[ 20, 6, 3, 720, 2880, 192, 210.5, 3.7557, 3.0375, 25000], # 2.3h\n",
    "[ 20, 6, 3, 720, 2880, 176, 206.4, 3.6120, 3.0348, 25000], # 2.2h\n",
    "\n",
    "[ 20, 6, 3, 696, 2784, 256, 215.5, 3.6183, 3.0380, 25000], # 2.6h 15.1G # 272:out-VRAM\n",
    "[ 20, 6, 3, 696, 2784, 240, 211.5, 3.6343, 3.0319, 25000], # 2.5h\n",
    "[ 20, 6, 3, 696, 2784, 224, 207.5, 3.6229, 3.0364, 25000], # 2.4h\n",
    "[ 20, 6, 3, 696, 2784, 208, 203.5, 3.6160, 3.0385, 25000], # 2.3h\n",
    "[ 20, 6, 3, 696, 2784, 192, 199.5, 3.8818, 3.0524, 25000], # 2.2h\n",
    "[ 20, 6, 3, 696, 2784, 176, 195.5, 3.6195, 3.0373, 25000], # 2.2h\n",
    "\n",
    "[ 20, 6, 3, 672, 2688, 272, 208.1, 3.5256, 3.0411,  31000],# 3.6h 15.5G\n",
    "[ 20, 6, 3, 672, 2688, 272, 208.1, 3.4916, 3.0307,  30000],# 3.3h\n",
    "[ 20, 6, 3, 672, 2688, 272, 208.1, 3.4796,+3.0279,  29000],# 3.2h 15.5G\n",
    "[ 20, 6, 3, 672, 2688, 272, 208.1, 3.8155, 3.0496,  28000],# 3.1h 15.5G\n",
    "[ 20, 6, 3, 672, 2688, 272, 208.1, 3.6562, 3.0345, 25000], # 2.8h 15.3G\n",
    "[ 20, 6, 3, 672, 2688, 256, 204.2, 3.5336, 3.0342,  31000],# 3.1h 15.0G\n",
    "[ 20, 6, 3, 672, 2688, 256, 204.2, 3.4540,+3.0284,  30000],# 3.0h 14.8G\n",
    "[ 20, 6, 3, 672, 2688, 256, 204.2, 3.6548,+3.0293,  29000],# 2.9h\n",
    "[ 20, 6, 3, 672, 2688, 256, 204.2, 3.7558, 3.0673,  28000],# 2.7h\n",
    "[ 20, 6, 3, 672, 2688, 256, 204.2, 3.6955, 3.0399,  27000],# 2.8h\n",
    "[ 20, 6, 3, 672, 2688, 256, 204.2, 3.6880, 3.0483,  26000],# 2.6h\n",
    "[ 20, 6, 3, 672, 2688, 256, 204.2, 3.6250,+3.0297, 25000], # 2.5h 14.8G\n",
    "[ 20, 6, 3, 672, 2688, 256, 204.2, 3.6109, 3.0374,  24000],# 2.4h\n",
    "[ 20, 6, 3, 672, 2688, 240, 200.4, 3.7100, 3.0810,  30000],# 2.9h 15.1G\n",
    "[ 20, 6, 3, 672, 2688, 240, 200.4, 3.5477, 3.0308,  26000],# 2.5h\n",
    "[ 20, 6, 3, 672, 2688, 240, 200.4, 3.5555,+3.0278, 25000], # 2.4h\n",
    "[ 20, 6, 3, 672, 2688, 240, 200.4, 3.6358, 3.0345,  24000],# 2.3h\n",
    "[ 20, 6, 3, 672, 2688, 224, 196.5, 3.5050, 3.0346,  30000],# 2.8h\n",
    "[ 20, 6, 3, 672, 2688, 224, 196.5, 3.6013, 3.0394, 25000], # 2.3h\n",
    "[ 20, 6, 3, 672, 2688, 208, 192.6, 3.4533, 3.0371,  33000],# 3.0h\n",
    "[ 20, 6, 3, 672, 2688, 208, 192.6, 3.4537, 3.0322,  32000],# 2.9h\n",
    "[ 20, 6, 3, 672, 2688, 208, 192.6, 3.4557, 3.0309,  31000],# 2.8h\n",
    "[ 20, 6, 3, 672, 2688, 208, 192.6, 3.4678,+3.0281,  30000],# 2.7h\n",
    "[ 20, 6, 3, 672, 2688, 208, 192.6, 3.4816,+3.0273,  29000],# 2.6h\n",
    "[ 20, 6, 3, 672, 2688, 208, 192.6, 3.4931,+3.0295,  28000],# 2.5h\n",
    "[ 20, 6, 3, 672, 2688, 208, 192.6, 3.6700, 3.0473,  27000],# 2.4h\n",
    "[ 20, 6, 3, 672, 2688, 208, 192.6, 3.5418, 3.0337,  26000],# 2.3h\n",
    "[ 20, 6, 3, 672, 2688, 208, 192.6, 3.6919, 3.0419, 25000], # 2.3h\n",
    "[ 20, 6, 3, 672, 2688, 208, 192.6, 3.6309, 3.0322,  24000],# 2.2h 14.0G\n",
    "[ 20, 6, 3, 672, 2688, 208, 192.6, 3.6489, 3.0416,  23000],# 2.1h\n",
    "[ 20, 6, 3, 672, 2688, 208, 192.6, 3.6445, 3.0365,  22000],# 2.0h\n",
    "[ 20, 6, 3, 672, 2688, 208, 192.6, 3.7072, 3.0389,  21000],# 1.9h\n",
    "[ 20, 6, 3, 672, 2688, 208, 192.6, 3.7217, 3.0375,  20000],# 1.8h\n",
    "[ 20, 6, 3, 672, 2688, 192, 188.8, 3.6728, 3.0612,  31000],# 2.7h 13.6G\n",
    "[ 20, 6, 3, 672, 2688, 192, 188.8, 3.4828,+3.0292,  30000],# 2.6h\n",
    "[ 20, 6, 3, 672, 2688, 192, 188.8, 3.4436, 3.0325,  29000],# 2.5h\n",
    "[ 20, 6, 3, 672, 2688, 192, 188.8, 3.6263, 3.0312,  28000],# 2.4h\n",
    "[ 20, 6, 3, 672, 2688, 192, 188.8, 3.7969, 3.0680,  27000],# 2.3h\n",
    "[ 20, 6, 3, 672, 2688, 192, 188.8, 3.7589, 3.0686,  26000],# 2.2h\n",
    "[ 20, 6, 3, 672, 2688, 192, 188.8, 3.5819, 3.0383, 25000], # 2.1h\n",
    "[ 20, 6, 3, 672, 2688, 176, 184.9, 3.5806, 3.0347,  30000],# 2.5h\n",
    "[ 20, 6, 3, 672, 2688, 176, 184.9, 3.5647, 3.0392, 25000], # 2.1h\n",
    "\n",
    "[ 20, 6, 3, 648, 2592, 272, 196.9, 3.6469, 3.0552,  30000],# 3.3h 14.3G\n",
    "[ 20, 6, 3, 648, 2592, 272, 196.9, 3.5354, 3.0350,  26000],# 2.8h\n",
    "[ 20, 6, 3, 648, 2592, 272, 196.9, 3.5606,+3.0297, 25000], # 2.8h 14.3G\n",
    "[ 20, 6, 3, 648, 2592, 272, 196.9, 3.5674, 3.0414,  24000],# 2.6h\n",
    "[ 20, 6, 3, 648, 2592, 256, 193.2, 3.7317, 3.0803,  31000],# 3.0h\n",
    "[ 20, 6, 3, 648, 2592, 256, 193.2, 3.4312,+3.0296,  30000],# 2.9h\n",
    "[ 20, 6, 3, 648, 2592, 256, 193.2, 3.5076, 3.0448,  29000],# 2.8h\n",
    "[ 20, 6, 3, 648, 2592, 256, 193.2, 3.6927, 3.0500, 25000], # 2.4h\n",
    "[ 20, 6, 3, 648, 2592, 240, 189.5, 3.7467, 3.0589,  32000],# 3.0h\n",
    "[ 20, 6, 3, 648, 2592, 240, 189.5, 3.4168, 3.0302,  31000],# 3.0h\n",
    "[ 20, 6, 3, 648, 2592, 240, 189.5, 3.4770, 3.0306,  30000],# 2.9h\n",
    "[ 20, 6, 3, 648, 2592, 240, 189.5, 3.5859, 3.0411,  29000],# 2.8h\n",
    "[ 20, 6, 3, 648, 2592, 240, 189.5, 3.5115,+3.0297,  28000],# 2.7h\n",
    "[ 20, 6, 3, 648, 2592, 240, 189.5, 3.5060,+3.0284,  27000],# 2.6h\n",
    "[ 20, 6, 3, 648, 2592, 240, 189.5, 3.5001, 3.0304,  26000],# 2.5h\n",
    "[ 20, 6, 3, 648, 2592, 240, 189.5, 3.5222,+3.0236, 25000], # 2.4h  minGemma-hidden_layers20-att_heads6-kv_heads3-hidden648-intermediate2592-head_dim240-T1024--2025-08-27-13-24.pth\n",
    "[ 20, 6, 3, 648, 2592, 240, 189.5, 3.6489, 3.0444,  24000],# 2.3h\n",
    "[ 20, 6, 3, 648, 2592, 240, 189.5, 3.6955, 3.0343,  23000],# 2.2h\n",
    "[ 20, 6, 3, 648, 2592, 240, 189.5, 3.6824, 3.0396,  22000],# 2.1h\n",
    "[ 20, 6, 3, 648, 2592, 240, 189.5, 3.6853, 3.0419,  21000],# 2.0h\n",
    "[ 20, 6, 3, 648, 2592, 240, 189.5, 3.8699, 3.0622,  20000],# 1.9h\n",
    "[ 20, 6, 3, 648, 2592, 224, 185.7, 3.5050, 3.0346,  30000],# 2.8h\n",
    "[ 20, 6, 3, 648, 2592, 224, 185.7, 3.5521, 3.0321, 25000], # 2.4h 13.6G\n",
    "[ 20, 6, 3, 648, 2592, 208, 182.0, 3.4243, 3.0319,  30000],# 2.7h\n",
    "[ 20, 6, 3, 648, 2592, 208, 182.0, 3.5503, 3.0319, 25000], # 2.2h\n",
    "[ 20, 6, 3, 648, 2592, 192, 178.3, 3.4517, 3.0357,  30000],# 2.6h\n",
    "[ 20, 6, 3, 648, 2592, 192, 178.3, 3.5452, 3.0395, 25000], # 2.1h\n",
    "[ 20, 6, 3, 648, 2592, 176, 174.5, 3.4364, 3.0374,  30000],# 2.5h\n",
    "[ 20, 6, 3, 648, 2592, 176, 174.5, 3.6128, 3.0455, 25000], # 2.1h\n",
    "\n",
    "[ 20, 6, 3, 624, 2496, 288, 189.6, 3.5943, 3.0320, 25000], # 2.7h\n",
    "[ 20, 6, 3, 624, 2496, 272, 186.1, 3.5192, 3.0304,  26000],# 2.8h\n",
    "[ 20, 6, 3, 624, 2496, 272, 186.1, 3.5142,+3.0286, 25000], # 2.6h\n",
    "[ 20, 6, 3, 624, 2496, 272, 186.1, 3.5505, 3.0353,  24000],# 2.5h\n",
    "[ 20, 6, 3, 624, 2496, 256, 182.5, 3.4321, 3.0346,  29000],# 2.7h\n",
    "[ 20, 6, 3, 624, 2496, 256, 182.5, 3.4990,+3.0301,  28000],# 2.7h 13.5G\n",
    "[ 20, 6, 3, 624, 2496, 256, 182.5, 3.4563,+3.0303,  27000],# 2.6h\n",
    "[ 20, 6, 3, 624, 2496, 256, 182.5, 3.5009,+3.0299,  26000],# 2.5h\n",
    "[ 20, 6, 3, 624, 2496, 256, 182.5, 3.4984,+3.0283, 25000], # 2.4h\n",
    "[ 20, 6, 3, 624, 2496, 256, 182.5, 3.6457,+3.0281,  24000],# 2.3h\n",
    "[ 20, 6, 3, 624, 2496, 256, 182.5, 3.5407,+3.0277,  23000],# 2.2h\n",
    "[ 20, 6, 3, 624, 2496, 256, 182.5, 3.6252, 3.0358,  22000],# 2.0h\n",
    "[ 20, 6, 3, 624, 2496, 240, 178.9, 3.7353, 3.1174,  27000],# 2.5h 13.3G\n",
    "[ 20, 6, 3, 624, 2496, 240, 178.9, 3.4894,+3.0288,  26000],# 2.4h\n",
    "[ 20, 6, 3, 624, 2496, 240, 178.9, 3.4574,+3.0298, 25000], # 2.3h\n",
    "[ 20, 6, 3, 624, 2496, 240, 178.9, 3.5883, 3.0339,  24000],# 2.2h\n",
    "[ 20, 6, 3, 624, 2496, 224, 175.3, 3.4852, 3.0321,  26000],# 2.3h\n",
    "[ 20, 6, 3, 624, 2496, 224, 175.3, 3.5194,+3.0267, 25000], # 2.2h\n",
    "[ 20, 6, 3, 624, 2496, 224, 175.3, 3.5206,+3.0282,  24000],# 2.2h\n",
    "[ 20, 6, 3, 624, 2496, 224, 175.3, 3.7930, 3.1049,  23000],# 2.0h\n",
    "[ 20, 6, 3, 624, 2496, 208, 171.7, 3.5226, 3.0378, 25000], # 2.2h\n",
    "[ 20, 6, 3, 624, 2496, 192, 168.1, 3.6433, 3.0594,  29000],# 2.5h\n",
    "[ 20, 6, 3, 624, 2496, 192, 168.1, 3.4767, 3.0309,  28000],# 2.3h\n",
    "[ 20, 6, 3, 624, 2496, 192, 168.1, 3.4899,+3.0287,  27000],# 2.2h\n",
    "[ 20, 6, 3, 624, 2496, 192, 168.1, 3.4670,+3.0287,  26000],# 2.1h\n",
    "[ 20, 6, 3, 624, 2496, 192, 168.1, 3.4865, 3.0301, 25000], # 2.1h\n",
    "[ 20, 6, 3, 624, 2496, 192, 168.1, 3.8544, 3.3674,  24000],# 2.0h\n",
    "[ 20, 6, 3, 624, 2496, 176, 164.5, 3.5243, 3.0362, 25000], # 2.0h\n",
    "\n",
    "[ 20, 6, 3, 600, 2400, 336, 189.3, 3.5513, 3.0401, 25000], # 3.0h\n",
    "[ 20, 6, 3, 600, 2400, 320, 185.8, 3.5373, 3.0414,  26000],# 2.9h\n",
    "[ 20, 6, 3, 600, 2400, 320, 185.8, 3.5813,+3.0295, 25000], # 2.8h\n",
    "[ 20, 6, 3, 600, 2400, 320, 185.8, 3.5734, 3.0352,  24000],# 2.7h\n",
    "[ 20, 6, 3, 600, 2400, 304, 182.4, 3.5274, 3.0391,  27000],# 3.0h\n",
    "[ 20, 6, 3, 600, 2400, 304, 182.4, 3.4641,+3.0250,  26000],# 2.9h 14.1G\n",
    "[ 20, 6, 3, 600, 2400, 304, 182.4, 3.4908, 3.0300, 25000], # 2.8h\n",
    "[ 20, 6, 3, 600, 2400, 304, 182.4, 3.5525, 3.0357,  24000],# 2.7h\n",
    "[ 20, 6, 3, 600, 2400, 288, 178.9, 3.4593, 3.0348,  28000],# 3.0h\n",
    "[ 20, 6, 3, 600, 2400, 288, 178.9, 3.4542,+3.0263,  27000],# 2.9h\n",
    "[ 20, 6, 3, 600, 2400, 288, 178.9, 3.4134,+3.0282,  26000],# 2.8h\n",
    "[ 20, 6, 3, 600, 2400, 288, 178.9, 3.4932,+3.0269, 25000], # 2.6h\n",
    "[ 20, 6, 3, 600, 2400, 288, 178.9, 3.5944, 3.0415,  24000],# 2.6h 14.2G\n",
    "[ 20, 6, 3, 600, 2400, 272, 175.4, 3.4718, 3.0316, 25000], # 2.6h\n",
    "[ 20, 6, 3, 600, 2400, 256, 172.0, 3.4876, 3.0363,  26000],# 2.4h\n",
    "[ 20, 6, 3, 600, 2400, 256, 172.0, 3.4750,+3.0295, 25000], # 2.4h\n",
    "[ 20, 6, 3, 600, 2400, 256, 172.0, 3.5254,+3.0256,  24000],# 2.2h\n",
    "[ 20, 6, 3, 600, 2400, 256, 172.0, 3.5261, 3.0316,  23000],# 2.1h\n",
    "[ 20, 6, 3, 600, 2400, 240, 168.5, 3.7047, 3.0628, 25000], # 2.3h\n",
    "[ 20, 6, 3, 600, 2400, 224, 165.1, 3.3463, 3.0320,  31000],# 2.7h 13.1G\n",
    "[ 20, 6, 3, 600, 2400, 224, 165.1, 3.3971, 3.0307,  30000],# 2.6h\n",
    "[ 20, 6, 3, 600, 2400, 224, 165.1, 3.3861,+3.0270,  29000],# 2.7h\n",
    "[ 20, 6, 3, 600, 2400, 224, 165.1, 3.4088,+3.0268,  28000],# 2.4h\n",
    "[ 20, 6, 3, 600, 2400, 224, 165.1, 3.4123,+3.0290,  27000],# 2.4h\n",
    "[ 20, 6, 3, 600, 2400, 224, 165.1, 3.4453,+3.0244,  26000],# 2.3h\n",
    "[ 20, 6, 3, 600, 2400, 224, 165.1, 3.5383,+3.0260, 25000], # 2.2h 13.2G\n",
    "[ 20, 6, 3, 600, 2400, 224, 165.1, 3.5015, 3.0332,  24000],# 2.1h\n",
    "[ 20, 6, 3, 600, 2400, 208, 161.6, 3.7451, 3.0964, 25000], # 2.1h\n",
    "[ 20, 6, 3, 600, 2400, 192, 158.2, 3.6468, 3.0537, 25000], # 2.0h\n",
    "[ 20, 6, 3, 600, 2400, 176, 154.7, 3.5075, 3.0399, 25000], # 2.0h\n",
    "\n",
    "[ 20, 6, 3, 576, 2304, 272, 165.1, 3.4618, 3.0335,  26000],# 2.7h\n",
    "[ 20, 6, 3, 576, 2304, 272, 165.1, 3.4675,+3.0290, 25000], # 2.6h\n",
    "[ 20, 6, 3, 576, 2304, 272, 165.1, 3.5223, 3.0330,  24000],# 2.5h\n",
    "[ 20, 6, 3, 576, 2304, 256, 161.8, 3.4485, 3.0335,  26000],# 2.4h\n",
    "[ 20, 6, 3, 576, 2304, 256, 161.8, 3.4632, 3.0309, 25000], # 2.3h\n",
    "[ 20, 6, 3, 576, 2304, 256, 161.8, 3.4804, 3.0390,  24000],# 2.2h\n",
    "[ 20, 6, 3, 576, 2304, 240, 158.5, 3.5064, 3.0395, 25000], # 2.2h\n",
    "[ 20, 6, 3, 576, 2304, 224, 155.2, 3.5869, 3.0519, 25000], # 2.2h\n",
    "[ 20, 6, 3, 576, 2304, 208, 151.8, 3.4791, 3.0378, 25000], # 2.1h\n",
    "[ 20, 6, 3, 576, 2304, 192, 148.5, 3.4489, 3.0345, 25000], # 2.0h 12.5G\n",
    "[ 20, 6, 3, 576, 2304, 176, 145.2, 3.4404, 3.0338, 25000], # 1.9h\n",
    "\n",
    "\n",
    "# local best for H5(1): 3.0217  (best)\n",
    "[ 20, 5, 1, 800, 3200, 256, 243.1, 3.8725, 3.0417, 25000], # 2.5h 15.6G\n",
    "[ 20, 5, 1, 800, 3200, 240, 240.1, 3.7708, 3.0501, 25000], # 2.4h 15.6G\n",
    "[ 20, 5, 1, 800, 3200, 224, 237.0, 3.6901, 3.0329, 25000], # 2.4h 15.5G\n",
    "[ 20, 5, 1, 800, 3200, 208, 233.9, 3.6378, 3.0325, 25000], # 2.3h\n",
    "[ 20, 5, 1, 800, 3200, 192, 230.8, 3.6649, 3.0372, 25000], # 2.2h\n",
    "[ 20, 5, 1, 800, 3200, 176, 227.8, 3.8232, 3.0430, 25000], # 10.8h\n",
    "[ 20, 5, 1, 800, 3200, 160, 224.7, 3.7345, 3.0373, 25000], # 2.1h\n",
    "\n",
    "[ 20, 5, 1, 760, 3040, 256, 223.7, 3.6264, 3.0340, 25000], # 14.4h\n",
    "[ 20, 5, 1, 760, 3040, 240, 220.8, 3.8837, 3.0967, 25000], # 2.2h\n",
    "[ 20, 5, 1, 760, 3040, 224, 217.8, 3.5811, 3.0365, 25000], # 2.1h\n",
    "[ 20, 5, 1, 760, 3040, 208, 214.9, 3.6560, 3.0376, 25000], # 2.1h\n",
    "[ 20, 5, 1, 760, 3040, 192, 212.0, 3.6258, 3.0319, 25000], # 2.0h\n",
    "[ 20, 5, 1, 760, 3040, 176, 209.1, 3.6061, 3.0361, 25000], # 2.0h\n",
    "[ 20, 5, 1, 760, 3040, 160, 206.2, 3.6426, 3.0406, 25000], # 1.9h\n",
    "\n",
    "[ 20, 5, 1, 720, 2880, 256, 205.0, 3.7699, 3.0464, 25000], # 2.2h\n",
    "[ 20, 5, 1, 720, 2880, 240, 202.2, 3.6679, 3.0384, 25000], # 2.1h\n",
    "[ 20, 5, 1, 720, 2880, 224, 199.5, 3.7516, 3.0435,  26000],# 2.2h\n",
    "[ 20, 5, 1, 720, 2880, 224, 199.5, 3.6248,+3.0276, 25000], # 2.1h 13.9G\n",
    "[ 20, 5, 1, 720, 2880, 224, 199.5, 3.6597,+3.0291,  24000],# 2.0h\n",
    "[ 20, 5, 1, 720, 2880, 224, 199.5, 3.6915, 3.0431,  23000],# 2.0h\n",
    "[ 20, 5, 1, 720, 2880, 208, 196.7, 3.5791, 3.0351, 25000], # 2.1h\n",
    "[ 20, 5, 1, 720, 2880, 192, 193.9, 3.7053, 3.0372, 25000], # 2.0h\n",
    "[ 20, 5, 1, 720, 2880, 176, 191.2, 3.5839, 3.0408,  26000],# 2.0h\n",
    "[ 20, 5, 1, 720, 2880, 176, 191.2, 3.5531,+3.0276, 25000], # 1.9h\n",
    "[ 20, 5, 1, 720, 2880, 176, 191.2, 3.6465, 3.0330,  24000],# 1.9h\n",
    "[ 20, 5, 1, 720, 2880, 160, 188.4, 3.6112, 3.0396, 25000], # 1.9h\n",
    "\n",
    "[ 20, 5, 1, 680, 2720, 256, 187.1, 3.5560, 3.0373,  27000],# 2.3h\n",
    "[ 20, 5, 1, 680, 2720, 256, 187.1, 3.5439,+3.0283,  26000],# 2.3h 13.5G\n",
    "[ 20, 5, 1, 680, 2720, 256, 187.1, 3.5201, 3.0303, 25000], # 2.2h\n",
    "[ 20, 5, 1, 680, 2720, 256, 187.1, 3.5684, 3.0334,  24000],# 2.1h\n",
    "[ 20, 5, 1, 680, 2720, 240, 184.5, 3.5353, 3.0331, 25000], # 2.1h\n",
    "[ 20, 5, 1, 680, 2720, 224, 181.9, 3.5159, 3.0319, 25000], # 2.1h\n",
    "[ 20, 5, 1, 680, 2720, 208, 179.2, 3.5072, 3.0315, 25000], # 2.0h\n",
    "[ 20, 5, 1, 680, 2720, 192, 176.6, 3.5054, 3.0321, 25000], # 1.9h\n",
    "[ 20, 5, 1, 680, 2720, 176, 174.0, 3.5225, 3.0378,  26000],# 2.0h\n",
    "[ 20, 5, 1, 680, 2720, 176, 174.0, 3.5162,+3.0287, 25000], # 1.9h\n",
    "[ 20, 5, 1, 680, 2720, 176, 174.0, 3.6882, 3.0480,  24000],# 1.8h\n",
    "[ 20, 5, 1, 680, 2720, 160, 171.4, 3.5556, 3.0360, 25000], # 1.8h 13.0G\n",
    "\n",
    "[ 20, 5, 1, 640, 2560, 256, 169.9, 3.5202, 3.0322, 25000], # 2.0h\n",
    "[ 20, 5, 1, 640, 2560, 240, 167.5, 3.6894, 3.0564, 25000], # 2.0h 13.2G\n",
    "[ 20, 5, 1, 640, 2560, 224, 165.0, 3.5624, 3.0348, 25000], # 1.9h\n",
    "[ 20, 5, 1, 640, 2560, 208, 162.6, 3.6549, 3.0493,  26000],# 2.0h\n",
    "[ 20, 5, 1, 640, 2560, 208, 162.6, 3.4319,+3.0294, 25000], # 1.9h\n",
    "[ 20, 5, 1, 640, 2560, 208, 162.6, 3.5223, 3.0316,  24000],# 1.8h\n",
    "[ 20, 5, 1, 640, 2560, 192, 160.1, 3.4747, 3.0318, 25000], # 1.8h\n",
    "[ 20, 5, 1, 640, 2560, 176, 157.6, 3.7068, 3.0625, 25000], # 1.8h\n",
    "[ 20, 5, 1, 640, 2560, 160, 155.2, 3.4876, 3.0383, 25000], # 1.7h\n",
    "\n",
    "[ 20, 5, 1, 600, 2400, 272, 155.9, 3.4779, 3.0328, 25000], # 2.2h\n",
    "[ 20, 5, 1, 600, 2400, 256, 153.6, 3.3805, 3.0370,  27000],# 2.2h\n",
    "[+20, 5, 1, 600, 2400, 256, 153.6, 3.3780,+3.0217,  26000],# 2.1h   minGemma-hidden_layers20-att_heads5-kv_heads1-hidden600-intermediate2400-head_dim256-T1024--2025-09-26-08-14.pth\n",
    "[ 20, 5, 1, 600, 2400, 256, 153.6, 3.4369, 3.0302, 25000], # 2.0h\n",
    "[ 20, 5, 1, 600, 2400, 256, 153.6, 3.5024, 3.0325,  24000],# 2.0h\n",
    "[ 20, 5, 1, 600, 2400, 240, 151.2, 3.4597, 3.0333,  26000],# 2.1h\n",
    "[ 20, 5, 1, 600, 2400, 240, 151.2, 3.4372, 3.0303, 25000], # 2.0h\n",
    "[ 20, 5, 1, 600, 2400, 240, 151.2, 3.4917, 3.0446,  24000],# 1.9h 13.0G\n",
    "[ 20, 5, 1, 600, 2400, 224, 148.9, 3.5229, 3.0390,  26000],# 2.0h\n",
    "[ 20, 5, 1, 600, 2400, 224, 148.9, 3.4340,+3.0295, 25000], # 1.9h\n",
    "[ 20, 5, 1, 600, 2400, 224, 148.9, 3.4612, 3.0350,  24000],# 1.8h\n",
    "[ 20, 5, 1, 600, 2400, 208, 146.6, 3.5711, 3.0454, 25000], # 1.9h 12.9G\n",
    "[ 20, 5, 1, 600, 2400, 192, 144.3, 3.4065, 3.0315, 25000], # 1.8h\n",
    "[ 20, 5, 1, 600, 2400, 176, 142.0, 3.5964, 3.0745,  26000],# 1.8h\n",
    "[ 20, 5, 1, 600, 2400, 176, 142.0, 3.4001,+3.0292, 25000], # 1.7h 12.5G\n",
    "[ 20, 5, 1, 600, 2400, 176, 142.0, 3.6606, 3.0569,  24000],# 1.7h\n",
    "[ 20, 5, 1, 600, 2400, 160, 139.7, 3.4716, 3.0376, 25000], # 1.7h\n",
    "\n",
    "[ 20, 5, 1, 560, 2240, 272, 140.1, 3.4183, 3.0350, 25000], # 2.2h\n",
    "[ 20, 5, 1, 560, 2240, 256, 137.9, 3.4175, 3.0360,  26000],# 2.0h\n",
    "[ 20, 5, 1, 560, 2240, 256, 137.9, 3.4386,+3.0294, 25000], # 1.9h\n",
    "[ 20, 5, 1, 560, 2240, 256, 137.9, 3.4377,+3.0287,  24000],# 1.9h\n",
    "[ 20, 5, 1, 560, 2240, 256, 137.9, 3.5394,+3.0292,  23000],# 1.8h\n",
    "[ 20, 5, 1, 560, 2240, 256, 137.9, 3.5971, 3.0384,  22000],# 1.7h\n",
    "[ 20, 5, 1, 560, 2240, 240, 135.8, 3.3878, 3.0334, 25000], # 1.9h\n",
    "[ 20, 5, 1, 560, 2240, 224, 133.6, 3.4220, 3.0355, 25000], # 1.8h\n",
    "[ 20, 5, 1, 560, 2240, 208, 131.5, 3.3709, 3.0344, 25000], # 1.8h\n",
    "[ 20, 5, 1, 560, 2240, 192, 129.3, 3.4105, 3.0390, 25000], # 1.7h\n",
    "[ 20, 5, 1, 560, 2240, 176, 127.2, 3.4046, 3.0379, 25000], # 1.7h\n",
    "[ 20, 5, 1, 560, 2240, 160, 125.0, 3.4128, 3.0391, 25000], # 1.6h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b30af576-ab2d-4fbf-9e4a-d6051a1f6168",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "159.744\n",
      "L20 att5 kv_heads1 hidden600 intermediate2400 head_dim256 T1024\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13000' max='13000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13000/13000 2:14:15, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>3.378000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 20, 5, 1, 600, 2400, 256, 153.6, 3.3780, 3.0217, 26000],\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt; import numpy as np; import time, torch; device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "from transformers import AutoTokenizer, TrainingArguments, DefaultDataCollator, Trainer\n",
    "vocab_size = 50257 # =tokenizer.vocab_size  # FIX!!! # G256128    ### T=256 for minGemma # G8192 for real Gemma\n",
    "num_hidden_layers =  20 # 8 # G28 G18 #blocks\n",
    "num_attention_heads = 5 # 4 # G16 G8\n",
    "num_key_value_heads = 1 # 4 # G16 G1\n",
    "hidden_size = num_attention_heads*120 # 128 # G3072 G2048 # embedding dimension\n",
    "intermediate_size = hidden_size*4 # x4 or x8 # time limiting factor #512 # G24576 G16384  # MLP inner dim\n",
    "head_dim = 256 # 32 # G256 # dim in attention # Doesn't affect time\n",
    "rms_norm_eps = 1e-6 # 1e-6\n",
    "rope_theta = 1000.0 # scale freq is small for S-model. 1000 might work too # G10000.0\n",
    "#240, 25000], #?\n",
    "def apply_rotary_emb(x: torch.Tensor, dim: int) -> torch.Tensor: # seq_len = x.size(1) # N\n",
    "    freqs = 1.0 / (rope_theta ** (torch.arange(0, dim, 2, device=device).float() / dim)) # Dynamically compute frequency cis\n",
    "    t = torch.arange(x.size(1), device=device); freqs = torch.outer(t, freqs).float(); freqs_cis = torch.polar(torch.ones_like(freqs), freqs)  # complex64\n",
    "    x_ = torch.view_as_complex(torch.stack(torch.chunk(x.transpose(1, 2).float(), 2, dim=-1), dim=-1))\n",
    "    x_out = torch.view_as_real(x_ * freqs_cis.unsqueeze(0)).type_as(x)  # Ensure batch dimension is handled\n",
    "    x_out = torch.cat(torch.chunk(x_out, 2, dim=-1), dim=-2)\n",
    "    return x_out.reshape(x_out.shape[0], x_out.shape[1], x_out.shape[2], -1).transpose(1, 2)\n",
    "\n",
    "class RMSNorm(torch.nn.Module): # RMS:4.326552, RMS_no_weight:4.410741 # RMS':4.554899\n",
    "    def __init__(self, dim: int = hidden_size):\n",
    "        super().__init__(); self.weight = torch.nn.Parameter(torch.zeros(dim)) # one weight per feature to be learned\n",
    "    def _norm(self, x): # mean square for each feature (across the last dimension)\n",
    "        return x * torch.rsqrt(x.pow(2).mean(-1, keepdim=True) + rms_norm_eps)\n",
    "    def forward(self, x): # ensure the data type matches the input.\n",
    "        return self._norm(x.float()).type_as(x) * (1 + self.weight)\n",
    "\n",
    "class GemmaAttention(torch.nn.Module): # MQA = K,V shared by 4Qs\n",
    "    def __init__(self):\n",
    "        super().__init__(); self.qkv_proj = torch.nn.Linear(hidden_size, (num_attention_heads + 2 * num_key_value_heads) * head_dim, bias=False); self.o_proj = torch.nn.Linear(num_attention_heads * head_dim, hidden_size, bias=False) # concatenated attention outputs back to the hidden size.\n",
    "    def forward(self, hidden_states: torch.Tensor,) -> torch.Tensor:  # in=(B, T, hidden_size)\n",
    "        batch_size, input_len, _ = hidden_states.shape\n",
    "        qkv = self.qkv_proj(hidden_states)\n",
    "        xq, xk, xv = qkv.split([num_attention_heads * head_dim, num_key_value_heads * head_dim, num_key_value_heads * head_dim],dim=-1)\n",
    "        xq = xq.view(batch_size, -1, num_attention_heads, head_dim); xk = xk.view(batch_size, -1, num_key_value_heads, head_dim); xv = xv.view(batch_size, -1, num_key_value_heads, head_dim)\n",
    "        xq = apply_rotary_emb(xq, head_dim); xk = apply_rotary_emb(xk, head_dim)\n",
    "        if num_key_value_heads != num_attention_heads:  # Q/KV multiples of K and V to match Q\n",
    "            xk = torch.repeat_interleave(xk, num_attention_heads // num_key_value_heads, dim=2) # [B, T, n_local_heads, head_dim]\n",
    "            xv = torch.repeat_interleave(xv, num_attention_heads // num_key_value_heads, dim=2)\n",
    "        q = xq.transpose(1, 2); k = xk.transpose(1, 2); v = xv.transpose(1, 2) # [batch_size, n_local_heads, input_len, head_dim]\n",
    "        output = torch.nn.functional.scaled_dot_product_attention(q, k, v, attn_mask=None, dropout_p=0, is_causal=True) # B nh T hs        \n",
    "        output = output.transpose(1, 2).contiguous().view(batch_size, input_len, -1)  # [B, T, \"hidden_dim\"]\n",
    "        return self.o_proj(output)\n",
    "\n",
    "class GemmaDecoderLayer(torch.nn.Module): # normalize before and after the attention mechanism\n",
    "    def __init__(self):\n",
    "        super().__init__(); self.self_attn = GemmaAttention(); self.input_layernorm = RMSNorm(); self.post_attention_layernorm = RMSNorm(); self.gate_proj = torch.nn.Linear(hidden_size, intermediate_size); self.up_proj = torch.nn.Linear(hidden_size, intermediate_size); self.down_proj = torch.nn.Linear(intermediate_size, hidden_size) # mlp\n",
    "    def forward(self, hidden_states: torch.Tensor) -> torch.Tensor:  # input_size = (B, T, hidden_size)\n",
    "        residual = hidden_states # Self Attention Block\n",
    "        hidden_states = self.input_layernorm(hidden_states); hidden_states = self.self_attn(hidden_states=hidden_states)\n",
    "        hidden_states = residual + hidden_states\n",
    "        residual = hidden_states # MLP Block\n",
    "        hidden_states = self.post_attention_layernorm(hidden_states); gate = torch.nn.functional.gelu(self.gate_proj(hidden_states)); up = self.up_proj(hidden_states); fuse = gate * up; hidden_states = self.down_proj(fuse) # mlp\n",
    "        return residual + hidden_states\n",
    "\n",
    "class minGemma(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__(); self.embedder = torch.nn.Embedding(vocab_size, hidden_size); self.layers = torch.nn.ModuleList(GemmaDecoderLayer() for _ in range(num_hidden_layers)); self.norm = RMSNorm();\n",
    "    def forward(self, input_token_ids: torch.Tensor) -> torch.Tensor: # (B, T)\n",
    "        hidden_states = self.embedder(input_token_ids[:,:-1]) # (B, T) & (vocab_size, hidden_size) -> (B, T, hidden_size)\n",
    "        hidden_states = hidden_states * (hidden_size**0.5)\n",
    "        for i in range(len(self.layers)):\n",
    "            hidden_states = self.layers[i](hidden_states) # shortened too much???\n",
    "        hidden_states = self.norm(hidden_states) # -> (B, T, hidden_size)        \n",
    "        embedder_weight = self.embedder.weight\n",
    "        logits = torch.matmul(hidden_states, embedder_weight.t()); b,t,v=logits.shape; # (B, T, hidden_size) @ (hidden_size, vocab_size) -> (B, T, vocab_size)\n",
    "        loss = torch.nn.functional.cross_entropy(logits.view(b*t,v), input_token_ids[:,1:].reshape(b*t)) #, weight=None, ignore_index=-100, reduction='mean')\n",
    "        return loss, logits # logits, loss\n",
    "\n",
    "def map_to_array5(ix):\n",
    "    common = torch.stack([torch.from_numpy((train_data[i[0]:i[0]+T+1]).astype(np.int64)) for i in ix]); return {'input_token_ids': common}\n",
    "def map_to_array_Val(ix):\n",
    "    common = torch.stack([torch.from_numpy((val_data[i[0]:i[0]+T+1]).astype(np.int64)) for i in ix]); return {'input_token_ids': common}\n",
    "\n",
    "train_data = np.memmap('train_BabyLM_10M.bin', dtype=np.uint16, mode='r'); val_data = np.memmap('val_BabyLM.bin', dtype=np.uint16, mode='r')\n",
    "T=1024; B=12//2; N_step=13000*2; print(T * B * N_step / 1000000) # 0.01 B-tokens being calculated # n_steps=N_step;\n",
    "model = minGemma().to(device); print(f'L{num_hidden_layers}' f' att{num_attention_heads}' f' kv_heads{num_key_value_heads}' f' hidden{hidden_size}' f' intermediate{intermediate_size}' f' head_dim{head_dim}' f' T{T}')\n",
    "\n",
    "# Normal # lr_scheduler_type=\"linear\" can be omitted\n",
    "training_args = TrainingArguments(gradient_accumulation_steps=2, learning_rate=24.0e-4, weight_decay=1.2, num_train_epochs=1, logging_strategy='epoch', output_dir='./', bf16=True, per_device_train_batch_size=B, per_device_eval_batch_size=B, eval_strategy='no', save_strategy='no', report_to='none', remove_unused_columns=False, dataloader_pin_memory=True) #, dataloader_num_workers=4\n",
    "trainer = Trainer(model=model, args=training_args, train_dataset=torch.utils.data.TensorDataset(torch.randint(len(train_data)-T-1, (B*N_step,))), data_collator=map_to_array5);\n",
    "result = trainer.train(); tloss=result[2][\"train_loss\"] # trainer = Trainer(model=model, args=training_args, eval_dataset=torch.utils.data.TensorDataset(torch.randint(len(val_data)-T-1, (B*400*4,))), data_collator=map_to_array_Val); trainer.can_return_loss = True; loss_current = trainer.evaluate()[\"eval_loss\"]\n",
    "\n",
    "loss = []; model.eval(); B2=16; B2=12//2; torch.cuda.empty_cache();\n",
    "for k in range(5000*2): #4000 # std=0.0056 for 1000 with 89sec\n",
    "    val_ind = torch.randint(len(val_data)-T-1, (B2,)); common = (torch.stack([torch.from_numpy((val_data[i:i+T+1]).astype(np.int64)) for i in val_ind]))\n",
    "    loss += [model(common.to('cuda', non_blocking=True))[0].item()]\n",
    "if torch.Tensor(loss).mean() < 3.0217:\n",
    "    torch.save(model.state_dict(), f'{model.__class__.__name__}' f'-hidden_layers{num_hidden_layers}' f'-att_heads{num_attention_heads}' f'-kv_heads{num_key_value_heads}' f'-hidden{hidden_size}' f'-intermediate{intermediate_size}' f'-head_dim{head_dim}' f'-T{T}' f'--{time.strftime(\"%Y-%m-%d-%H-%M\")}.pth')\n",
    "model.train(); del common; print(f'[ {num_hidden_layers}, {num_attention_heads}, {num_key_value_heads}, {hidden_size}, {intermediate_size}, {head_dim}, {sum(p.numel() for p in model.parameters()) / 10**6:.1f}, {tloss:.4f}, {torch.Tensor(loss).mean():.4f}, {N_step}],')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a9b51c20-76c3-4295-8e8f-5742a761d560",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "153.6\n",
      "L20 att6 kv_heads3 hidden648 intermediate2592 head_dim240 T1024\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='12500' max='12500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [12500/12500 2:26:22, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>12500</td>\n",
       "      <td>3.522200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 20, 6, 3, 648, 2592, 240, 189.5, 3.5222, 3.0236, 25000],\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt; import numpy as np; import time, torch; device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "from transformers import AutoTokenizer, TrainingArguments, DefaultDataCollator, Trainer\n",
    "vocab_size = 50257 # =tokenizer.vocab_size  # FIX!!! # G256128    ### T=256 for minGemma # G8192 for real Gemma\n",
    "num_hidden_layers =  20 # 8 # G28 G18 #blocks\n",
    "num_attention_heads = 6 # 4 # G16 G8\n",
    "num_key_value_heads = 3 # 4 # G16 G1\n",
    "hidden_size = num_attention_heads*108 # 128 # G3072 G2048 # embedding dimension\n",
    "intermediate_size = hidden_size*4 # x4 or x8 # time limiting factor #512 # G24576 G16384  # MLP inner dim\n",
    "head_dim = 240 # 32 # G256 # dim in attention # Doesn't affect time\n",
    "rms_norm_eps = 1e-6 # 1e-6\n",
    "rope_theta = 1000.0 # scale freq is small for S-model. 1000 might work too # G10000.0\n",
    "\n",
    "def apply_rotary_emb(x: torch.Tensor, dim: int) -> torch.Tensor: # seq_len = x.size(1) # N\n",
    "    freqs = 1.0 / (rope_theta ** (torch.arange(0, dim, 2, device=device).float() / dim)) # Dynamically compute frequency cis\n",
    "    t = torch.arange(x.size(1), device=device); freqs = torch.outer(t, freqs).float(); freqs_cis = torch.polar(torch.ones_like(freqs), freqs)  # complex64\n",
    "    x_ = torch.view_as_complex(torch.stack(torch.chunk(x.transpose(1, 2).float(), 2, dim=-1), dim=-1))\n",
    "    x_out = torch.view_as_real(x_ * freqs_cis.unsqueeze(0)).type_as(x)  # Ensure batch dimension is handled\n",
    "    x_out = torch.cat(torch.chunk(x_out, 2, dim=-1), dim=-2)\n",
    "    return x_out.reshape(x_out.shape[0], x_out.shape[1], x_out.shape[2], -1).transpose(1, 2)\n",
    "\n",
    "class RMSNorm(torch.nn.Module): # RMS:4.326552, RMS_no_weight:4.410741 # RMS':4.554899\n",
    "    def __init__(self, dim: int = hidden_size):\n",
    "        super().__init__(); self.weight = torch.nn.Parameter(torch.zeros(dim)) # one weight per feature to be learned\n",
    "    def _norm(self, x): # mean square for each feature (across the last dimension)\n",
    "        return x * torch.rsqrt(x.pow(2).mean(-1, keepdim=True) + rms_norm_eps)\n",
    "    def forward(self, x): # ensure the data type matches the input.\n",
    "        return self._norm(x.float()).type_as(x) * (1 + self.weight)\n",
    "\n",
    "class GemmaAttention(torch.nn.Module): # MQA = K,V shared by 4Qs\n",
    "    def __init__(self):\n",
    "        super().__init__(); self.qkv_proj = torch.nn.Linear(hidden_size, (num_attention_heads + 2 * num_key_value_heads) * head_dim, bias=False); self.o_proj = torch.nn.Linear(num_attention_heads * head_dim, hidden_size, bias=False) # concatenated attention outputs back to the hidden size.\n",
    "    def forward(self, hidden_states: torch.Tensor,) -> torch.Tensor:  # in=(B, T, hidden_size)\n",
    "        batch_size, input_len, _ = hidden_states.shape\n",
    "        qkv = self.qkv_proj(hidden_states)\n",
    "        xq, xk, xv = qkv.split([num_attention_heads * head_dim, num_key_value_heads * head_dim, num_key_value_heads * head_dim],dim=-1)\n",
    "        xq = xq.view(batch_size, -1, num_attention_heads, head_dim); xk = xk.view(batch_size, -1, num_key_value_heads, head_dim); xv = xv.view(batch_size, -1, num_key_value_heads, head_dim)\n",
    "        xq = apply_rotary_emb(xq, head_dim); xk = apply_rotary_emb(xk, head_dim)\n",
    "        if num_key_value_heads != num_attention_heads:  # Q/KV multiples of K and V to match Q\n",
    "            xk = torch.repeat_interleave(xk, num_attention_heads // num_key_value_heads, dim=2) # [B, T, n_local_heads, head_dim]\n",
    "            xv = torch.repeat_interleave(xv, num_attention_heads // num_key_value_heads, dim=2)\n",
    "        q = xq.transpose(1, 2); k = xk.transpose(1, 2); v = xv.transpose(1, 2) # [batch_size, n_local_heads, input_len, head_dim]\n",
    "        output = torch.nn.functional.scaled_dot_product_attention(q, k, v, attn_mask=None, dropout_p=0, is_causal=True) # B nh T hs        \n",
    "        output = output.transpose(1, 2).contiguous().view(batch_size, input_len, -1)  # [B, T, \"hidden_dim\"]\n",
    "        return self.o_proj(output)\n",
    "\n",
    "class GemmaDecoderLayer(torch.nn.Module): # normalize before and after the attention mechanism\n",
    "    def __init__(self):\n",
    "        super().__init__(); self.self_attn = GemmaAttention(); self.input_layernorm = RMSNorm(); self.post_attention_layernorm = RMSNorm(); self.gate_proj = torch.nn.Linear(hidden_size, intermediate_size); self.up_proj = torch.nn.Linear(hidden_size, intermediate_size); self.down_proj = torch.nn.Linear(intermediate_size, hidden_size) # mlp\n",
    "    def forward(self, hidden_states: torch.Tensor) -> torch.Tensor:  # input_size = (B, T, hidden_size)\n",
    "        residual = hidden_states # Self Attention Block\n",
    "        hidden_states = self.input_layernorm(hidden_states); hidden_states = self.self_attn(hidden_states=hidden_states)\n",
    "        hidden_states = residual + hidden_states\n",
    "        residual = hidden_states # MLP Block\n",
    "        hidden_states = self.post_attention_layernorm(hidden_states); gate = torch.nn.functional.gelu(self.gate_proj(hidden_states)); up = self.up_proj(hidden_states); fuse = gate * up; hidden_states = self.down_proj(fuse) # mlp\n",
    "        return residual + hidden_states\n",
    "\n",
    "class minGemma(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__(); self.embedder = torch.nn.Embedding(vocab_size, hidden_size); self.layers = torch.nn.ModuleList(GemmaDecoderLayer() for _ in range(num_hidden_layers)); self.norm = RMSNorm();\n",
    "    def forward(self, input_token_ids: torch.Tensor) -> torch.Tensor: # (B, T)\n",
    "        hidden_states = self.embedder(input_token_ids[:,:-1]) # (B, T) & (vocab_size, hidden_size) -> (B, T, hidden_size)\n",
    "        hidden_states = hidden_states * (hidden_size**0.5)\n",
    "        for i in range(len(self.layers)):\n",
    "            hidden_states = self.layers[i](hidden_states) # shortened too much???\n",
    "        hidden_states = self.norm(hidden_states) # -> (B, T, hidden_size)        \n",
    "        embedder_weight = self.embedder.weight\n",
    "        logits = torch.matmul(hidden_states, embedder_weight.t()); b,t,v=logits.shape; # (B, T, hidden_size) @ (hidden_size, vocab_size) -> (B, T, vocab_size)\n",
    "        loss = torch.nn.functional.cross_entropy(logits.view(b*t,v), input_token_ids[:,1:].reshape(b*t)) #, weight=None, ignore_index=-100, reduction='mean')\n",
    "        return loss, logits # logits, loss\n",
    "\n",
    "def map_to_array5(ix):\n",
    "    common = torch.stack([torch.from_numpy((train_data[i[0]:i[0]+T+1]).astype(np.int64)) for i in ix]); return {'input_token_ids': common}\n",
    "def map_to_array_Val(ix):\n",
    "    common = torch.stack([torch.from_numpy((val_data[i[0]:i[0]+T+1]).astype(np.int64)) for i in ix]); return {'input_token_ids': common}\n",
    "\n",
    "train_data = np.memmap('train_BabyLM_10M.bin', dtype=np.uint16, mode='r'); val_data = np.memmap('val_BabyLM.bin', dtype=np.uint16, mode='r')\n",
    "T=1024; B=12//2; N_step=12500*2; print(T * B * N_step / 1000000) # 0.01 B-tokens being calculated # n_steps=N_step;\n",
    "model = minGemma().to(device); print(f'L{num_hidden_layers}' f' att{num_attention_heads}' f' kv_heads{num_key_value_heads}' f' hidden{hidden_size}' f' intermediate{intermediate_size}' f' head_dim{head_dim}' f' T{T}')\n",
    "\n",
    "# Normal # lr_scheduler_type=\"linear\" can be omitted\n",
    "training_args = TrainingArguments(gradient_accumulation_steps=2, learning_rate=24.0e-4, weight_decay=1.2, num_train_epochs=1, logging_strategy='epoch', output_dir='./', bf16=True, per_device_train_batch_size=B, per_device_eval_batch_size=B, eval_strategy='no', save_strategy='no', report_to='none', remove_unused_columns=False, dataloader_pin_memory=True) #, dataloader_num_workers=4\n",
    "trainer = Trainer(model=model, args=training_args, train_dataset=torch.utils.data.TensorDataset(torch.randint(len(train_data)-T-1, (B*N_step,))), data_collator=map_to_array5);\n",
    "result = trainer.train(); tloss=result[2][\"train_loss\"] # trainer = Trainer(model=model, args=training_args, eval_dataset=torch.utils.data.TensorDataset(torch.randint(len(val_data)-T-1, (B*400*4,))), data_collator=map_to_array_Val); trainer.can_return_loss = True; loss_current = trainer.evaluate()[\"eval_loss\"]\n",
    "\n",
    "loss = []; model.eval(); B2=16; B2=12//2; torch.cuda.empty_cache();\n",
    "for k in range(5000*2): #4000 # std=0.0056 for 1000 with 89sec\n",
    "    val_ind = torch.randint(len(val_data)-T-1, (B2,)); common = (torch.stack([torch.from_numpy((val_data[i:i+T+1]).astype(np.int64)) for i in val_ind]))\n",
    "    loss += [model(common.to('cuda', non_blocking=True))[0].item()]\n",
    "if torch.Tensor(loss).mean() < 3.0236:\n",
    "    torch.save(model.state_dict(), f'{model.__class__.__name__}' f'-hidden_layers{num_hidden_layers}' f'-att_heads{num_attention_heads}' f'-kv_heads{num_key_value_heads}' f'-hidden{hidden_size}' f'-intermediate{intermediate_size}' f'-head_dim{head_dim}' f'-T{T}' f'--{time.strftime(\"%Y-%m-%d-%H-%M\")}.pth')\n",
    "model.train(); del common; print(f'[ {num_hidden_layers}, {num_attention_heads}, {num_key_value_heads}, {hidden_size}, {intermediate_size}, {head_dim}, {sum(p.numel() for p in model.parameters()) / 10**6:.1f}, {tloss:.4f}, {torch.Tensor(loss).mean():.4f}, {N_step}],')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "506ae450-68cd-4618-b2eb-c78f1d13cb0a",
   "metadata": {},
   "source": [
    "# L18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9997514-59c8-4c0a-8857-e082dcc56add",
   "metadata": {},
   "outputs": [],
   "source": [
    "# L18 Normal Model T1024 (default: x4 B12 lr24e-4 WD1.2 N13000) w/ Grad_Acc\n",
    "# Best model for each number of heads:  6(3):3.0224, 8(4):3.0261\n",
    "\n",
    "# local best for H8(4): 3.0261  (bad)\n",
    "[ 18, 8, 4, 832, 3328, 288, 295.0, 4.4182, 3.0934, 45000], # 4.1h 14.2G\n",
    "[ 18, 8, 4, 832, 3328, 272, 289.3, 3.8492, 3.0540, 45000], # 4.0h\n",
    "[ 18, 8, 4, 832, 3328, 256, 283.5, 4.0197, 3.0565, 45000], # 3.6h\n",
    "[ 18, 8, 4, 832, 3328, 240, 277.8, 4.0482, 3.0633, 30000], # 2.7h\n",
    "[ 18, 8, 4, 832, 3328, 224, 272.0, 3.8934, 3.0521, 30000], # 2.6h\n",
    "[ 18, 8, 4, 832, 3328, 208, 266.3, 4.0773, 3.0563, 30000], # 2.5h\n",
    "[ 18, 8, 4, 832, 3328, 192, 260.5, 3.6649, 3.0436, 45000], # 3.2h\n",
    "[ 18, 8, 4, 832, 3328, 176, 254.8, 3.6484, 3.0488, 45000], # 3.1h\n",
    "[ 18, 8, 4, 832, 3328, 160, 249.0, 3.5868, 3.0447, 45000], # 3.0h\n",
    "\n",
    "[ 18, 8, 4, 800, 3200, 288, 278.1, 3.7993, 3.0500, 45000], # 4.1h\n",
    "[ 18, 8, 4, 800, 3200, 272, 272.6, 4.1531, 3.0939, 45000], # 4.0h\n",
    "[ 18, 8, 4, 800, 3200, 256, 267.1, 3.8445, 3.0526, 45000], # 3.5h\n",
    "[ 18, 8, 4, 800, 3200, 240, 261.5, 3.7519, 3.0481, 30000], # 2.7h 16.4G  ### 800-240 15.5G impossible\n",
    "[ 18, 8, 4, 800, 3200, 224, 256.0, 3.7560, 3.0464, 30000], # 2.6h\n",
    "[ 18, 8, 4, 800, 3200, 208, 250.5, 3.6537, 3.0403, 30000], # 2.5h\n",
    "[ 18, 8, 4, 800, 3200, 192, 245.0, 3.6361, 3.0518, 45000], # 3.1h\n",
    "[ 18, 8, 4, 800, 3200, 176, 239.4, 3.7531, 3.0436, 45000], # 3.0h\n",
    "[ 18, 8, 4, 800, 3200, 160, 233.9, 3.6813, 3.0407, 45000], # 2.9h # No N13000(*3) for 832 and 800 as they are bad\n",
    "\n",
    "[ 18, 8, 4, 768, 3072, 288, 261.7, 3.8537, 3.0504, 30000], # 4.0h 15.5G\n",
    "[ 18, 8, 4, 768, 3072, 288, 261.7, 4.2450, 3.1072,  39000],# 3.4h\n",
    "[ 18, 8, 4, 768, 3072, 272, 256.4, 3.7718, 3.0532, 45000], # 3.8h # 4.1h 15.5G\n",
    "[ 18, 8, 4, 768, 3072, 272, 256.4, 4.0625, 3.1149,  39000],# 3.3h\n",
    "[ 18, 8, 4, 768, 3072, 256, 251.1, 3.7127, 3.0468, 45000], # 3.4h\n",
    "[ 18, 8, 4, 768, 3072, 256, 251.1, 3.7727, 3.0443,  39000],# 2.9h\n",
    "[ 18, 8, 4, 768, 3072, 240, 245.8, 3.9943, 3.0570, 30000], # 2.6h\n",
    "[ 18, 8, 4, 768, 3072, 240, 245.8, 3.7038, 3.0424,  39000],# 2.9h 12.5G\n",
    "[ 18, 8, 4, 768, 3072, 224, 240.5, 3.6035, 3.0329, 30000], # 2.5h\n",
    "[ 18, 8, 4, 768, 3072, 224, 240.5, 3.7050, 3.0427,  39000],# 2.8h\n",
    "[ 18, 8, 4, 768, 3072, 208, 235.2, 3.5699, 3.0412, 30000], # 2.4h\n",
    "[ 18, 8, 4, 768, 3072, 208, 235.2, 3.7367, 3.0409,  39000],# 2.7h\n",
    "[ 18, 8, 4, 768, 3072, 192, 229.9, 3.5640, 3.0416, 30000], # 19.2h\n",
    "[ 18, 8, 4, 768, 3072, 192, 229.9, 3.7740, 3.0476,  39000],# 2.6h\n",
    "[ 18, 8, 4, 768, 3072, 176, 224.5, 3.7179, 3.0568, 30000], # 2.9h\n",
    "[ 18, 8, 4, 768, 3072, 176, 224.5, 3.7809, 3.0441,  39000],# 2.5h\n",
    "[ 18, 8, 4, 768, 3072, 160, 219.2, 3.5003, 3.0372, 45000], # 2.8h\n",
    "[ 18, 8, 4, 768, 3072, 160, 219.2, 3.7193, 3.0495,  39000],# 2.4h\n",
    "\n",
    "[ 18, 8, 4, 736, 2944, 288, 245.7, 3.6591, 3.0479, 45000], # 3.9h\n",
    "[ 18, 8, 4, 736, 2944, 288, 245.7, 3.8185, 3.0502,  39000],# 3.3h\n",
    "[ 18, 8, 4, 736, 2944, 272, 240.6, 3.6613, 3.0411, 45000], # 3.8h # 4.0h 15.4G\n",
    "[ 18, 8, 4, 736, 2944, 272, 240.6, 3.8033, 3.0534,  39000],# 3.3h 12.2G\n",
    "[ 18, 8, 4, 736, 2944, 256, 235.5, 3.8161, 3.0549, 30000], # 2.6h\n",
    "[ 18, 8, 4, 736, 2944, 256, 235.5, 3.7010, 3.0474,  39000],# 2.9h\n",
    "[ 18, 8, 4, 736, 2944, 240, 230.5, 3.4959, 3.0336, 30000], # 2.6h\n",
    "[ 18, 8, 4, 736, 2944, 240, 230.5, 3.8158, 3.0477,  39000],# 2.8h\n",
    "[ 18, 8, 4, 736, 2944, 224, 225.4, 3.5448, 3.0364, 30000], # 2.5h\n",
    "[ 18, 8, 4, 736, 2944, 224, 225.4, 3.6477, 3.0376,  39000],# 2.7h\n",
    "[ 18, 8, 4, 736, 2944, 208, 220.3, 3.4812, 3.0367,  31000],# 2.4h\n",
    "[ 18, 8, 4, 736, 2944, 208, 220.3, 3.4933,+3.0296, 30000], # 2.4h 15.6G\n",
    "[ 18, 8, 4, 736, 2944, 208, 220.3, 3.5665, 3.0357,  29000],# 2.3h\n",
    "[ 18, 8, 4, 736, 2944, 208, 220.3, 3.5365, 3.0372,  28000],# 2.2h\n",
    "[ 18, 8, 4, 736, 2944, 208, 220.3, 3.5955, 3.0386,  39000],# 2.6h\n",
    "#\n",
    "# underf construction (192)\n",
    "#\n",
    "[ 18, 8, 4, 736, 2944, 176, 210.1, 3.4233, 3.0366,  33000],# 2.4h\n",
    "[ 18, 8, 4, 736, 2944, 176, 210.1, 3.6541, 3.0496,  32000],# 2.3h\n",
    "[ 18, 8, 4, 736, 2944, 176, 210.1, 3.4566,+3.0291,  31000],# 2.2h\n",
    "[ 18, 8, 4, 736, 2944, 176, 210.1, 3.5124, 3.0314, 30000], # 2.2h\n",
    "[ 18, 8, 4, 736, 2944, 176, 210.1, 3.5622, 3.0382,  29000],# 2.1h\n",
    "[ 18, 8, 4, 736, 2944, 176, 210.1, 3.5774, 3.0337,  39000],# 2.4h\n",
    "[ 18, 8, 4, 736, 2944, 160, 205.0, 3.5169, 3.0359, 30000], # 2.1h\n",
    "[ 18, 8, 4, 736, 2944, 160, 205.0, 3.6169, 3.0353,  39000],# 2.4h\n",
    "\n",
    "[ 18, 8, 4, 704, 2816, 288, 230.2, 3.5469, 3.0366, 45000], # 3.8h\n",
    "[ 18, 8, 4, 704, 2816, 288, 230.2, 3.6677, 3.0402,  39000],# 3.3h 12.0G\n",
    "[ 18, 8, 4, 704, 2816, 272, 225.3, 3.5613, 3.0390, 45000], # 3.7h\n",
    "[ 18, 8, 4, 704, 2816, 272, 225.3, 3.6818, 3.0416,  39000],# 3.2h\n",
    "[ 18, 8, 4, 704, 2816, 256, 220.4, 3.5760, 3.0474, 30000], # 2.6h\n",
    "[ 18, 8, 4, 704, 2816, 256, 220.4, 3.6643, 3.0365,  39000],# 2.8h 12.2G\n",
    "[ 18, 8, 4, 704, 2816, 240, 215.6, 3.5211, 3.0327, 30000], # 2.5h\n",
    "[ 18, 8, 4, 704, 2816, 240, 215.6, 3.6691, 3.0402,  39000],# 2.8h\n",
    "[ 18, 8, 4, 704, 2816, 224, 210.7, 3.5275, 3.0355, 30000], # 2.4h\n",
    "[ 18, 8, 4, 704, 2816, 224, 210.7, 3.6348, 3.0407,  39000],# 2.7h\n",
    "[ 18, 8, 4, 704, 2816, 208, 205.8, 3.5311, 3.0385, 30000], # 2.3h\n",
    "[ 18, 8, 4, 704, 2816, 208, 205.8, 3.5722, 3.0366,  39000],# 2.6h\n",
    "[ 18, 8, 4, 704, 2816, 192, 201.0, 3.4921, 3.0327, 30000], # 2.9h\n",
    "[ 18, 8, 4, 704, 2816, 192, 201.0, 3.5861, 3.0361,  39000],# 2.5h\n",
    "[ 18, 8, 4, 704, 2816, 176, 196.1, 3.4396, 3.0320, 30000], # 2.8h\n",
    "[ 18, 8, 4, 704, 2816, 176, 196.1, 3.5797, 3.0339,  39000],# 2.4h\n",
    "[ 18, 8, 4, 704, 2816, 160, 191.2, 3.4954, 3.0376, 30000], # 2.7h\n",
    "[ 18, 8, 4, 704, 2816, 160, 191.2, 3.5442, 3.0419,  39000],# 2.3h\n",
    "\n",
    "[ 18, 8, 4, 672, 2688, 304, 219.7, 3.5896, 3.0408, 45000], # 3.9h\n",
    "[ 18, 8, 4, 672, 2688, 288, 215.1, 3.5849, 3.0340,  46500],# 3.9h\n",
    "[ 18, 8, 4, 672, 2688, 288, 215.1, 3.4617, 3.0311, 45000], # 3.7h # 3.9h 15.1G\n",
    "[ 18, 8, 4, 672, 2688, 288, 215.1, 3.6060, 3.0422,  43500],# 3.6h\n",
    "[ 18, 8, 4, 672, 2688, 288, 215.1, 3.6442, 3.0377,  39000],# 3.3h 11.8G\n",
    "[ 18, 8, 4, 672, 2688, 272, 210.4, 3.5157, 3.0364,  46500],# 3.8h\n",
    "[ 18, 8, 4, 672, 2688, 272, 210.4, 3.5425,+3.0274, 45000], # 3.7h\n",
    "[ 18, 8, 4, 672, 2688, 272, 210.4, 3.5401, 3.0371,  43500],# 3.5h\n",
    "[ 18, 8, 4, 672, 2688, 272, 210.4, 3.6229, 3.0435,  39000],# 3.1h\n",
    "[ 18, 8, 4, 672, 2688, 256, 205.8, 3.6681, 3.0462, 45000], # 3.2h\n",
    "[ 18, 8, 4, 672, 2688, 256, 205.8, 3.5809, 3.0484,  39000],# 2.8h\n",
    "[ 18, 8, 4, 672, 2688, 240, 201.1, 3.4467, 3.0357, 45000], # 3.2h\n",
    "[ 18, 8, 4, 672, 2688, 240, 201.1, 3.5141, 3.0321,  39000],# 2.7h\n",
    "[ 18, 8, 4, 672, 2688, 224, 196.5, 3.4791, 3.0390, 30000], # 3.1h\n",
    "[ 18, 8, 4, 672, 2688, 224, 196.5, 3.5467, 3.0389,  39000],# 2.6h\n",
    "#\n",
    "# under construction (208)\n",
    "#\n",
    "[ 18, 8, 4, 672, 2688, 192, 187.2, 3.5080, 3.0374, 30000], # 2.8h\n",
    "[ 18, 8, 4, 672, 2688, 192, 187.2, 3.5854, 3.0429,  39000],# 2.4h\n",
    "[ 18, 8, 4, 672, 2688, 176, 182.5, 3.3999, 3.0341,  32000],# 2.9h\n",
    "[ 18, 8, 4, 672, 2688, 176, 182.5, 3.4153, 3.0317,  31000],# 2.8h\n",
    "[ 18, 8, 4, 672, 2688, 176, 182.5, 3.4674, 3.0310, 30000], # 2.7h\n",
    "[ 18, 8, 4, 672, 2688, 176, 182.5, 3.4848,+3.0274,  29000],# 2.6h\n",
    "[ 18, 8, 4, 672, 2688, 176, 182.5, 3.4834, 3.0323,  28000],# 2.5h\n",
    "[ 18, 8, 4, 672, 2688, 176, 182.5, 3.4969, 3.0313,  40500],# 2.5h\n",
    "[ 18, 8, 4, 672, 2688, 176, 182.5, 3.4957,+3.0271,  39000],# 2.4h\n",
    "[ 18, 8, 4, 672, 2688, 176, 182.5, 3.5838, 3.0322,  37500],# 2.3h 10.6G\n",
    "#\n",
    "# under construction (160)\n",
    "#\n",
    "\n",
    "[ 18, 8, 4, 640, 2560, 304, 204.8, 3.5130, 3.0378, 45000], # 3.8h\n",
    "[ 18, 8, 4, 640, 2560, 288, 200.4, 3.4992, 3.0381, 45000], # 3.6h\n",
    "[ 18, 8, 4, 640, 2560, 288, 200.4, 3.6309, 3.0346,  39000],# 3.1h\n",
    "[ 18, 8, 4, 640, 2560, 272, 196.0, 3.4908, 3.0335, 45000], # 3.6h 12.7G\n",
    "[ 18, 8, 4, 640, 2560, 272, 196.0, 3.5729, 3.0445,  39000],# 3.1h\n",
    "[ 18, 8, 4, 640, 2560, 256, 191.5, 3.6464, 3.0487,  48000], # 3.3h\n",
    "[ 18, 8, 4, 640, 2560, 256, 191.5, 3.4254, 3.0318,  46500],# 3.2h\n",
    "[ 18, 8, 4, 640, 2560, 256, 191.5, 3.4133,+3.0303, 45000], # 3.1h\n",
    "[+18, 8, 4, 640, 2560, 256, 191.5, 3.4397,+3.0261,  43500],# 3.0h   minGemma-hidden_layers18-att_heads8-kv_heads4-hidden640-intermediate2560-head_dim256-T1024--2025-10-26-15-27\n",
    "[ 18, 8, 4, 640, 2560, 256, 191.5, 3.4448, 3.0302,  42000], # 2.9h\n",
    "[ 18, 8, 4, 640, 2560, 256, 191.5, 3.5449, 3.0405,  40500],# 2.8h\n",
    "[ 18, 8, 4, 640, 2560, 256, 191.5, 3.5772, 3.0358,  39000],# 2.7h\n",
    "[ 18, 8, 4, 640, 2560, 240, 187.1, 3.5636, 3.0406, 30000], # 3.1h\n",
    "[ 18, 8, 4, 640, 2560, 240, 187.1, 3.5084,+3.0265,  39000],# 2.6h\n",
    "[ 18, 8, 4, 640, 2560, 224, 182.7, 3.5013, 3.0354, 30000], # 3.0h\n",
    "[ 18, 8, 4, 640, 2560, 224, 182.7, 3.7076, 3.0555,  39000],# 2.5h\n",
    "[ 18, 8, 4, 640, 2560, 208, 178.3, 3.4422, 3.0394, 30000], # 2.9h\n",
    "[ 18, 8, 4, 640, 2560, 208, 178.3, 3.4758, 3.0344,  26000],# 2.5h\n",
    "[ 18, 8, 4, 640, 2560, 192, 173.8, 3.6107, 3.0440, 30000], # 2.7h 13.1G\n",
    "[ 18, 8, 4, 640, 2560, 192, 173.8, 3.5087, 3.0354,  26000],# 2.3h\n",
    "[ 18, 8, 4, 640, 2560, 176, 169.4, 3.5248, 3.0374, 30000], # 2.6h\n",
    "[ 18, 8, 4, 640, 2560, 176, 169.4, 3.5194, 3.0350,  26000],# 2.2h\n",
    "[ 18, 8, 4, 640, 2560, 160, 165.0, 3.6393, 3.0537, 30000], # 2.6h\n",
    "[ 18, 8, 4, 640, 2560, 160, 165.0, 3.4815, 3.0351,  26000],# 2.1h\n",
    "\n",
    "[ 18, 8, 4, 608, 2432, 304, 190.4, 3.4361, 3.0354, 30000], # 3.7h # 3.9h 13.5G\n",
    "[ 18, 8, 4, 608, 2432, 288, 186.2, 3.4548, 3.0404,  31000],# 3.7h\n",
    "[ 18, 8, 4, 608, 2432, 288, 186.2, 3.4928,+3.0294, 30000], # 3.6h # 3.8h 13.4G\n",
    "[ 18, 8, 4, 608, 2432, 288, 186.2, 3.4108, 3.0337,  29000],# 3.5h\n",
    "[ 18, 8, 4, 608, 2432, 288, 186.2, 3.4310, 3.0331,  27000],# 3.4h\n",
    "[ 18, 8, 4, 608, 2432, 288, 186.2, 3.4689,+3.0274,  26000],# 3.1h\n",
    "[ 18, 8, 4, 608, 2432, 288, 186.2, 3.5359, 3.0346,  25000],# 3.1h\n",
    "[ 18, 8, 4, 608, 2432, 272, 182.0, 3.4538, 3.0332, 30000], # 3.5h 13.4G\n",
    "[ 18, 8, 4, 608, 2432, 272, 182.0, 3.4948, 3.0321,  27000],# 3.3h 13.3G\n",
    "[ 18, 8, 4, 608, 2432, 272, 182.0, 3.5109,+3.0277,  26000],# 3.0h\n",
    "[ 18, 8, 4, 608, 2432, 272, 182.0, 3.5612, 3.0341,  25000],# 3.0h\n",
    "[ 18, 8, 4, 608, 2432, 256, 177.8, 3.3714, 3.0341, 30000], # 3.1h\n",
    "[ 18, 8, 4, 608, 2432, 256, 177.8, 3.5234, 3.0359,  26000],# 2.7h\n",
    "[ 18, 8, 4, 608, 2432, 240, 173.6, 3.3719, 3.0330, 30000], # 3.0h 13.3G\n",
    "[ 18, 8, 4, 608, 2432, 240, 173.6, 3.4592, 3.0351,  26000],# 2.6h\n",
    "[ 18, 8, 4, 608, 2432, 224, 169.4, 3.3742, 3.0350,  31000],# 3.0h\n",
    "[ 18, 8, 4, 608, 2432, 224, 169.4, 3.3707,+3.0278, 30000], # 2.9h 13.4G\n",
    "[ 18, 8, 4, 608, 2432, 224, 169.4, 3.5627, 3.0393,  29000],# 2.8h 13.3G\n",
    "[ 18, 8, 4, 608, 2432, 224, 169.4, 3.4506, 3.0326,  27000],# 2.7h\n",
    "[ 18, 8, 4, 608, 2432, 224, 169.4, 3.4491,+3.0291,  26000],# 2.5h\n",
    "[ 18, 8, 4, 608, 2432, 224, 169.4, 3.5879, 3.0400,  25000],# 2.5h\n",
    "#\n",
    "# under construction (192, 208)\n",
    "#\n",
    "[ 18, 8, 4, 608, 2432, 176, 156.8, 3.3256, 3.0332,  31000],# 2.6h 12.9G\n",
    "[ 18, 8, 4, 608, 2432, 176, 156.8, 3.3652,+3.0278, 30000], # 2.6h\n",
    "[ 18, 8, 4, 608, 2432, 176, 156.8, 3.4074, 3.0337,  29000],# 2.5h\n",
    "[ 18, 8, 4, 608, 2432, 176, 156.8, 3.4212, 3.0336,  26000],# 2.2h\n",
    "[ 18, 8, 4, 608, 2432, 160, 152.5, 3.3489, 3.0333, 30000], # 2.5h\n",
    "[ 18, 8, 4, 608, 2432, 160, 152.5, 3.3930, 3.0341,  26000],# 2.1h\n",
    "\n",
    "[ 18, 8, 4, 576, 2304, 288, 172.4, 3.4337, 3.0373, 30000], # 3.6h\n",
    "[ 18, 8, 4, 576, 2304, 288, 172.4, 3.4482, 3.0338,  27000],# 3.3h 13.0G\n",
    "[ 18, 8, 4, 576, 2304, 288, 172.4, 3.5559, 3.0311,  26000],# 3.1h\n",
    "[ 18, 8, 4, 576, 2304, 288, 172.4, 3.4872, 3.0352,  25000],# 3.1h\n",
    "[ 18, 8, 4, 576, 2304, 272, 168.4, 3.3312, 3.0333,  32000],# 3.7h\n",
    "[ 18, 8, 4, 576, 2304, 272, 168.4, 3.3744, 3.0314,  31000],# 3.6h\n",
    "[ 18, 8, 4, 576, 2304, 272, 168.4, 3.3558, 3.0310, 30000], # 3.5h 12.9G\n",
    "[ 18, 8, 4, 576, 2304, 272, 168.4, 3.3732, 3.0325,  29000],# 3.4h\n",
    "[ 18, 8, 4, 576, 2304, 272, 168.4, 3.4789, 3.0344,  26000],# 3.0h\n",
    "[ 18, 8, 4, 576, 2304, 256, 164.4, 3.3456, 3.0338,  32000],# 3.3h\n",
    "[ 18, 8, 4, 576, 2304, 256, 164.4, 3.3656, 3.0306,  31000],# 3.2h\n",
    "[ 18, 8, 4, 576, 2304, 256, 164.4, 3.3819, 3.0314, 30000], # 3.1h\n",
    "[ 18, 8, 4, 576, 2304, 256, 164.4, 3.5780, 3.0593,  29000],# 3.0h\n",
    "[ 18, 8, 4, 576, 2304, 256, 164.4, 3.4539, 3.0390,  26000],# 2.6h\n",
    "[ 18, 8, 4, 576, 2304, 240, 160.4, 3.4030, 3.0332,  31000],# 3.1h\n",
    "[ 18, 8, 4, 576, 2304, 240, 160.4, 3.3610,+3.0285, 30000], # 3.0h\n",
    "[ 18, 8, 4, 576, 2304, 240, 160.4, 3.3813, 3.0306,  29000],# 2.9h 13.1G\n",
    "[ 18, 8, 4, 576, 2304, 240, 160.4, 3.4054, 3.0346,  28000],# 2.8h\n",
    "[ 18, 8, 4, 576, 2304, 240, 160.4, 3.4524, 3.0353,  26000],# 2.5h\n",
    "[ 18, 8, 4, 576, 2304, 224, 156.5, 3.5695, 3.0575, 30000], # 2.9h\n",
    "[ 18, 8, 4, 576, 2304, 224, 156.5, 3.5259, 3.0342,  26000],# 2.4h\n",
    "[ 18, 8, 4, 576, 2304, 208, 152.5, 3.4099, 3.0321, 30000], # 2.8h\n",
    "[ 18, 8, 4, 576, 2304, 208, 152.5, 3.4823, 3.0353,  26000],# 2.4h\n",
    "[ 18, 8, 4, 576, 2304, 192, 148.5, 3.3598, 3.0347, 30000], # 2.7h\n",
    "[ 18, 8, 4, 576, 2304, 192, 148.5, 3.4058, 3.0327,  27000],# 2.4h\n",
    "[ 18, 8, 4, 576, 2304, 192, 148.5, 3.4225,+3.0278,  26000],# 2.2h\n",
    "[ 18, 8, 4, 576, 2304, 192, 148.5, 3.4451, 3.0387,  25000],# 2.2h\n",
    "[ 18, 8, 4, 576, 2304, 176, 144.5, 3.5014, 3.0467, 30000], # 2.6h\n",
    "[ 18, 8, 4, 576, 2304, 176, 144.5, 3.4155, 3.0332,  26000],# 2.1h\n",
    "[ 18, 8, 4, 576, 2304, 160, 140.5, 3.3426, 3.0364, 30000], # 2.5h\n",
    "[ 18, 8, 4, 576, 2304, 160, 140.5, 3.4434, 3.0344,  26000],# 2.1h\n",
    "\n",
    "[ 18, 8, 4, 544, 2176, 288, 159.1, 3.3621, 3.0335, 30000], # 3.5h\n",
    "[ 18, 8, 4, 544, 2176, 288, 159.1, 3.4094, 3.0331,  26000],# 3.0h\n",
    "[ 18, 8, 4, 544, 2176, 272, 155.3, 3.3223, 3.0342, 30000], # 3.5h 12.5G\n",
    "[ 18, 8, 4, 544, 2176, 272, 155.3, 3.3775, 3.0372,  27000],# 3.2h\n",
    "[ 18, 8, 4, 544, 2176, 272, 155.3, 3.4113, 3.0317,  26000],# 2.9h\n",
    "[ 18, 8, 4, 544, 2176, 272, 155.3, 3.4258, 3.0359,  25000],# 3.0h\n",
    "[ 18, 8, 4, 544, 2176, 256, 151.5, 3.4054, 3.0353, 30000], # 3.0h 12.8G\n",
    "[ 18, 8, 4, 544, 2176, 256, 151.5, 3.3992, 3.0403,  26000],# 2.6h\n",
    "[ 18, 8, 4, 544, 2176, 240, 147.8, 3.3359, 3.0337,  31000],# 3.0h\n",
    "[ 18, 8, 4, 544, 2176, 240, 147.8, 3.3314,+3.0307, 30000], # 2.9h\n",
    "[ 18, 8, 4, 544, 2176, 240, 147.8, 3.3461, 3.0332,  29000],# 2.8h\n",
    "[ 18, 8, 4, 544, 2176, 240, 147.8, 3.3973, 3.0403,  27000],# 2.6h 13.2G\n",
    "[ 18, 8, 4, 544, 2176, 240, 147.8, 3.3914, 3.0312,  26000],# 2.5h\n",
    "[ 18, 8, 4, 544, 2176, 240, 147.8, 3.4169, 3.0398,  25000],# 2.5h\n",
    "[ 18, 8, 4, 544, 2176, 224, 144.0, 3.3313, 3.0389, 30000], # 2.8h\n",
    "[ 18, 8, 4, 544, 2176, 224, 144.0, 3.4021, 3.0372,  26000],# 2.4h\n",
    "[ 18, 8, 4, 544, 2176, 208, 140.3, 3.3038, 3.0359,  31000],# 2.8h\n",
    "[ 18, 8, 4, 544, 2176, 208, 140.3, 3.3120,+3.0310, 30000], # 2.7h\n",
    "[ 18, 8, 4, 544, 2176, 208, 140.3, 3.2997, 3.0346,  29000],# 2.6h\n",
    "[ 18, 8, 4, 544, 2176, 208, 140.3, 3.4022, 3.0382,  26000],# 2.3h\n",
    "[ 18, 8, 4, 544, 2176, 192, 136.5, 3.3163, 3.0381, 30000], # 2.6h\n",
    "[ 18, 8, 4, 544, 2176, 192, 136.5, 3.3653, 3.0330,  26000],# 2.2h\n",
    "[ 18, 8, 4, 544, 2176, 176, 132.7, 3.2982, 3.0366, 30000], # 2.5h 12.3G\n",
    "[ 18, 8, 4, 544, 2176, 176, 132.7, 3.3495, 3.0361,  26000],# 2.1h\n",
    "[ 18, 8, 4, 544, 2176, 160, 129.0, 3.3151, 3.0395, 30000], # 2.4h 12.2G\n",
    "[ 18, 8, 4, 544, 2176, 160, 129.0, 3.4041, 3.0393,  26000],# 2.0h\n",
    "\n",
    "[ 18, 8, 4, 512, 2048, 288, 146.2, 3.3081, 3.0392, 30000], # 3.4h\n",
    "[ 18, 8, 4, 512, 2048, 288, 146.2, 3.3915, 3.0439,  26000],# 2.9h\n",
    "[ 18, 8, 4, 512, 2048, 272, 142.6, 3.3071, 3.0408, 30000], # 3.3h\n",
    "[ 18, 8, 4, 512, 2048, 272, 142.6, 3.3827, 3.0360,  26000],# 2.8h\n",
    "[ 18, 8, 4, 512, 2048, 256, 139.1, 3.3021, 3.0379, 30000], # 2.9h\n",
    "[ 18, 8, 4, 512, 2048, 256, 139.1, 3.3662, 3.0369,  26000],# 2.5h\n",
    "[ 18, 8, 4, 512, 2048, 240, 135.5, 3.3138, 3.0446, 30000], # 2.8h\n",
    "[ 18, 8, 4, 512, 2048, 240, 135.5, 3.3994, 3.0370,  26000],# 2.4h\n",
    "[ 18, 8, 4, 512, 2048, 224, 132.0, 3.3084, 3.0419, 30000], # 2.7h\n",
    "[ 18, 8, 4, 512, 2048, 224, 132.0, 3.3470, 3.0382,  26000],# 2.3h\n",
    "[ 18, 8, 4, 512, 2048, 208, 128.5, 3.3683, 3.0405, 30000], # 2.6h\n",
    "[ 18, 8, 4, 512, 2048, 208, 128.5, 3.4455, 3.0401,  26000],# 2.2h\n",
    "[ 18, 8, 4, 512, 2048, 192, 124.9, 3.4283, 3.0478, 30000], # 2.5h\n",
    "[ 18, 8, 4, 512, 2048, 192, 124.9, 3.3744, 3.0400,  26000],# 2.1h\n",
    "[ 18, 8, 4, 512, 2048, 176, 121.4, 3.3131, 3.0413, 30000], # 2.4h 12.1G\n",
    "[ 18, 8, 4, 512, 2048, 176, 121.4, 3.3629, 3.0359,  26000],# 2.0h\n",
    "[ 18, 8, 4, 512, 2048, 160, 117.8, 3.2839, 3.0413, 30000], # 2.3h 12.1G\n",
    "[ 18, 8, 4, 512, 2048, 160, 117.8, 3.3738, 3.0349,  26000],# 1.9h\n",
    "\n",
    "[ 18, 4, 2, 512, 2048, 160, 100.2, 3.3768, 3.0514, 15000], # 1.1h\n",
    "\n",
    "\n",
    "# local best for H6(3): 3.0224  (best)\n",
    "[ 18, 6, 3, 816, 3264, 240, 248.4, 3.7677, 3.0439, 30000], # 2.2h\n",
    "[ 18, 6, 3, 816, 3264, 240, 248.4, 3.9872, 3.0844,  39000],# 2.5h\n",
    "[ 18, 6, 3, 816, 3264, 224, 244.2, 3.7712, 3.0388, 30000], # 2.2h\n",
    "[ 18, 6, 3, 816, 3264, 224, 244.2, 3.8019, 3.0495,  39000],# 2.5h //3\n",
    "[ 18, 6, 3, 816, 3264, 208, 240.0, 3.6092, 3.0384, 30000], # 2.1h\n",
    "[ 18, 6, 3, 816, 3264, 208, 240.0, 3.6649, 3.0451,  39000],# 2.4h //3\n",
    "[ 18, 6, 3, 816, 3264, 192, 235.8, 3.7519, 3.0444, 30000], # 2.8h 15.4G\n",
    "[ 18, 6, 3, 816, 3264, 192, 235.8, 3.8502, 3.0484,  39000],# 2.3h //3\n",
    "[ 18, 6, 3, 816, 3264, 176, 231.5, 3.5848, 3.0373, 30000], # 2.7h\n",
    "[ 18, 6, 3, 816, 3264, 176, 231.5, 3.8920, 3.0542,  39000],# 2.3h //3\n",
    "[ 18, 6, 3, 816, 3264, 160, 227.3, 3.6916, 3.0413, 30000], # 2.6h\n",
    "[ 18, 6, 3, 816, 3264, 160, 227.3, 3.6981, 3.0381,  39000],# 2.2h 11.7G //3\n",
    "\n",
    "[ 18, 6, 3, 768, 3072, 256, 229.9, 3.7808, 3.0432,  39000],# 2.5h //3\n",
    "[ 18, 6, 3, 768, 3072, 240, 225.9, 3.7256, 3.0473, 30000], # 2.1h\n",
    "[ 18, 6, 3, 768, 3072, 240, 225.9, 4.0722, 3.1678,  39000],# 2.4h //3\n",
    "[ 18, 6, 3, 768, 3072, 224, 221.9, 3.9431, 3.0520, 30000], # 2.0h 14.9G\n",
    "[ 18, 6, 3, 768, 3072, 224, 221.9, 3.6359, 3.0365,  39000],# 2.4h //3\n",
    "[ 18, 6, 3, 768, 3072, 208, 217.9, 3.7937, 3.0700, 30000], # 2.0h\n",
    "[ 18, 6, 3, 768, 3072, 208, 217.9, 3.7903, 3.0507,  39000],# 2.3h //3\n",
    "[ 18, 6, 3, 768, 3072, 192, 213.9, 3.8207, 3.0785, 30000], # 2.5h\n",
    "[ 18, 6, 3, 768, 3072, 192, 213.9, 3.6776, 3.0412,  39000],# 2.2h //3\n",
    "[ 18, 6, 3, 768, 3072, 176, 209.9, 3.7337, 3.0488, 30000], # 2.5h\n",
    "[ 18, 6, 3, 768, 3072, 176, 209.9, 3.7534, 3.0406,  26000],# 2.1h\n",
    "[ 18, 6, 3, 768, 3072, 160, 206.0, 3.6075, 3.0379, 30000], # 2.4h\n",
    "[ 18, 6, 3, 768, 3072, 160, 206.0, 3.7055, 3.0401,  26000],# 2.0h\n",
    "\n",
    "[ 18, 6, 3, 720, 2880, 288, 215.5, 3.6965, 3.0385,  26000],# 2.7h 15.4G\n",
    "[ 18, 6, 3, 720, 2880, 272, 211.8, 3.5853, 3.0376,  26000],# 2.7h\n",
    "[ 18, 6, 3, 720, 2880, 256, 208.0, 3.6505, 3.0436,  26000],# 2.4h\n",
    "[ 18, 6, 3, 720, 2880, 240, 204.3, 3.5242, 3.0363, 30000], # 2.1h 14.7G\n",
    "[ 18, 6, 3, 720, 2880, 240, 204.3, 3.7960, 3.0479,  26000],# 2.3h\n",
    "[ 18, 6, 3, 720, 2880, 224, 200.6, 3.5910, 3.0316, 30000], # 2.0h\n",
    "[ 18, 6, 3, 720, 2880, 224, 200.6, 3.7618, 3.0523,  27000],# 2.3h\n",
    "[ 18, 6, 3, 720, 2880, 224, 200.6, 3.6133, 3.0319,  26000],# 2.3h\n",
    "[ 18, 6, 3, 720, 2880, 224, 200.6, 3.6017,+3.0290,  25000],# 2.2h\n",
    "[ 18, 6, 3, 720, 2880, 224, 200.6, 3.7286, 3.0454,  24000],# 2.1h\n",
    "[ 18, 6, 3, 720, 2880, 208, 196.8, 3.7087, 3.1111, 30000], # 1.9h\n",
    "[ 18, 6, 3, 720, 2880, 208, 196.8, 3.6631, 3.0442,  27000],# 2.3h\n",
    "[ 18, 6, 3, 720, 2880, 208, 196.8, 3.6444, 3.0314,  26000],# 2.2h\n",
    "[ 18, 6, 3, 720, 2880, 208, 196.8, 3.6618, 3.0361,  25000],# 2.1h\n",
    "[ 18, 6, 3, 720, 2880, 192, 193.1, 3.6531, 3.0511,  32000],# 2.6h\n",
    "[ 18, 6, 3, 720, 2880, 192, 193.1, 3.4915,+3.0292,  31000],# 2.5h\n",
    "[ 18, 6, 3, 720, 2880, 192, 193.1, 3.4869,+3.0290, 30000], # 2.5h\n",
    "[ 18, 6, 3, 720, 2880, 192, 193.1, 3.7847, 3.0560,  29000],# 2.3h\n",
    "[ 18, 6, 3, 720, 2880, 192, 193.1, 3.6660, 3.0397,  26000],# 2.1h\n",
    "[ 18, 6, 3, 720, 2880, 176, 189.4, 3.5335, 3.0366, 30000], # 2.4h\n",
    "[ 18, 6, 3, 720, 2880, 176, 189.4, 3.6088, 3.0332,  26000],# 2.0h\n",
    "[ 18, 6, 3, 720, 2880, 160, 185.6, 3.5018, 3.0360, 30000], # 2.3h\n",
    "[ 18, 6, 3, 720, 2880, 160, 185.6, 3.6123, 3.0388,  26000],# 2.0h\n",
    "\n",
    "[ 18, 6, 3, 672, 2688, 288, 194.2, 3.5929, 3.0333, 30000], # 3.1h\n",
    "[ 18, 6, 3, 672, 2688, 288, 194.2, 3.6838, 3.0369,  26000],# 2.6h\n",
    "[ 18, 6, 3, 672, 2688, 272, 190.7, 3.4888, 3.0414,  31000],# 3.1h\n",
    "[ 18, 6, 3, 672, 2688, 272, 190.7, 3.5716, 3.0308, 30000], # 3.1h 13.8G\n",
    "[ 18, 6, 3, 672, 2688, 272, 190.7, 3.6535, 3.0554,  29000],# 2.9h 13.7G\n",
    "[ 18, 6, 3, 672, 2688, 272, 190.7, 3.6048, 3.0410,  26000],# 2.6h 13.7G\n",
    "[ 18, 6, 3, 672, 2688, 256, 187.2, 3.6382, 3.0567,  32000],# 2.8h\n",
    "[ 18, 6, 3, 672, 2688, 256, 187.2, 3.4586,+3.0270,  31000],# 2.8h\n",
    "[ 18, 6, 3, 672, 2688, 256, 187.2, 3.4455,+3.0295, 30000], # 2.1h\n",
    "[ 18, 6, 3, 672, 2688, 256, 187.2, 3.4662,+3.0272,  29000],# 2.6h\n",
    "[ 18, 6, 3, 672, 2688, 256, 187.2, 3.6440, 3.0374,  28000],# 2.5h\n",
    "[ 18, 6, 3, 672, 2688, 256, 187.2, 3.5893, 3.0347,  26000],# 2.3h\n",
    "[ 18, 6, 3, 672, 2688, 240, 183.7, 3.4941, 3.0354,  31000],# 2.7h\n",
    "[ 18, 6, 3, 672, 2688, 240, 183.7, 3.4279,+3.0285, 30000], # 2.0h\n",
    "[ 18, 6, 3, 672, 2688, 240, 183.7, 3.4988, 3.0322,  29000],# 2.5h\n",
    "[ 18, 6, 3, 672, 2688, 240, 183.7, 3.8263, 3.0750,  26000],# 2.3h\n",
    "[ 18, 6, 3, 672, 2688, 224, 180.2, 3.4278, 3.0349, 30000], # 1.9h\n",
    "[ 18, 6, 3, 672, 2688, 224, 180.2, 3.5482, 3.0383,  27000],# 2.3h\n",
    "[ 18, 6, 3, 672, 2688, 224, 180.2, 3.5449,+3.0283,  26000],# 2.2h\n",
    "[ 18, 6, 3, 672, 2688, 224, 180.2, 3.8344, 3.0767,  25000],# 2.1h\n",
    "[ 18, 6, 3, 672, 2688, 208, 176.7, 3.5759, 3.0457,  31000],# 2.0h\n",
    "[ 18, 6, 3, 672, 2688, 208, 176.7, 3.4613,+3.0264, 30000], # 1.9h\n",
    "[ 18, 6, 3, 672, 2688, 208, 176.7, 3.4602, 3.0304,  29000],# 1.9h\n",
    "[ 18, 6, 3, 672, 2688, 208, 176.7, 3.5724, 3.0329,  28000],# 1.8h\n",
    "[ 18, 6, 3, 672, 2688, 208, 176.7, 3.5001,+3.0284,  27000],# 2.2h 12.8G\n",
    "[ 18, 6, 3, 672, 2688, 208, 176.7, 3.5501, 3.0338,  26000],# 2.2h 13.0G\n",
    "[ 18, 6, 3, 672, 2688, 208, 176.7, 3.6657, 3.0431,  25000],# 2.0h\n",
    "[ 18, 6, 3, 672, 2688, 192, 173.3, 3.6488, 3.0667, 30000], # 2.4h 15.1G\n",
    "[ 18, 6, 3, 672, 2688, 192, 173.3, 3.7083, 3.0616,  28000],# 2.2h\n",
    "[ 18, 6, 3, 672, 2688, 192, 173.3, 3.4817, 3.0310,  27000],# 2.1h\n",
    "[ 18, 6, 3, 672, 2688, 192, 173.3, 3.5490,+3.0303,  26000],# 2.0h\n",
    "[ 18, 6, 3, 672, 2688, 192, 173.3, 3.6275, 3.0389,  25000],# 1.9h 12.8G\n",
    "[ 18, 6, 3, 672, 2688, 176, 169.8, 3.6161, 3.0522, 30000], # 2.3h 15.2G\n",
    "[ 18, 6, 3, 672, 2688, 176, 169.8, 3.6166, 3.0378,  26000],# 2.0h\n",
    "[ 18, 6, 3, 672, 2688, 160, 166.3, 3.6426, 3.0620, 30000], # 2.2h 15.2G\n",
    "[ 18, 6, 3, 672, 2688, 160, 166.3, 3.5152, 3.0376,  26000],# 1.9h\n",
    "\n",
    "[ 18, 6, 3, 624, 2496, 288, 173.8, 3.4245, 3.0365,  31000],# 4.5h\n",
    "[ 18, 6, 3, 624, 2496, 288, 173.8, 3.4039,+3.0289, 30000], # 3.0h\n",
    "[ 18, 6, 3, 624, 2496, 288, 173.8, 3.4274, 3.0350,  29000],# 4.0h\n",
    "[ 18, 6, 3, 624, 2496, 288, 173.8, 3.7678, 3.0868,  26000],# 2.6h 13.6G\n",
    "[ 18, 6, 3, 624, 2496, 272, 170.6, 3.3842, 3.0320,  31000],# 4.2h\n",
    "[ 18, 6, 3, 624, 2496, 272, 170.6, 3.4280,+3.0282, 30000], # 2.9h\n",
    "[ 18, 6, 3, 624, 2496, 272, 170.6, 3.5693, 3.0408,  29000],# 3.8h\n",
    "[ 18, 6, 3, 624, 2496, 272, 170.6, 3.5153, 3.0405,  26000],# 2.5h\n",
    "[ 18, 6, 3, 624, 2496, 256, 167.3, 3.4703, 3.0359, 30000], # 2.6h\n",
    "[ 18, 6, 3, 624, 2496, 256, 167.3, 3.4437, 3.0338,  27000],# 2.3h\n",
    "[ 18, 6, 3, 624, 2496, 256, 167.3, 3.5098,+3.0286,  26000],# 2.2h\n",
    "[ 18, 6, 3, 624, 2496, 256, 167.3, 3.4784,+3.0294,  25000],# 2.1h\n",
    "[ 18, 6, 3, 624, 2496, 256, 167.3, 3.5762, 3.0387,  24000],# 2.0h\n",
    "[ 18, 6, 3, 624, 2496, 240, 164.1, 3.5905, 3.0577,  31000],# 2.0h\n",
    "[ 18, 6, 3, 624, 2496, 240, 164.1, 3.4592,+3.0267, 30000], # 1.9h\n",
    "[ 18, 6, 3, 624, 2496, 240, 164.1, 3.6504, 3.0660,  29000],# 1.9h\n",
    "[ 18, 6, 3, 624, 2496, 240, 164.1, 3.4386, 3.0347,  28000],# 1.8h\n",
    "[ 18, 6, 3, 624, 2496, 240, 164.1, 3.4405,+3.0292,  27000],# 2.2h\n",
    "[ 18, 6, 3, 624, 2496, 240, 164.1, 3.5138,+3.0271,  26000],# 2.2h\n",
    "[ 18, 6, 3, 624, 2496, 240, 164.1, 3.5109,+3.0306,  25000],# 2.1h\n",
    "[ 18, 6, 3, 624, 2496, 240, 164.1, 3.5161,+3.0250,  24000],# 2.0h\n",
    "[ 18, 6, 3, 624, 2496, 240, 164.1, 3.5647,+3.0264,  23000],# 1.9h\n",
    "[ 18, 6, 3, 624, 2496, 240, 164.1, 3.6561, 3.0382,  22000],# 1.9h 12.6G\n",
    "[ 18, 6, 3, 624, 2496, 224, 160.9, 3.4691, 3.0347, 30000], # 1.9h\n",
    "[ 18, 6, 3, 624, 2496, 224, 160.9, 3.4937, 3.0345,  26000],# 2.1h\n",
    "[ 18, 6, 3, 624, 2496, 208, 157.6, 3.3364, 3.0346,  33000],# 2.7h\n",
    "[ 18, 6, 3, 624, 2496, 208, 157.6, 3.3608,+3.0243,  32000],# 2.5h\n",
    "[+18, 6, 3, 624, 2496, 208, 157.6, 3.3532,+3.0224,  31000],# 2.4h  minGemma-hidden_layers18-att_heads6-kv_heads3-hidden624-intermediate2496-head_dim208-T1024--2025-11-05-02-30\n",
    "[ 18, 6, 3, 624, 2496, 208, 157.6, 3.3922,+3.0284, 30000], # 1.8h\n",
    "[ 18, 6, 3, 624, 2496, 208, 157.6, 3.4571, 3.0303,  29000],# 2.3h\n",
    "[ 18, 6, 3, 624, 2496, 208, 157.6, 3.4565, 3.0317,  28000],# 2.2h\n",
    "[ 18, 6, 3, 624, 2496, 208, 157.6, 3.4612,+3.0303,  27000],# 2.1h\n",
    "[ 18, 6, 3, 624, 2496, 208, 157.6, 3.4774,+3.0287,  26000],# 2.0h\n",
    "[ 18, 6, 3, 624, 2496, 208, 157.6, 3.4829,+3.0269,  25000],# 1.9h\n",
    "[ 18, 6, 3, 624, 2496, 208, 157.6, 3.5119, 3.0352,  24000],# 1.9h\n",
    "[ 18, 6, 3, 624, 2496, 192, 154.4, 3.3715, 3.0346, 30000], # 1.7h\n",
    "[ 18, 6, 3, 624, 2496, 192, 154.4, 3.5119, 3.0376,  26000],# 1.9h\n",
    "[ 18, 6, 3, 624, 2496, 176, 151.2, 3.4083, 3.0376,  32000],# 2.4h\n",
    "[ 18, 6, 3, 624, 2496, 176, 151.2, 3.3260,+3.0280,  31000],# 2.3h 15.6G\n",
    "[ 18, 6, 3, 624, 2496, 176, 151.2, 3.4251,+3.0288, 30000], # 2.2h\n",
    "[ 18, 6, 3, 624, 2496, 176, 151.2, 3.4180, 3.0308,  29000],# 2.1h\n",
    "[ 18, 6, 3, 624, 2496, 176, 151.2, 3.4094, 3.0327,  28000],# 2.1h\n",
    "[ 18, 6, 3, 624, 2496, 176, 151.2, 3.4658,+3.0264,  27000],# 2.0h\n",
    "[ 18, 6, 3, 624, 2496, 176, 151.2, 3.5067, 3.0303,  26000],# 1.9h 12.3G\n",
    "[ 18, 6, 3, 624, 2496, 176, 151.2, 3.4546, 3.0337,  25000],# 1.8h\n",
    "[ 18, 6, 3, 624, 2496, 160, 147.9, 3.4730, 3.0362, 30000], # 2.1h\n",
    "[ 18, 6, 3, 624, 2496, 160, 147.9, 3.4981, 3.0342,  26000],# 1.8h\n",
    "\n",
    "[ 18, 6, 3, 576, 2304, 304, 157.5, 3.4379, 3.0326,  26000],# 2.5h\n",
    "[ 18, 6, 3, 576, 2304, 288, 154.5, 3.4018, 3.0341, 30000], # 2.9h\n",
    "[ 18, 6, 3, 576, 2304, 288, 154.5, 3.5820, 3.0680,  27000],# 2.6h 13.2G\n",
    "[ 18, 6, 3, 576, 2304, 288, 154.5, 3.4454,+3.0290,  26000],# 2.5h\n",
    "[ 18, 6, 3, 576, 2304, 288, 154.5, 3.4764, 3.0373,  25000],# 2.4h\n",
    "[ 18, 6, 3, 576, 2304, 272, 151.5, 3.3859, 3.0328, 30000], # 2.8h\n",
    "[ 18, 6, 3, 576, 2304, 272, 151.5, 3.4366, 3.0365,  26000],# 2.4h\n",
    "[ 18, 6, 3, 576, 2304, 256, 148.5, 3.3641, 3.0315, 30000], # 1.9h\n",
    "[ 18, 6, 3, 576, 2304, 256, 148.5, 3.3994, 3.0320,  26000],# 2.1h\n",
    "[ 18, 6, 3, 576, 2304, 256, 148.5, 3.4606, 3.0328,  25000],# 2.1h 12.5G\n",
    "[ 18, 6, 3, 576, 2304, 240, 145.5, 3.3388, 3.0341,  31000],# 1.9h\n",
    "[ 18, 6, 3, 576, 2304, 240, 145.5, 3.3367,+3.0282, 30000], # 1.9h\n",
    "[ 18, 6, 3, 576, 2304, 240, 145.5, 3.4579, 3.0380,  29000],# 1.8h\n",
    "[ 18, 6, 3, 576, 2304, 240, 145.5, 3.4098, 3.0326,  28000],# 1.7h\n",
    "[ 18, 6, 3, 576, 2304, 240, 145.5, 3.4293, 3.0313,  27000],# 2.2h\n",
    "[ 18, 6, 3, 576, 2304, 240, 145.5, 3.4723, 3.0316,  26000],# 2.1h\n",
    "[ 18, 6, 3, 576, 2304, 240, 145.5, 3.4353,+3.0271,  25000],# 2.0h\n",
    "[ 18, 6, 3, 576, 2304, 240, 145.5, 3.5268,+3.0296,  24000],# 1.9h\n",
    "[ 18, 6, 3, 576, 2304, 240, 145.5, 3.5790, 3.0411,  23000],# 1.9h\n",
    "[ 18, 6, 3, 576, 2304, 224, 142.5, 3.4649, 3.0364, 30000], # 1.8h 12.4G\n",
    "[ 18, 6, 3, 576, 2304, 224, 142.5, 3.5289, 3.0372,  27000],# 2.1h\n",
    "[+18, 6, 3, 576, 2304, 224, 142.5, 3.4368,+3.0234,  26000],# 1.6h 12.3G  minGemma-hidden_layers18-att_heads6-kv_heads3-hidden576-intermediate2304-head_dim224-T1024--2025-10-28-14-50.pth\n",
    "[ 18, 6, 3, 576, 2304, 224, 142.5, 3.4464, 3.0342,  25000],# 1.9h\n",
    "[ 18, 6, 3, 576, 2304, 208, 139.5, 3.5361, 3.0628, 30000], # 1.7h\n",
    "[ 18, 6, 3, 576, 2304, 208, 139.5, 3.4918, 3.0354,  26000],# 2.0h\n",
    "[ 18, 6, 3, 576, 2304, 192, 136.6, 3.3467, 3.0316, 30000], # 2.2h\n",
    "[ 18, 6, 3, 576, 2304, 192, 136.6, 3.4063, 3.0343,  26000],# 1.9h\n",
    "[ 18, 6, 3, 576, 2304, 176, 133.6, 3.3643, 3.0300, 30000], # 2.1h\n",
    "[ 18, 6, 3, 576, 2304, 176, 133.6, 3.4704, 3.0344,  26000],# 1.8h\n",
    "[ 18, 6, 3, 576, 2304, 160, 130.6, 3.2973, 3.0366, 30000], # 2.0h\n",
    "[ 18, 6, 3, 576, 2304, 160, 130.6, 3.5104, 3.0398,  26000],# 1.7h\n",
    "\n",
    "[ 18, 6, 3, 528, 2112, 288, 136.1, 3.3469, 3.0402, 30000], # 2.8h\n",
    "[ 18, 6, 3, 528, 2112, 288, 136.1, 3.4228, 3.0419,  26000],# 2.4h\n",
    "[ 18, 6, 3, 528, 2112, 272, 133.4, 3.3407, 3.0369, 30000], # 2.7h\n",
    "[ 18, 6, 3, 528, 2112, 272, 133.4, 3.4280, 3.0419,  26000],# 2.4h\n",
    "[ 18, 6, 3, 528, 2112, 256, 130.7, 3.3199, 3.0314, 30000], # 2.4h\n",
    "[ 18, 6, 3, 528, 2112, 256, 130.7, 3.4296, 3.0392,  26000],# 2.1h\n",
    "[ 18, 6, 3, 528, 2112, 240, 127.9, 3.3202, 3.0366, 30000], # 1.8h\n",
    "[ 18, 6, 3, 528, 2112, 240, 127.9, 3.3906, 3.0328,  26000],# 2.0h\n",
    "[ 18, 6, 3, 528, 2112, 224, 125.2, 3.5130, 3.0598, 30000], # 1.8h\n",
    "[ 18, 6, 3, 528, 2112, 224, 125.2, 3.5256, 3.0442,  26000],# 2.0h\n",
    "[ 18, 6, 3, 528, 2112, 208, 122.4, 3.3464, 3.0353, 30000], # 1.7h\n",
    "[ 18, 6, 3, 528, 2112, 208, 122.4, 3.3331, 3.0386,  26000],# 1.9h 11.8G\n",
    "[ 18, 6, 3, 528, 2112, 192, 119.7, 3.3315, 3.0333, 30000], # 2.1h\n",
    "[ 18, 6, 3, 528, 2112, 192, 119.7, 3.3665, 3.0397,  26000],# 1.8h\n",
    "[ 18, 6, 3, 528, 2112, 176, 117.0, 3.3436, 3.0333, 30000], # 2.1h\n",
    "[ 18, 6, 3, 528, 2112, 176, 117.0, 3.4214, 3.0375,  26000],# 1.8h\n",
    "[ 18, 6, 3, 528, 2112, 160, 114.2, 3.4004, 3.0449, 30000], # 2.0h\n",
    "[ 18, 6, 3, 528, 2112, 160, 114.2, 3.3572, 3.0425,  26000],# 1.7h\n",
    "\n",
    "\n",
    "[ 18, 8, 4, 704, 2816, 256, 220.4, 3.6698, 3.1012, 20000], # B12 lr13.5e-4 WD1.0 2.6h # old hyper param  w/ Grad-Acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "81e6fdce-9338-4dd7-ab23-7a200226dbd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "190.464\n",
      "L18 att6 kv_heads3 hidden624 intermediate2496 head_dim208 T1024\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='15500' max='15500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [15500/15500 2:28:13, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>15500</td>\n",
       "      <td>3.353200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 18, 6, 3, 624, 2496, 208, 157.6, 3.3532, 3.0224, 31000],\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt; import numpy as np; import time, torch; device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "from transformers import AutoTokenizer, TrainingArguments, DefaultDataCollator, Trainer\n",
    "vocab_size = 50257 # =tokenizer.vocab_size  # FIX!!! # G256128    ### T=256 for minGemma # G8192 for real Gemma\n",
    "num_hidden_layers =  18 # 8 # G28 G18 #blocks\n",
    "num_attention_heads = 6 # 4 # G16 G8\n",
    "num_key_value_heads = 3 # 4 # G16 G1\n",
    "hidden_size = num_attention_heads*104 # 128 # G3072 G2048 # embedding dimension\n",
    "intermediate_size = hidden_size*4 # x4 or x8 # time limiting factor #512 # G24576 G16384  # MLP inner dim\n",
    "head_dim = 208 # 32 # G256 # dim in attention # Doesn't affect time\n",
    "rms_norm_eps = 1e-6 # 1e-6\n",
    "rope_theta = 1000.0 # scale freq is small for S-model. 1000 might work too # G10000.0\n",
    "\n",
    "def apply_rotary_emb(x: torch.Tensor, dim: int) -> torch.Tensor: # seq_len = x.size(1) # N\n",
    "    freqs = 1.0 / (rope_theta ** (torch.arange(0, dim, 2, device=device).float() / dim)) # Dynamically compute frequency cis\n",
    "    t = torch.arange(x.size(1), device=device); freqs = torch.outer(t, freqs).float(); freqs_cis = torch.polar(torch.ones_like(freqs), freqs)  # complex64\n",
    "    x_ = torch.view_as_complex(torch.stack(torch.chunk(x.transpose(1, 2).float(), 2, dim=-1), dim=-1))\n",
    "    x_out = torch.view_as_real(x_ * freqs_cis.unsqueeze(0)).type_as(x)  # Ensure batch dimension is handled\n",
    "    x_out = torch.cat(torch.chunk(x_out, 2, dim=-1), dim=-2)\n",
    "    return x_out.reshape(x_out.shape[0], x_out.shape[1], x_out.shape[2], -1).transpose(1, 2)\n",
    "\n",
    "class RMSNorm(torch.nn.Module): # RMS:4.326552, RMS_no_weight:4.410741 # RMS':4.554899\n",
    "    def __init__(self, dim: int = hidden_size):\n",
    "        super().__init__(); self.weight = torch.nn.Parameter(torch.zeros(dim)) # one weight per feature to be learned\n",
    "    def _norm(self, x): # mean square for each feature (across the last dimension)\n",
    "        return x * torch.rsqrt(x.pow(2).mean(-1, keepdim=True) + rms_norm_eps)\n",
    "    def forward(self, x): # ensure the data type matches the input.\n",
    "        return self._norm(x.float()).type_as(x) * (1 + self.weight)\n",
    "        \n",
    "class GemmaAttention(torch.nn.Module): # MQA = K,V shared by 4Qs\n",
    "    def __init__(self):\n",
    "        super().__init__(); self.qkv_proj = torch.nn.Linear(hidden_size, (num_attention_heads + 2 * num_key_value_heads) * head_dim, bias=False); self.o_proj = torch.nn.Linear(num_attention_heads * head_dim, hidden_size, bias=False) # concatenated attention outputs back to the hidden size.\n",
    "    def forward(self, hidden_states: torch.Tensor,) -> torch.Tensor:  # in=(B, T, hidden_size)\n",
    "        batch_size, input_len, _ = hidden_states.shape\n",
    "        qkv = self.qkv_proj(hidden_states)\n",
    "        xq, xk, xv = qkv.split([num_attention_heads * head_dim, num_key_value_heads * head_dim, num_key_value_heads * head_dim],dim=-1)\n",
    "        xq = xq.view(batch_size, -1, num_attention_heads, head_dim); xk = xk.view(batch_size, -1, num_key_value_heads, head_dim); xv = xv.view(batch_size, -1, num_key_value_heads, head_dim)\n",
    "        xq = apply_rotary_emb(xq, head_dim); xk = apply_rotary_emb(xk, head_dim)\n",
    "        if num_key_value_heads != num_attention_heads:  # Q/KV multiples of K and V to match Q\n",
    "            xk = torch.repeat_interleave(xk, num_attention_heads // num_key_value_heads, dim=2) # [B, T, n_local_heads, head_dim]\n",
    "            xv = torch.repeat_interleave(xv, num_attention_heads // num_key_value_heads, dim=2)\n",
    "        q = xq.transpose(1, 2); k = xk.transpose(1, 2); v = xv.transpose(1, 2) # [batch_size, n_local_heads, input_len, head_dim]\n",
    "        output = torch.nn.functional.scaled_dot_product_attention(q, k, v, attn_mask=None, dropout_p=0, is_causal=True) # B nh T hs        \n",
    "        output = output.transpose(1, 2).contiguous().view(batch_size, input_len, -1)  # [B, T, \"hidden_dim\"]\n",
    "        return self.o_proj(output)\n",
    "\n",
    "class GemmaDecoderLayer(torch.nn.Module): # normalize before and after the attention mechanism\n",
    "    def __init__(self):\n",
    "        super().__init__(); self.self_attn = GemmaAttention(); self.input_layernorm = RMSNorm(); self.post_attention_layernorm = RMSNorm(); self.gate_proj = torch.nn.Linear(hidden_size, intermediate_size); self.up_proj = torch.nn.Linear(hidden_size, intermediate_size); self.down_proj = torch.nn.Linear(intermediate_size, hidden_size) # mlp\n",
    "    def forward(self, hidden_states: torch.Tensor) -> torch.Tensor:  # input_size = (B, T, hidden_size)\n",
    "        residual = hidden_states # Self Attention Block\n",
    "        hidden_states = self.input_layernorm(hidden_states); hidden_states = self.self_attn(hidden_states=hidden_states)\n",
    "        hidden_states = residual + hidden_states\n",
    "        residual = hidden_states # MLP Block\n",
    "        hidden_states = self.post_attention_layernorm(hidden_states); gate = torch.nn.functional.gelu(self.gate_proj(hidden_states)); up = self.up_proj(hidden_states); fuse = gate * up; hidden_states = self.down_proj(fuse) # mlp\n",
    "        return residual + hidden_states\n",
    "\n",
    "class minGemma(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__(); self.embedder = torch.nn.Embedding(vocab_size, hidden_size); self.layers = torch.nn.ModuleList(GemmaDecoderLayer() for _ in range(num_hidden_layers)); self.norm = RMSNorm();\n",
    "    def forward(self, input_token_ids: torch.Tensor) -> torch.Tensor: # (B, T)\n",
    "        hidden_states = self.embedder(input_token_ids[:,:-1]) # (B, T) & (vocab_size, hidden_size) -> (B, T, hidden_size)\n",
    "        hidden_states = hidden_states * (hidden_size**0.5)\n",
    "        for i in range(len(self.layers)):\n",
    "            hidden_states = self.layers[i](hidden_states) # shortened too much???\n",
    "        hidden_states = self.norm(hidden_states) # -> (B, T, hidden_size)        \n",
    "        embedder_weight = self.embedder.weight\n",
    "        logits = torch.matmul(hidden_states, embedder_weight.t()); b,t,v=logits.shape; # (B, T, hidden_size) @ (hidden_size, vocab_size) -> (B, T, vocab_size)\n",
    "        loss = torch.nn.functional.cross_entropy(logits.view(b*t,v), input_token_ids[:,1:].reshape(b*t)) #, weight=None, ignore_index=-100, reduction='mean')\n",
    "        return loss, logits # logits, loss\n",
    "\n",
    "def map_to_array5(ix):\n",
    "    common = torch.stack([torch.from_numpy((train_data[i[0]:i[0]+T+1]).astype(np.int64)) for i in ix]); return {'input_token_ids': common}\n",
    "def map_to_array_Val(ix):\n",
    "    common = torch.stack([torch.from_numpy((val_data[i[0]:i[0]+T+1]).astype(np.int64)) for i in ix]); return {'input_token_ids': common}\n",
    "\n",
    "train_data = np.memmap('train_BabyLM_10M.bin', dtype=np.uint16, mode='r'); val_data = np.memmap('val_BabyLM.bin', dtype=np.uint16, mode='r')\n",
    "T=1024; B=12//2; N_step=15500*2; print(T * B * N_step / 1000000) # 0.01 B-tokens being calculated # n_steps=N_step;\n",
    "model = minGemma().to(device); print(f'L{num_hidden_layers}' f' att{num_attention_heads}' f' kv_heads{num_key_value_heads}' f' hidden{hidden_size}' f' intermediate{intermediate_size}' f' head_dim{head_dim}' f' T{T}')\n",
    "\n",
    "# Normal # lr_scheduler_type=\"linear\" can be omitted\n",
    "training_args = TrainingArguments(gradient_accumulation_steps=2, learning_rate=24.0e-4, weight_decay=1.2, num_train_epochs=1, logging_strategy='epoch', output_dir='./', bf16=True, per_device_train_batch_size=B, per_device_eval_batch_size=B, eval_strategy='no', save_strategy='no', report_to='none', remove_unused_columns=False, dataloader_pin_memory=True) #, dataloader_num_workers=4\n",
    "trainer = Trainer(model=model, args=training_args, train_dataset=torch.utils.data.TensorDataset(torch.randint(len(train_data)-T-1, (B*N_step,))), data_collator=map_to_array5);\n",
    "result = trainer.train(); tloss=result[2][\"train_loss\"] # trainer = Trainer(model=model, args=training_args, eval_dataset=torch.utils.data.TensorDataset(torch.randint(len(val_data)-T-1, (B*400*4,))), data_collator=map_to_array_Val); trainer.can_return_loss = True; loss_current = trainer.evaluate()[\"eval_loss\"]\n",
    "\n",
    "loss = []; model.eval(); B2=16; B2=12//2; torch.cuda.empty_cache();\n",
    "for k in range(5000*2): #4000 # std=0.0056 for 1000 with 89sec\n",
    "    val_ind = torch.randint(len(val_data)-T-1, (B2,)); common = (torch.stack([torch.from_numpy((val_data[i:i+T+1]).astype(np.int64)) for i in val_ind]))\n",
    "    loss += [model(common.to('cuda', non_blocking=True))[0].item()]\n",
    "if torch.Tensor(loss).mean() < 3.0224:\n",
    "    torch.save(model.state_dict(), f'{model.__class__.__name__}' f'-hidden_layers{num_hidden_layers}' f'-att_heads{num_attention_heads}' f'-kv_heads{num_key_value_heads}' f'-hidden{hidden_size}' f'-intermediate{intermediate_size}' f'-head_dim{head_dim}' f'-T{T}' f'--{time.strftime(\"%Y-%m-%d-%H-%M\")}.pth')\n",
    "model.train(); del common; print(f'[ {num_hidden_layers}, {num_attention_heads}, {num_key_value_heads}, {hidden_size}, {intermediate_size}, {head_dim}, {sum(p.numel() for p in model.parameters()) / 10**6:.1f}, {tloss:.4f}, {torch.Tensor(loss).mean():.4f}, {N_step}],')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "dc2d7b28-eeed-4b2f-9691-c074271308c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "159.744\n",
      "L18 att6 kv_heads3 hidden576 intermediate2304 head_dim224 T1024\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13000' max='13000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13000/13000 2:04:10, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>3.436800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 18, 6, 3, 576, 2304, 224, 142.5, 3.4368, 3.0234, 26000],\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt; import numpy as np; import time, torch; device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "from transformers import AutoTokenizer, TrainingArguments, DefaultDataCollator, Trainer\n",
    "vocab_size = 50257 # =tokenizer.vocab_size  # FIX!!! # G256128    ### T=256 for minGemma # G8192 for real Gemma\n",
    "num_hidden_layers =  18 # 8 # G28 G18 #blocks\n",
    "num_attention_heads = 6 # 4 # G16 G8\n",
    "num_key_value_heads = 3 # 4 # G16 G1\n",
    "hidden_size = num_attention_heads*96 # 128 # G3072 G2048 # embedding dimension\n",
    "intermediate_size = hidden_size*4 # x4 or x8 # time limiting factor #512 # G24576 G16384  # MLP inner dim\n",
    "head_dim = 224 # 32 # G256 # dim in attention # Doesn't affect time\n",
    "rms_norm_eps = 1e-6 # 1e-6\n",
    "rope_theta = 1000.0 # scale freq is small for S-model. 1000 might work too # G10000.0\n",
    "\n",
    "def apply_rotary_emb(x: torch.Tensor, dim: int) -> torch.Tensor: # seq_len = x.size(1) # N\n",
    "    freqs = 1.0 / (rope_theta ** (torch.arange(0, dim, 2, device=device).float() / dim)) # Dynamically compute frequency cis\n",
    "    t = torch.arange(x.size(1), device=device); freqs = torch.outer(t, freqs).float(); freqs_cis = torch.polar(torch.ones_like(freqs), freqs)  # complex64\n",
    "    x_ = torch.view_as_complex(torch.stack(torch.chunk(x.transpose(1, 2).float(), 2, dim=-1), dim=-1))\n",
    "    x_out = torch.view_as_real(x_ * freqs_cis.unsqueeze(0)).type_as(x)  # Ensure batch dimension is handled\n",
    "    x_out = torch.cat(torch.chunk(x_out, 2, dim=-1), dim=-2)\n",
    "    return x_out.reshape(x_out.shape[0], x_out.shape[1], x_out.shape[2], -1).transpose(1, 2)\n",
    "\n",
    "class RMSNorm(torch.nn.Module): # RMS:4.326552, RMS_no_weight:4.410741 # RMS':4.554899\n",
    "    def __init__(self, dim: int = hidden_size):\n",
    "        super().__init__(); self.weight = torch.nn.Parameter(torch.zeros(dim)) # one weight per feature to be learned\n",
    "    def _norm(self, x): # mean square for each feature (across the last dimension)\n",
    "        return x * torch.rsqrt(x.pow(2).mean(-1, keepdim=True) + rms_norm_eps)\n",
    "    def forward(self, x): # ensure the data type matches the input.\n",
    "        return self._norm(x.float()).type_as(x) * (1 + self.weight)\n",
    "        \n",
    "class GemmaAttention(torch.nn.Module): # MQA = K,V shared by 4Qs\n",
    "    def __init__(self):\n",
    "        super().__init__(); self.qkv_proj = torch.nn.Linear(hidden_size, (num_attention_heads + 2 * num_key_value_heads) * head_dim, bias=False); self.o_proj = torch.nn.Linear(num_attention_heads * head_dim, hidden_size, bias=False) # concatenated attention outputs back to the hidden size.\n",
    "    def forward(self, hidden_states: torch.Tensor,) -> torch.Tensor:  # in=(B, T, hidden_size)\n",
    "        batch_size, input_len, _ = hidden_states.shape\n",
    "        qkv = self.qkv_proj(hidden_states)\n",
    "        xq, xk, xv = qkv.split([num_attention_heads * head_dim, num_key_value_heads * head_dim, num_key_value_heads * head_dim],dim=-1)\n",
    "        xq = xq.view(batch_size, -1, num_attention_heads, head_dim); xk = xk.view(batch_size, -1, num_key_value_heads, head_dim); xv = xv.view(batch_size, -1, num_key_value_heads, head_dim)\n",
    "        xq = apply_rotary_emb(xq, head_dim); xk = apply_rotary_emb(xk, head_dim)\n",
    "        if num_key_value_heads != num_attention_heads:  # Q/KV multiples of K and V to match Q\n",
    "            xk = torch.repeat_interleave(xk, num_attention_heads // num_key_value_heads, dim=2) # [B, T, n_local_heads, head_dim]\n",
    "            xv = torch.repeat_interleave(xv, num_attention_heads // num_key_value_heads, dim=2)\n",
    "        q = xq.transpose(1, 2); k = xk.transpose(1, 2); v = xv.transpose(1, 2) # [batch_size, n_local_heads, input_len, head_dim]\n",
    "        output = torch.nn.functional.scaled_dot_product_attention(q, k, v, attn_mask=None, dropout_p=0, is_causal=True) # B nh T hs        \n",
    "        output = output.transpose(1, 2).contiguous().view(batch_size, input_len, -1)  # [B, T, \"hidden_dim\"]\n",
    "        return self.o_proj(output)\n",
    "\n",
    "class GemmaDecoderLayer(torch.nn.Module): # normalize before and after the attention mechanism\n",
    "    def __init__(self):\n",
    "        super().__init__(); self.self_attn = GemmaAttention(); self.input_layernorm = RMSNorm(); self.post_attention_layernorm = RMSNorm(); self.gate_proj = torch.nn.Linear(hidden_size, intermediate_size); self.up_proj = torch.nn.Linear(hidden_size, intermediate_size); self.down_proj = torch.nn.Linear(intermediate_size, hidden_size) # mlp\n",
    "    def forward(self, hidden_states: torch.Tensor) -> torch.Tensor:  # input_size = (B, T, hidden_size)\n",
    "        residual = hidden_states # Self Attention Block\n",
    "        hidden_states = self.input_layernorm(hidden_states); hidden_states = self.self_attn(hidden_states=hidden_states)\n",
    "        hidden_states = residual + hidden_states\n",
    "        residual = hidden_states # MLP Block\n",
    "        hidden_states = self.post_attention_layernorm(hidden_states); gate = torch.nn.functional.gelu(self.gate_proj(hidden_states)); up = self.up_proj(hidden_states); fuse = gate * up; hidden_states = self.down_proj(fuse) # mlp\n",
    "        return residual + hidden_states\n",
    "\n",
    "class minGemma(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__(); self.embedder = torch.nn.Embedding(vocab_size, hidden_size); self.layers = torch.nn.ModuleList(GemmaDecoderLayer() for _ in range(num_hidden_layers)); self.norm = RMSNorm();\n",
    "    def forward(self, input_token_ids: torch.Tensor) -> torch.Tensor: # (B, T)\n",
    "        hidden_states = self.embedder(input_token_ids[:,:-1]) # (B, T) & (vocab_size, hidden_size) -> (B, T, hidden_size)\n",
    "        hidden_states = hidden_states * (hidden_size**0.5)\n",
    "        for i in range(len(self.layers)):\n",
    "            hidden_states = self.layers[i](hidden_states) # shortened too much???\n",
    "        hidden_states = self.norm(hidden_states) # -> (B, T, hidden_size)        \n",
    "        embedder_weight = self.embedder.weight\n",
    "        logits = torch.matmul(hidden_states, embedder_weight.t()); b,t,v=logits.shape; # (B, T, hidden_size) @ (hidden_size, vocab_size) -> (B, T, vocab_size)\n",
    "        loss = torch.nn.functional.cross_entropy(logits.view(b*t,v), input_token_ids[:,1:].reshape(b*t)) #, weight=None, ignore_index=-100, reduction='mean')\n",
    "        return loss, logits # logits, loss\n",
    "\n",
    "def map_to_array5(ix):\n",
    "    common = torch.stack([torch.from_numpy((train_data[i[0]:i[0]+T+1]).astype(np.int64)) for i in ix]); return {'input_token_ids': common}\n",
    "def map_to_array_Val(ix):\n",
    "    common = torch.stack([torch.from_numpy((val_data[i[0]:i[0]+T+1]).astype(np.int64)) for i in ix]); return {'input_token_ids': common}\n",
    "\n",
    "train_data = np.memmap('train_BabyLM_10M.bin', dtype=np.uint16, mode='r'); val_data = np.memmap('val_BabyLM.bin', dtype=np.uint16, mode='r')\n",
    "T=1024; B=12//2; N_step=13000*2; print(T * B * N_step / 1000000) # 0.01 B-tokens being calculated # n_steps=N_step;\n",
    "model = minGemma().to(device); print(f'L{num_hidden_layers}' f' att{num_attention_heads}' f' kv_heads{num_key_value_heads}' f' hidden{hidden_size}' f' intermediate{intermediate_size}' f' head_dim{head_dim}' f' T{T}')\n",
    "\n",
    "# Normal # lr_scheduler_type=\"linear\" can be omitted\n",
    "training_args = TrainingArguments(gradient_accumulation_steps=2, learning_rate=24.0e-4, weight_decay=1.2, num_train_epochs=1, logging_strategy='epoch', output_dir='./', bf16=True, per_device_train_batch_size=B, per_device_eval_batch_size=B, eval_strategy='no', save_strategy='no', report_to='none', remove_unused_columns=False, dataloader_pin_memory=True) #, dataloader_num_workers=4\n",
    "trainer = Trainer(model=model, args=training_args, train_dataset=torch.utils.data.TensorDataset(torch.randint(len(train_data)-T-1, (B*N_step,))), data_collator=map_to_array5);\n",
    "result = trainer.train(); tloss=result[2][\"train_loss\"] # trainer = Trainer(model=model, args=training_args, eval_dataset=torch.utils.data.TensorDataset(torch.randint(len(val_data)-T-1, (B*400*4,))), data_collator=map_to_array_Val); trainer.can_return_loss = True; loss_current = trainer.evaluate()[\"eval_loss\"]\n",
    "\n",
    "loss = []; model.eval(); B2=16; B2=12//2; torch.cuda.empty_cache();\n",
    "for k in range(5000*2): #4000 # std=0.0056 for 1000 with 89sec\n",
    "    val_ind = torch.randint(len(val_data)-T-1, (B2,)); common = (torch.stack([torch.from_numpy((val_data[i:i+T+1]).astype(np.int64)) for i in val_ind]))\n",
    "    loss += [model(common.to('cuda', non_blocking=True))[0].item()]\n",
    "if torch.Tensor(loss).mean() < 3.0264:\n",
    "    torch.save(model.state_dict(), f'{model.__class__.__name__}' f'-hidden_layers{num_hidden_layers}' f'-att_heads{num_attention_heads}' f'-kv_heads{num_key_value_heads}' f'-hidden{hidden_size}' f'-intermediate{intermediate_size}' f'-head_dim{head_dim}' f'-T{T}' f'--{time.strftime(\"%Y-%m-%d-%H-%M\")}.pth')\n",
    "model.train(); del common; print(f'[ {num_hidden_layers}, {num_attention_heads}, {num_key_value_heads}, {hidden_size}, {intermediate_size}, {head_dim}, {sum(p.numel() for p in model.parameters()) / 10**6:.1f}, {tloss:.4f}, {torch.Tensor(loss).mean():.4f}, {N_step}],')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c6838c-102e-4867-bf00-b9b29311d179",
   "metadata": {},
   "source": [
    "# L12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a791ae-6ea8-40d9-977e-12dd47e04674",
   "metadata": {},
   "outputs": [],
   "source": [
    "# L12 Normal Model T1024 (default: x4 B12 lr24e-4 WD1.2 N13500) w/ Grad_Acc\n",
    "# Best model for each number of heads:  8(4):3.0294, 9(3):3.0254, 10(2):3.0260, 10(5):3.0288, 12(3):3.0283, 12(4):3.0289\n",
    "\n",
    "# local best for H12(4): 3.0289  (bad although only large N_step was tried)\n",
    "[ 12, 12, 4, 816, 3264, 288, 227.2, 4.0300, 3.0643, 30000], # 3.9h\n",
    "[ 12, 12, 4, 816, 3264, 272, 222.2, 4.0500, 3.0727, 30000], # 3.8h\n",
    "[ 12, 12, 4, 816, 3264, 256, 217.2, 4.0191, 3.0603, 30000], # 3.4h\n",
    "[ 12, 12, 4, 816, 3264, 240, 212.2, 3.9712, 3.0945, 30000], # 3.3h\n",
    "[ 12, 12, 4, 816, 3264, 224, 207.2, 4.0281, 3.0797, 30000], # 3.1h\n",
    "[ 12, 12, 4, 816, 3264, 208, 202.2, 3.5572, 3.0366, 30000], # 3.1h\n",
    "[ 12, 12, 4, 816, 3264, 192, 197.2, 3.5552, 3.0358, 30000], # 2.9h 12.4G\n",
    "[ 12, 12, 4, 816, 3264, 176, 192.2, 3.6008, 3.0603, 30000], # 2.8h\n",
    "[ 12, 12, 4, 816, 3264, 160, 187.1, 3.5754, 3.0413, 30000], # 2.7h\n",
    "\n",
    "[ 12, 12, 4, 768, 3072, 288, 208.6, 3.9343, 3.0699, 30000], # 3.7h\n",
    "[ 12, 12, 4, 768, 3072, 272, 203.9, 3.6595, 3.0423, 30000], # 3.6h\n",
    "[ 12, 12, 4, 768, 3072, 256, 199.1, 3.6486, 3.0487, 30000], # 3.2h\n",
    "[ 12, 12, 4, 768, 3072, 240, 194.4, 3.5753, 3.0399, 30000], # 3.1h\n",
    "[ 12, 12, 4, 768, 3072, 224, 189.7, 3.5741, 3.0399, 30000], # 3.0h\n",
    "[ 12, 12, 4, 768, 3072, 208, 185.0, 3.4837, 3.0378, 30000], # 2.9h\n",
    "[ 12, 12, 4, 768, 3072, 192, 180.3, 3.5341, 3.0453, 30000], # 2.7h\n",
    "[ 12, 12, 4, 768, 3072, 176, 175.5, 3.4868, 3.0341, 30000], # 2.6h\n",
    "[ 12, 12, 4, 768, 3072, 160, 170.8, 3.5173, 3.0382, 30000], # 2.5h\n",
    "\n",
    "[ 12, 12, 4, 720, 2880, 288, 190.6, 3.7506, 3.0650,  31000],# 3.8h\n",
    "[ 12, 12, 4, 720, 2880, 288, 190.6, 3.7582, 3.0698, 30000], # 3.7h\n",
    "[ 12, 12, 4, 720, 2880, 288, 190.6, 3.8715, 3.0638,  29000],# 3.5h\n",
    "[ 12, 12, 4, 720, 2880, 272, 186.1, 3.5257, 3.0420,  31000],# 3.7h 13.6G\n",
    "[ 12, 12, 4, 720, 2880, 272, 186.1, 3.5166,+3.0306, 30000], # 3.6h\n",
    "[ 12, 12, 4, 720, 2880, 272, 186.1, 3.5375, 3.0356,  29000],# 3.4h\n",
    "[ 12, 12, 4, 720, 2880, 256, 181.7, 3.6177, 3.0452, 30000], # 3.1h 12.4G\n",
    "[ 12, 12, 4, 720, 2880, 240, 177.3, 3.5404, 3.0415, 30000], # 3.1h\n",
    "[ 12, 12, 4, 720, 2880, 224, 172.9, 3.4643, 3.0349, 30000], # 2.9h\n",
    "[ 12, 12, 4, 720, 2880, 208, 168.4, 3.4421, 3.0387, 30000], # 2.8h\n",
    "[ 12, 12, 4, 720, 2880, 192, 164.0, 3.4921, 3.0397, 30000], # 2.7h\n",
    "[ 12, 12, 4, 720, 2880, 176, 159.6, 3.4843, 3.0420, 30000], # 2.6h\n",
    "[ 12, 12, 4, 720, 2880, 160, 155.2, 3.4495, 3.0344, 30000], # 2.5h 11.5G\n",
    "\n",
    "[ 12, 12, 4, 672, 2688, 288, 173.2, 3.5636, 3.0485, 30000], # 3.6h\n",
    "[ 12, 12, 4, 672, 2688, 272, 169.1, 3.4617, 3.0389, 30000], # 3.5h\n",
    "[ 12, 12, 4, 672, 2688, 256, 165.0, 3.4780, 3.0358, 30000], # 3.1h\n",
    "[ 12, 12, 4, 672, 2688, 240, 160.8, 3.4587, 3.0411, 30000], # 3.0h\n",
    "[ 12, 12, 4, 672, 2688, 224, 156.7, 3.4408, 3.0378, 30000], # 2.9h\n",
    "[ 12, 12, 4, 672, 2688, 208, 152.6, 3.4323, 3.0441, 30000], # 2.8h\n",
    "[ 12, 12, 4, 672, 2688, 192, 148.4, 3.4064, 3.0319, 30000], # 2.6h\n",
    "[ 12, 12, 4, 672, 2688, 192, 148.4, 3.4053, 3.0394,  29000],# 2.5h\n",
    "[ 12, 12, 4, 672, 2688, 176, 144.3, 3.3981, 3.0410,  31000],# 2.5h\n",
    "[ 12, 12, 4, 672, 2688, 176, 144.3, 3.3834,+3.0307, 30000], # 2.5h\n",
    "[ 12, 12, 4, 672, 2688, 176, 144.3, 3.3906,+3.0295,  29000],# 2.4h 11.3G\n",
    "[ 12, 12, 4, 672, 2688, 176, 144.3, 3.4277, 3.0313,  28000],# 2.3h\n",
    "[ 12, 12, 4, 672, 2688, 176, 144.3, 3.4777, 3.0350,  27000],# 2.3h\n",
    "[ 12, 12, 4, 672, 2688, 176, 144.3, 3.4675, 3.0347,  26000],# 2.2h\n",
    "[ 12, 12, 4, 672, 2688, 160, 140.2, 3.4570, 3.0359, 30000], # 2.3h\n",
    "\n",
    "[ 12, 12, 4, 624, 2496, 304, 160.4, 3.4319, 3.0335, 30000], # 3.6h\n",
    "[ 12, 12, 4, 624, 2496, 288, 156.5, 3.3805, 3.0446,  31000],# 3.6h\n",
    "[ 12, 12, 4, 624, 2496, 288, 156.5, 3.4254, 3.0301, 30000], # 3.5h\n",
    "[ 12, 12, 4, 624, 2496, 288, 156.5, 3.4239, 3.0367,  29000],# 3.4h\n",
    "[ 12, 12, 4, 624, 2496, 288, 156.5, 3.4706, 3.0400,  27000],# 3.1h\n",
    "[ 12, 12, 4, 624, 2496, 288, 156.5, 3.4758,+3.0302,  26000],# 3.0h\n",
    "[ 12, 12, 4, 624, 2496, 288, 156.5, 3.4954, 3.0357,  25000],# 2.9h\n",
    "[ 12, 12, 4, 624, 2496, 272, 152.7, 3.5744, 3.0401, 30000], # 3.4h\n",
    "[ 12, 12, 4, 624, 2496, 256, 148.9, 3.3628, 3.0320, 30000], # 3.0h 11.8G\n",
    "[ 12, 12, 4, 624, 2496, 256, 148.9, 3.4444, 3.0360,  29000],# 2.9h\n",
    "[ 12, 12, 4, 624, 2496, 240, 145.0, 3.4734, 3.0355, 30000], # 2.9h 11.7G\n",
    "[ 12, 12, 4, 624, 2496, 224, 141.2, 3.3795, 3.0334, 30000], # 2.8h 11.6G\n",
    "[ 12, 12, 4, 624, 2496, 208, 137.4, 3.3745, 3.0396,  31000],# 2.8h\n",
    "[ 12, 12, 4, 624, 2496, 208, 137.4, 3.3633,+3.0289, 30000], # 2.7h\n",
    "[ 12, 12, 4, 624, 2496, 208, 137.4, 3.4051, 3.0321,  29000],# 2.6h\n",
    "[ 12, 12, 4, 624, 2496, 208, 137.4, 3.4456, 3.0386,  26000],# 2.3h\n",
    "[ 12, 12, 4, 624, 2496, 192, 133.5, 3.3518, 3.0357, 30000], # 2.5h\n",
    "[ 12, 12, 4, 624, 2496, 176, 129.7, 3.3482, 3.0364, 30000], # 2.4h\n",
    "[ 12, 12, 4, 624, 2496, 160, 125.9, 3.3599, 3.0364, 30000], # 2.3h\n",
    "\n",
    "[ 12, 12, 4, 576, 2304, 288, 140.5, 3.3776, 3.0369, 30000], # 3.4h\n",
    "[ 12, 12, 4, 576, 2304, 272, 137.0, 3.4261, 3.0379, 30000], # 3.3h 12.7G\n",
    "[ 12, 12, 4, 576, 2304, 256, 133.4, 3.3694, 3.0423, 30000], # 2.8h\n",
    "[ 12, 12, 4, 576, 2304, 240, 129.9, 3.3310, 3.0383, 30000], # 2.9h\n",
    "[ 12, 12, 4, 576, 2304, 224, 126.3, 3.3809, 3.0341, 30000], # 2.6h\n",
    "[ 12, 12, 4, 576, 2304, 208, 122.8, 3.3352, 3.0429, 30000], # 2.6h\n",
    "[ 12, 12, 4, 576, 2304, 192, 119.3, 3.3169, 3.0376, 30000], # 2.4h\n",
    "[ 12, 12, 4, 576, 2304, 176, 115.7, 3.3533, 3.0378, 30000], # 2.4h\n",
    "[ 12, 12, 4, 576, 2304, 160, 112.2, 3.3445, 3.0385, 30000], # 2.3h\n",
    "\n",
    "\n",
    "# local best for H12(3): 3.0283  (bad although only large N_step was tried)\n",
    "[ 12, 12, 3, 816, 3264, 288, 221.6, 4.0542, 3.0830, 29000], # 3.7h\n",
    "[ 12, 12, 3, 816, 3264, 272, 216.9, 3.8194, 3.0609, 29000], # 3.6h\n",
    "[ 12, 12, 3, 816, 3264, 256, 212.2, 3.8058, 3.0540, 29000], # 3.2h\n",
    "[ 12, 12, 3, 816, 3264, 240, 207.5, 3.6918, 3.0460, 29000], # 3.1h\n",
    "[ 12, 12, 3, 816, 3264, 224, 202.8, 3.6314, 3.0445, 29000], # 3.0h\n",
    "[ 12, 12, 3, 816, 3264, 208, 198.1, 3.7198, 3.0567, 29000], # 2.9h 12.5G\n",
    "[ 12, 12, 3, 816, 3264, 192, 193.4, 3.5789, 3.0435, 29000], # 2.8h\n",
    "[ 12, 12, 3, 816, 3264, 176, 188.7, 3.5691, 3.0424, 29000], # 2.7h\n",
    "[ 12, 12, 3, 816, 3264, 160, 184.0, 3.5543, 3.0384, 29000], # 2.6h\n",
    "\n",
    "[ 12, 12, 3, 768, 3072, 288, 203.3, 3.9302, 3.0635, 29000], # 3.5h\n",
    "[ 12, 12, 3, 768, 3072, 272, 198.8, 3.7272, 3.0579, 29000], # 3.5h\n",
    "[ 12, 12, 3, 768, 3072, 256, 194.4, 3.8728, 3.0525, 29000], # 3.1h\n",
    "[ 12, 12, 3, 768, 3072, 240, 190.0, 3.5671, 3.0408, 29000], # 3.0h\n",
    "[ 12, 12, 3, 768, 3072, 224, 185.6, 3.6210, 3.0576, 29000], # 2.9h\n",
    "[ 12, 12, 3, 768, 3072, 208, 181.1, 3.5155, 3.0412, 29000], # 2.8h\n",
    "[ 12, 12, 3, 768, 3072, 192, 176.7, 3.4848, 3.0333, 29000], # 2.6h 12.0G\n",
    "[ 12, 12, 3, 768, 3072, 176, 172.3, 3.4758, 3.0341, 29000], # 2.5h\n",
    "[ 12, 12, 3, 768, 3072, 160, 167.9, 3.4649, 3.0321, 29000], # 2.4h\n",
    "\n",
    "[ 12, 12, 3, 720, 2880, 288, 185.6, 3.6873, 3.0528, 29000], # 3.5h\n",
    "[ 12, 12, 3, 720, 2880, 272, 181.4, 3.5905, 3.0417, 29000], # 3.4h 13.6G\n",
    "[ 12, 12, 3, 720, 2880, 256, 177.3, 3.5005, 3.0360, 29000], # 3.0h\n",
    "[ 12, 12, 3, 720, 2880, 240, 173.1, 3.5698, 3.0389, 29000], # 2.9h\n",
    "[ 12, 12, 3, 720, 2880, 224, 169.0, 3.4824, 3.0318, 29000], # 2.8h\n",
    "[ 12, 12, 3, 720, 2880, 208, 164.8, 3.4746, 3.0374, 29000], # 2.7h\n",
    "[ 12, 12, 3, 720, 2880, 192, 160.7, 3.4617,+3.0283, 29000], # 2.6h\n",
    "[ 12, 12, 3, 720, 2880, 176, 156.5, 3.4501, 3.0322, 29000], # 2.5h\n",
    "[ 12, 12, 3, 720, 2880, 160, 152.4, 3.4240, 3.0359, 29000], # 2.4h\n",
    "\n",
    "[ 12, 12, 3, 672, 2688, 288, 168.6, 3.4415, 3.0358, 29000], # 3.4h\n",
    "[ 12, 12, 3, 672, 2688, 272, 164.7, 3.4857, 3.0369, 29000], # 3.3h\n",
    "[ 12, 12, 3, 672, 2688, 256, 160.8, 3.4670, 3.0357, 29000], # 2.9h\n",
    "[ 12, 12, 3, 672, 2688, 240, 157.0, 3.4099,+3.0298, 29000], # 2.9h\n",
    "[ 12, 12, 3, 672, 2688, 224, 153.1, 3.4076, 3.0373, 29000], # 2.7h\n",
    "[ 12, 12, 3, 672, 2688, 208, 149.2, 3.4697, 3.0444, 29000], # 2.7h 11.7G\n",
    "[ 12, 12, 3, 672, 2688, 192, 145.3, 3.4113, 3.0323, 29000], # 2.5h\n",
    "[ 12, 12, 3, 672, 2688, 176, 141.5, 3.3952, 3.0378, 29000], # 2.4h 11.4G\n",
    "[ 12, 12, 3, 672, 2688, 160, 137.6, 3.3964, 3.0333, 29000], # 2.3h\n",
    "\n",
    "[ 12, 12, 3, 624, 2496, 288, 152.2, 3.4248, 3.0403, 29000], # 3.3h\n",
    "[ 12, 12, 3, 624, 2496, 272, 148.6, 3.4091, 3.0353, 29000], # 3.3h\n",
    "[ 12, 12, 3, 624, 2496, 256, 145.0, 3.4048, 3.0355, 29000], # 2.9h\n",
    "[ 12, 12, 3, 624, 2496, 240, 141.4, 3.3757, 3.0314, 29000], # 2.8h\n",
    "[ 12, 12, 3, 624, 2496, 224, 137.8, 3.5006, 3.0316, 29000], # 2.7h\n",
    "[ 12, 12, 3, 624, 2496, 208, 134.2, 3.3804, 3.0311, 29000], # 2.6h\n",
    "[ 12, 12, 3, 624, 2496, 192, 130.6, 3.3598, 3.0345, 29000], # 2.4h\n",
    "[ 12, 12, 3, 624, 2496, 176, 127.1, 3.4133, 3.0329, 29000], # 2.3h\n",
    "[ 12, 12, 3, 624, 2496, 160, 123.5, 3.3845, 3.0359, 29000], # 2.2h\n",
    "\n",
    "[ 12, 12, 3, 576, 2304, 288, 136.5, 3.3817, 3.0377, 29000], # 3.3h\n",
    "[ 12, 12, 3, 576, 2304, 272, 133.2, 3.3856, 3.0438, 29000], # 3.2h\n",
    "[ 12, 12, 3, 576, 2304, 256, 129.9, 3.3468, 3.0348, 29000], # 2.8h 11.4G\n",
    "[ 12, 12, 3, 576, 2304, 240, 126.6, 3.3844, 3.0391, 29000], # 2.7h 11.3G\n",
    "[ 12, 12, 3, 576, 2304, 224, 123.2, 3.3524, 3.0426, 29000], # 2.6h\n",
    "[ 12, 12, 3, 576, 2304, 208, 119.9, 3.3723, 3.0422, 29000], # 2.5h\n",
    "[ 12, 12, 3, 576, 2304, 192, 116.6, 3.3368, 3.0426, 29000], # 2.4h\n",
    "[ 12, 12, 3, 576, 2304, 176, 113.3, 3.3412, 3.0417, 29000], # 2.3h\n",
    "[ 12, 12, 3, 576, 2304, 160, 110.0, 3.3488, 3.0416, 29000], # 2.2h\n",
    "\n",
    "\n",
    "# local best for H10(5): 3.0288  (bad)\n",
    "[ 12, 10, 5, 800, 3200, 288, 215.4, 4.0863, 3.0750,  29000],# 3.3h\n",
    "[ 12, 10, 5, 800, 3200, 288, 215.4, 4.4135, 3.1293, 26000], # 3.0h 13.4G(VRAM)\n",
    "[ 12, 10, 5, 800, 3200, 272, 210.8, 3.7596, 3.0502,  29000],# 3.2h\n",
    "[ 12, 10, 5, 800, 3200, 272, 210.8, 3.9277, 3.0641, 26000], # 2.9h\n",
    "[ 12, 10, 5, 800, 3200, 256, 206.2, 4.2289, 3.0812,  29000],# 2.9h\n",
    "[ 12, 10, 5, 800, 3200, 256, 206.2, 4.0111, 3.0730, 26000], # 2.6h\n",
    "[ 12, 10, 5, 800, 3200, 240, 201.6, 3.6964, 3.0503,  29000],# 2.8h 13.2G\n",
    "[ 12, 10, 5, 800, 3200, 240, 201.6, 3.8624, 3.0579, 26000], # 2.5h\n",
    "[ 12, 10, 5, 800, 3200, 224, 197.0, 3.7281, 3.0519,  29000],# 2.7h\n",
    "[ 12, 10, 5, 800, 3200, 224, 197.0, 4.1020, 3.0802, 26000], # 2.4h\n",
    "[ 12, 10, 5, 800, 3200, 208, 192.4, 3.7349, 3.0470,  29000],# 2.6h\n",
    "[ 12, 10, 5, 800, 3200, 208, 192.4, 3.7667, 3.0516, 26000], # 2.3h\n",
    "[ 12, 10, 5, 800, 3200, 192, 187.8, 3.7089, 3.0441,  29000],# 2.5h\n",
    "[ 12, 10, 5, 800, 3200, 192, 187.8, 3.7361, 3.0517, 26000], # 2.2h\n",
    "[ 12, 10, 5, 800, 3200, 176, 183.2, 3.6676, 3.0469,  29000],# 2.4h\n",
    "[ 12, 10, 5, 800, 3200, 176, 183.2, 3.7073, 3.0448, 26000], # 2.2h\n",
    "[ 12, 10, 5, 800, 3200, 160, 178.6, 3.5733, 3.0353,  29000],# 2.3h\n",
    "[ 12, 10, 5, 800, 3200, 160, 178.6, 3.6680, 3.0499, 26000], # 2.1h\n",
    "\n",
    "[ 12, 10, 5, 760, 3040, 288, 200.3, 3.7109, 3.0579,  29000],# 3.2h\n",
    "[ 12, 10, 5, 760, 3040, 288, 200.3, 3.9555, 3.0760, 26000], # 2.8h\n",
    "[ 12, 10, 5, 760, 3040, 272, 195.9, 3.6460, 3.0444,  29000],# 3.1h\n",
    "[ 12, 10, 5, 760, 3040, 272, 195.9, 3.9716, 3.0610, 26000], # 2.8h\n",
    "[ 12, 10, 5, 760, 3040, 256, 191.5, 3.9522, 3.0560,  29000],# 2.8h 13.0G\n",
    "[ 12, 10, 5, 760, 3040, 256, 191.5, 3.7498, 3.0452, 26000], # 2.5h 13.2G\n",
    "[ 12, 10, 5, 760, 3040, 240, 187.1, 3.5662, 3.0365,  30000],# 2.8h\n",
    "[ 12, 10, 5, 760, 3040, 240, 187.1, 3.5954, 3.0389,  29000],# 2.7h\n",
    "[ 12, 10, 5, 760, 3040, 240, 187.1, 3.7836, 3.0542, 26000], # 2.4h 13.0G\n",
    "[ 12, 10, 5, 760, 3040, 224, 182.8, 3.5649, 3.0381,  30000],# 2.7h\n",
    "[ 12, 10, 5, 760, 3040, 224, 182.8, 3.6129, 3.0430,  29000],# 2.6h\n",
    "[ 12, 10, 5, 760, 3040, 224, 182.8, 3.8027, 3.0526, 26000], # 2.3h\n",
    "[ 12, 10, 5, 760, 3040, 208, 178.4, 3.5510, 3.0389,  30000],# 2.6h\n",
    "[ 12, 10, 5, 760, 3040, 208, 178.4, 3.6085, 3.0410,  29000],# 2.5h\n",
    "[ 12, 10, 5, 760, 3040, 208, 178.4, 3.6174, 3.0394, 26000], # 2.2h\n",
    "[ 12, 10, 5, 760, 3040, 192, 174.0, 3.5742, 3.0400,  29000],# 2.4h\n",
    "[ 12, 10, 5, 760, 3040, 192, 174.0, 3.6318, 3.0424, 26000], # 2.1h\n",
    "[ 12, 10, 5, 760, 3040, 176, 169.6, 3.5571, 3.0340,  29000],# 2.3h\n",
    "[ 12, 10, 5, 760, 3040, 176, 169.6, 3.5638, 3.0439, 26000], # 2.0h\n",
    "[ 12, 10, 5, 760, 3040, 160, 165.2, 3.4873, 3.0338,  29000],# 2.2h\n",
    "[ 12, 10, 5, 760, 3040, 160, 165.2, 3.5710, 3.0398, 26000], # 1.9h\n",
    "\n",
    "[ 12, 10, 5, 720, 2880, 288, 185.6, 3.7851, 3.0571,  29000],# 3.1h\n",
    "[ 12, 10, 5, 720, 2880, 288, 185.6, 3.6666, 3.0446, 26000], # 2.8h\n",
    "[ 12, 10, 5, 720, 2880, 272, 181.4, 3.5993, 3.0389,  29000],# 3.1h\n",
    "[ 12, 10, 5, 720, 2880, 272, 181.4, 3.7501, 3.0566, 26000], # 2.7h 12.8G\n",
    "[ 12, 10, 5, 720, 2880, 256, 177.3, 3.6413, 3.0490,  29000],# 2.7h 12.8G\n",
    "[ 12, 10, 5, 720, 2880, 256, 177.3, 3.6165, 3.0391, 26000], # 2.4h\n",
    "[ 12, 10, 5, 720, 2880, 240, 173.1, 3.5680, 3.0523,  30000],# 2.7h\n",
    "[ 12, 10, 5, 720, 2880, 240, 173.1, 3.5868, 3.0361,  29000],# 2.6h\n",
    "[ 12, 10, 5, 720, 2880, 240, 173.1, 3.6740, 3.0505, 26000], # 2.4h\n",
    "[ 12, 10, 5, 720, 2880, 224, 169.0, 3.5683, 3.0389,  30000],# 2.6h 12.5G\n",
    "[ 12, 10, 5, 720, 2880, 224, 169.0, 3.5269, 3.0374,  29000],# 2.5h\n",
    "[ 12, 10, 5, 720, 2880, 224, 169.0, 3.6539, 3.0383, 26000], # 2.3h\n",
    "[ 12, 10, 5, 720, 2880, 208, 164.8, 3.6328, 3.0406,  30000],# 2.5h\n",
    "[ 12, 10, 5, 720, 2880, 208, 164.8, 3.5695, 3.0370,  29000],# 2.4h\n",
    "[ 12, 10, 5, 720, 2880, 208, 164.8, 3.6090, 3.0324, 26000], # 2.2h\n",
    "[ 12, 10, 5, 720, 2880, 192, 160.7, 3.5254, 3.0381,  29000],# 2.3h\n",
    "[ 12, 10, 5, 720, 2880, 192, 160.7, 3.6142, 3.0378, 26000], # 2.1h\n",
    "[ 12, 10, 5, 720, 2880, 176, 156.5, 3.5604, 3.0373,  29000],# 2.2h\n",
    "[ 12, 10, 5, 720, 2880, 176, 156.5, 3.5696, 3.0400, 26000], # 2.0h\n",
    "[ 12, 10, 5, 720, 2880, 160, 152.4, 3.4955, 3.0368,  29000],# 2.1h\n",
    "[ 12, 10, 5, 720, 2880, 160, 152.4, 3.5616, 3.0424, 26000], # 1.9h\n",
    "\n",
    "[ 12, 10, 5, 680, 2720, 288, 171.4, 3.6561, 3.0438,  29000],# 3.1h\n",
    "[ 12, 10, 5, 680, 2720, 288, 171.4, 3.6872, 3.0503, 26000], # 2.8h\n",
    "[ 12, 10, 5, 680, 2720, 272, 167.4, 3.5469, 3.0433,  29000],# 3.0h\n",
    "[ 12, 10, 5, 680, 2720, 272, 167.4, 3.6393, 3.0509, 26000], # 2.7h\n",
    "[ 12, 10, 5, 680, 2720, 256, 163.5, 3.4874, 3.0380,  29000],# 2.7h\n",
    "[ 12, 10, 5, 680, 2720, 256, 163.5, 3.5470, 3.0417, 26000], # 2.4h\n",
    "[ 12, 10, 5, 680, 2720, 240, 159.6, 3.4814, 3.0456,  30000],# 2.7h\n",
    "[ 12, 10, 5, 680, 2720, 240, 159.6, 3.4776,+3.0310,  29000],# 2.5h\n",
    "[ 12, 10, 5, 680, 2720, 240, 159.6, 3.5346, 3.0516,  28000],# 2.4h\n",
    "[ 12, 10, 5, 680, 2720, 240, 159.6, 3.5827, 3.0408, 26000], # 2.3h\n",
    "[ 12, 10, 5, 680, 2720, 224, 155.7, 3.5000, 3.0370,  30000],# 2.6h\n",
    "[ 12, 10, 5, 680, 2720, 224, 155.7, 3.4778, 3.0388,  29000],# 2.4h\n",
    "[ 12, 10, 5, 680, 2720, 224, 155.7, 3.5025, 3.0412, 26000], # 2.2h 12.4G\n",
    "[ 12, 10, 5, 680, 2720, 208, 151.8, 3.4079, 3.0322,  30000],# 2.5h\n",
    "[ 12, 10, 5, 680, 2720, 208, 151.8, 3.4980, 3.0328,  29000],# 2.4h\n",
    "[ 12, 10, 5, 680, 2720, 208, 151.8, 3.5130, 3.0370, 26000], # 2.1h\n",
    "[ 12, 10, 5, 680, 2720, 192, 147.9, 3.4302, 3.0352,  29000],# 2.3h\n",
    "[ 12, 10, 5, 680, 2720, 192, 147.9, 3.5506, 3.0344, 26000], # 2.0h\n",
    "[ 12, 10, 5, 680, 2720, 176, 143.9, 3.5458, 3.0359,  29000],# 2.2h\n",
    "[ 12, 10, 5, 680, 2720, 176, 143.9, 3.4835, 3.0362, 26000], # 2.0h\n",
    "[ 12, 10, 5, 680, 2720, 160, 140.0, 3.4417, 3.0400,  29000],# 2.1h\n",
    "[ 12, 10, 5, 680, 2720, 160, 140.0, 3.5176, 3.0372, 26000], # 1.9h\n",
    "\n",
    "[ 12, 10, 5, 640, 2560, 288, 157.6, 3.5000, 3.0386,  29000],# 3.0h 12.3G\n",
    "[ 12, 10, 5, 640, 2560, 288, 157.6, 3.5346, 3.0347, 26000], # 2.7h\n",
    "[ 12, 10, 5, 640, 2560, 272, 153.9, 3.4240, 3.0343,  29000],# 2.9h\n",
    "[ 12, 10, 5, 640, 2560, 272, 153.9, 3.4945, 3.0385,  27000],# 2.7h\n",
    "[ 12, 10, 5, 640, 2560, 272, 153.9, 3.5059,+3.0307, 26000], # 2.6h\n",
    "[ 12, 10, 5, 640, 2560, 272, 153.9, 3.5634, 3.0322,  25000],# 2.5h\n",
    "[ 12, 10, 5, 640, 2560, 256, 150.2, 3.4412, 3.0340,  29000],# 2.5h\n",
    "[ 12, 10, 5, 640, 2560, 256, 150.2, 3.5717, 3.0373, 26000], # 2.3h\n",
    "[ 12, 10, 5, 640, 2560, 240, 146.5, 3.3920, 3.0322,  30000],# 2.6h\n",
    "[ 12, 10, 5, 640, 2560, 240, 146.5, 3.4366,+3.0307,  29000],# 2.5h\n",
    "[ 12, 10, 5, 640, 2560, 240, 146.5, 3.4583, 3.0331,  28000],# 2.3h\n",
    "[ 12, 10, 5, 640, 2560, 240, 146.5, 3.5453, 3.0470, 26000], # 2.2h\n",
    "[ 12, 10, 5, 640, 2560, 224, 142.8, 3.4244, 3.0372,  30000],# 2.5h\n",
    "[ 12, 10, 5, 640, 2560, 224, 142.8, 3.4461, 3.0379,  29000],# 2.3h\n",
    "[ 12, 10, 5, 640, 2560, 224, 142.8, 3.5036, 3.0405, 26000], # 2.1h 12.2G\n",
    "[ 12, 10, 5, 640, 2560, 208, 139.2, 3.4015, 3.0383,  31000],# 2.5h\n",
    "[ 12, 10, 5, 640, 2560, 208, 139.2, 3.3960,+3.0305,  30000],# 2.4h\n",
    "[ 12, 10, 5, 640, 2560, 208, 139.2, 3.3827,+3.0291,  29000],# 2.3h\n",
    "[ 12, 10, 5, 640, 2560, 208, 139.2, 3.3926, 3.0311,  29000],# 2.3h\n",
    "[ 12, 10, 5, 640, 2560, 208, 139.2, 3.4484, 3.0391,  28000],# 2.2h\n",
    "[ 12, 10, 5, 640, 2560, 208, 139.2, 3.4341, 3.0402,  27000],# 2.1h\n",
    "[ 12, 10, 5, 640, 2560, 208, 139.2, 3.5084, 3.0407, 26000], # 2.1h\n",
    "[ 12, 10, 5, 640, 2560, 192, 135.5, 3.3479, 3.0384,  31000],# 2.3h\n",
    "[ 12, 10, 5, 640, 2560, 192, 135.5, 3.3488, 3.0308,  30000],# 2.2h\n",
    "[ 12, 10, 5, 640, 2560, 192, 135.5, 3.3784, 3.0328,  29000],# 2.1h 11.8G\n",
    "[ 12, 10, 5, 640, 2560, 192, 135.5, 3.4610, 3.0366, 26000], # 1.9h\n",
    "[ 12, 10, 5, 640, 2560, 176, 131.8, 3.4024, 3.0371,  29000],# 2.1h\n",
    "[ 12, 10, 5, 640, 2560, 176, 131.8, 3.4944, 3.0449,  27000],# 2.0h\n",
    "[ 12, 10, 5, 640, 2560, 176, 131.8, 3.4735,+3.0312, 26000], # 1.9h\n",
    "[ 12, 10, 5, 640, 2560, 176, 131.8, 3.4918, 3.0413,  25000],# 1.8h\n",
    "[ 12, 10, 5, 640, 2560, 160, 128.1, 3.4022, 3.0324,  29000],# 2.0h\n",
    "[ 12, 10, 5, 640, 2560, 160, 128.1, 3.4622, 3.0367, 26000], # 1.8h\n",
    "\n",
    "[ 12, 10, 5, 600, 2400, 288, 144.3, 3.3740, 3.0375,  29000],# 2.9h\n",
    "[ 12, 10, 5, 600, 2400, 288, 144.3, 3.4627, 3.0350,  27000],# 2.7h\n",
    "[ 12, 10, 5, 600, 2400, 288, 144.3, 3.4836,+3.0288, 26000], # 2.6h\n",
    "[ 12, 10, 5, 600, 2400, 288, 144.3, 3.5049, 3.0375,  25000],# 2.5h 12.2G\n",
    "[ 12, 10, 5, 600, 2400, 272, 140.8, 3.4060, 3.0418,  29000],# 2.9h\n",
    "[ 12, 10, 5, 600, 2400, 272, 140.8, 3.4302, 3.0419,  27000],# 2.7h\n",
    "[ 12, 10, 5, 600, 2400, 272, 140.8, 3.4275,+3.0313, 26000], # 2.6h\n",
    "[ 12, 10, 5, 600, 2400, 272, 140.8, 3.5024, 3.0356,  25000],# 2.5h\n",
    "[ 12, 10, 5, 600, 2400, 256, 137.4, 3.3952, 3.0323,  29000],# 2.5h 12.1G\n",
    "[ 12, 10, 5, 600, 2400, 256, 137.4, 3.4243, 3.0349, 26000], # 2.3h\n",
    "[ 12, 10, 5, 600, 2400, 240, 133.9, 3.4325, 3.0338,  29000],# 2.5h\n",
    "[ 12, 10, 5, 600, 2400, 240, 133.9, 3.4542, 3.0347, 26000], # 2.2h\n",
    "[ 12, 10, 5, 600, 2400, 224, 130.5, 3.4026, 3.0438,  29000],# 2.4h 11.9G\n",
    "[ 12, 10, 5, 600, 2400, 224, 130.5, 3.4419, 3.0352, 26000], # 2.1h\n",
    "[ 12, 10, 5, 600, 2400, 208, 127.0, 3.3605, 3.0320,  29000],# 2.3h\n",
    "[ 12, 10, 5, 600, 2400, 208, 127.0, 3.5144, 3.0392, 26000], # 2.0h\n",
    "[ 12, 10, 5, 600, 2400, 192, 123.5, 3.3845, 3.0388,  29000],# 2.1h\n",
    "[ 12, 10, 5, 600, 2400, 192, 123.5, 3.4342, 3.0364, 26000], # 1.9h\n",
    "[ 12, 10, 5, 600, 2400, 176, 120.1, 3.3593, 3.0349,  29000],# 2.1h\n",
    "[ 12, 10, 5, 600, 2400, 176, 120.1, 3.5165, 3.0333, 26000], # 1.8h\n",
    "[ 12, 10, 5, 600, 2400, 160, 116.6, 3.3973, 3.0353,  29000],# 2.0h\n",
    "[ 12, 10, 5, 600, 2400, 160, 116.6, 3.3979, 3.0382, 26000], # 1.8h\n",
    "\n",
    "[ 12, 10, 5, 560, 2240, 288, 131.4, 3.3872, 3.0427,  29000],# 2.9h\n",
    "[ 12, 10, 5, 560, 2240, 288, 131.4, 3.4486, 3.0401, 26000], # 2.6h\n",
    "[ 12, 10, 5, 560, 2240, 272, 128.2, 3.3745, 3.0378,  29000],# 2.8h\n",
    "[ 12, 10, 5, 560, 2240, 272, 128.2, 3.4223, 3.0357, 26000], # 2.5h\n",
    "[ 12, 10, 5, 560, 2240, 256, 125.0, 3.3430, 3.0362,  29000],# 2.5h\n",
    "[ 12, 10, 5, 560, 2240, 256, 125.0, 3.4543, 3.0405, 26000], # 2.2h\n",
    "[ 12, 10, 5, 560, 2240, 240, 121.8, 3.3799, 3.0411,  29000],# 2.4h 11.8G\n",
    "[ 12, 10, 5, 560, 2240, 240, 121.8, 3.4177, 3.0411, 26000], # 2.2h\n",
    "[ 12, 10, 5, 560, 2240, 224, 118.5, 3.3936, 3.0348,  29000],# 2.3h 11.7G\n",
    "[ 12, 10, 5, 560, 2240, 224, 118.5, 3.4812, 3.0349, 26000], # 2.1h\n",
    "[ 12, 10, 5, 560, 2240, 208, 115.3, 3.3496, 3.0387,  29000],# 2.2h\n",
    "[ 12, 10, 5, 560, 2240, 208, 115.3, 3.4287, 3.0394, 26000], # 2.0h\n",
    "[ 12, 10, 5, 560, 2240, 192, 112.1, 3.3388, 3.0415,  29000],# 2.1h\n",
    "[ 12, 10, 5, 560, 2240, 192, 112.1, 3.4062, 3.0395, 26000], # 1.9h\n",
    "[ 12, 10, 5, 560, 2240, 176, 108.9, 3.3864, 3.0392,  29000],# 2.0h\n",
    "[ 12, 10, 5, 560, 2240, 176, 108.9, 3.3693, 3.0402, 26000], # 1.8h\n",
    "[ 12, 10, 5, 560, 2240, 160, 105.6, 3.3874, 3.0372,  29000],# 1.9h\n",
    "[ 12, 10, 5, 560, 2240, 160, 105.6, 3.3719, 3.0383, 26000], # 1.7h\n",
    "\n",
    "\n",
    "# local best for H10(2): 3.0260  (only good at this point)\n",
    "[ 12, 10, 2, 800, 3200, 288, 198.8, 3.9294, 3.0821, 26000], # 2.9h\n",
    "[ 12, 10, 2, 800, 3200, 272, 195.1, 3.6850, 3.0520, 26000], # 2.8h\n",
    "[ 12, 10, 2, 800, 3200, 256, 191.5, 3.6749, 3.0391, 26000], # 2.5h\n",
    "[ 12, 10, 2, 800, 3200, 240, 187.8, 3.8333, 3.0566, 26000], # 2.4h\n",
    "[ 12, 10, 2, 800, 3200, 224, 184.1, 3.6739, 3.0473, 26000], # 2.4h\n",
    "[ 12, 10, 2, 800, 3200, 208, 180.4, 3.6830, 3.0451, 26000], # 2.3h\n",
    "[ 12, 10, 2, 800, 3200, 192, 176.7, 3.6462, 3.0376, 26000], # 2.2h\n",
    "[ 12, 10, 2, 800, 3200, 176, 173.0, 3.6425, 3.0383, 26000], # 2.1h\n",
    "[ 12, 10, 2, 800, 3200, 160, 169.3, 3.5807, 3.0464, 26000], # 2.0h\n",
    "\n",
    "[ 12, 10, 2, 760, 3040, 288, 184.5, 3.6212, 3.0404, 26000], # 2.7h\n",
    "[ 12, 10, 2, 760, 3040, 272, 181.0, 3.6664, 3.0476, 26000], # 2.7h\n",
    "[ 12, 10, 2, 760, 3040, 256, 177.5, 3.6229, 3.0388, 26000], # 2.4h\n",
    "[ 12, 10, 2, 760, 3040, 240, 174.0, 3.5441, 3.0386, 26000], # 2.3h\n",
    "[ 12, 10, 2, 760, 3040, 224, 170.5, 3.5667, 3.0438, 26000], # 2.2h 12.8G\n",
    "[ 12, 10, 2, 760, 3040, 208, 167.0, 3.7689, 3.0778, 26000], # 2.2h 12.7G\n",
    "[ 12, 10, 2, 760, 3040, 192, 163.5, 3.5892, 3.0356, 26000], # 2.1h\n",
    "[ 12, 10, 2, 760, 3040, 176, 160.0, 3.5334, 3.0403, 26000], # 2.0h\n",
    "[ 12, 10, 2, 760, 3040, 160, 156.5, 3.5415, 3.0398, 26000], # 1.9h\n",
    "\n",
    "[ 12, 10, 2, 720, 2880, 288, 170.7, 3.5531, 3.0394, 26000], # 2.7h\n",
    "[ 12, 10, 2, 720, 2880, 272, 167.3, 3.6179, 3.0445, 26000], # 2.6h\n",
    "[ 12, 10, 2, 720, 2880, 256, 164.0, 3.6385, 3.0442, 26000], # 2.4h\n",
    "[ 12, 10, 2, 720, 2880, 240, 160.7, 3.5280, 3.0433, 26000], # 2.3h\n",
    "[ 12, 10, 2, 720, 2880, 224, 157.4, 3.5645, 3.0380, 26000], # 2.2h\n",
    "[ 12, 10, 2, 720, 2880, 208, 154.1, 3.5226, 3.0332, 26000], # 2.1h\n",
    "[ 12, 10, 2, 720, 2880, 192, 150.7, 3.5308, 3.0444,  27000],# 2.1h 12.4G\n",
    "[ 12, 10, 2, 720, 2880, 192, 150.7, 3.5080,+3.0260, 26000], # 2.0h\n",
    "[ 12, 10, 2, 720, 2880, 192, 150.7, 3.5066, 3.0338, 26000], # 2.0h again\n",
    "[ 12, 10, 2, 720, 2880, 192, 150.7, 3.5329, 3.0497,  25000],# 1.9h\n",
    "[ 12, 10, 2, 720, 2880, 176, 147.4, 3.5143, 3.0432, 26000], # 2.0h 12.3G\n",
    "[ 12, 10, 2, 720, 2880, 160, 144.1, 3.4847, 3.0381,  27000],# 1.9h\n",
    "[ 12, 10, 2, 720, 2880, 160, 144.1, 3.5645,+3.0303, 26000], # 1.9h\n",
    "[ 12, 10, 2, 720, 2880, 160, 144.1, 3.5862, 3.0308,  25000],# 1.8h\n",
    "[ 12, 10, 2, 720, 2880, 160, 144.1, 3.6184, 3.0421,  24000],# 1.7h\n",
    "[ 12, 10, 2, 720, 2880, 144, 140.8, 3.6995, 3.0707, 26000], # 1.8h\n",
    "\n",
    "[ 12, 10, 2, 680, 2720, 288, 157.3, 3.4936, 3.0336, 26000], # 2.7h\n",
    "[ 12, 10, 2, 680, 2720, 272, 154.1, 3.5443, 3.0450, 26000], # 2.6h\n",
    "[ 12, 10, 2, 680, 2720, 256, 151.0, 3.4803, 3.0348, 26000], # 2.3h\n",
    "[ 12, 10, 2, 680, 2720, 240, 147.9, 3.4999, 3.0355, 26000], # 2.2h\n",
    "[ 12, 10, 2, 680, 2720, 224, 144.7, 3.4967, 3.0388, 26000], # 2.2h\n",
    "[ 12, 10, 2, 680, 2720, 208, 141.6, 3.4537, 3.0443,  27000],# 2.2h\n",
    "[ 12, 10, 2, 680, 2720, 208, 141.6, 3.4626,+3.0315, 26000], # 2.1h 12.2G\n",
    "[ 12, 10, 2, 680, 2720, 208, 141.6, 3.5535, 3.0419,  25000],# 2.0h\n",
    "[ 12, 10, 2, 680, 2720, 192, 138.5, 3.4808, 3.0324,  27000],# 2.0h\n",
    "[ 12, 10, 2, 680, 2720, 192, 138.5, 3.4781,+3.0314, 26000], # 2.0h\n",
    "[ 12, 10, 2, 680, 2720, 192, 138.5, 3.5054, 3.0383,  25000],# 1.9h\n",
    "[ 12, 10, 2, 680, 2720, 176, 135.3, 3.4783, 3.0393, 26000], # 1.9h\n",
    "[ 12, 10, 2, 680, 2720, 160, 132.2, 3.5681, 3.0406, 26000], # 1.8h\n",
    "\n",
    "[ 12, 10, 2, 640, 2560, 288, 144.3, 3.4985, 3.0352, 26000], # 2.6h\n",
    "[ 12, 10, 2, 640, 2560, 272, 141.4, 3.4746, 3.0395, 26000], # 2.5h\n",
    "[ 12, 10, 2, 640, 2560, 256, 138.4, 3.5643, 3.0360, 26000], # 2.2h\n",
    "[ 12, 10, 2, 640, 2560, 240, 135.5, 3.4467, 3.0374, 26000], # 2.2h\n",
    "[ 12, 10, 2, 640, 2560, 224, 132.5, 3.4434, 3.0378, 26000], # 2.1h\n",
    "[ 12, 10, 2, 640, 2560, 208, 129.6, 3.4446, 3.0393, 26000], # 2.0h\n",
    "[ 12, 10, 2, 640, 2560, 192, 126.6, 3.4329, 3.0377, 26000], # 1.9h\n",
    "[ 12, 10, 2, 640, 2560, 176, 123.7, 3.3538, 3.0401, 15000], # 1.6h # VRAM limit w/o grad-acc\n",
    "[ 12, 10, 2, 640, 2560, 176, 123.7, 3.4233, 3.0410, 26000], # 1.8h\n",
    "[ 12, 10, 2, 640, 2560, 160, 120.7, 3.4370, 3.0450, 26000], # 1.7h\n",
    "\n",
    "[ 12, 10, 2, 600, 2400, 288, 131.8, 3.4231, 3.0362, 26000], # 2.6h 12.1G\n",
    "[ 12, 10, 2, 600, 2400, 272, 129.1, 3.4839, 3.0375, 26000], # 2.5h\n",
    "[ 12, 10, 2, 600, 2400, 256, 126.3, 3.4325, 3.0386, 26000], # 2.2h\n",
    "[ 12, 10, 2, 600, 2400, 240, 123.5, 3.4149, 3.0406, 26000], # 2.1h\n",
    "[ 12, 10, 2, 600, 2400, 224, 120.8, 3.4350, 3.0347, 26000], # 2.1h\n",
    "[ 12, 10, 2, 600, 2400, 208, 118.0, 3.4233, 3.0385, 26000], # 2.0h\n",
    "[ 12, 10, 2, 600, 2400, 192, 115.3, 3.3803, 3.0349, 26000], # 1.9h\n",
    "[ 12, 10, 2, 600, 2400, 176, 112.5, 3.4254, 3.0372, 26000], # 1.8h\n",
    "[ 12, 10, 2, 600, 2400, 160, 109.7, 3.5005, 3.0370, 26000], # 1.7h\n",
    "\n",
    "[ 12, 10, 2, 560, 2240, 288, 119.8, 3.4000, 3.0416, 26000], # 2.5h 11.8G\n",
    "[ 12, 10, 2, 560, 2240, 272, 117.2, 3.4044, 3.0371, 26000], # 2.4h\n",
    "[ 12, 10, 2, 560, 2240, 256, 114.7, 3.3703, 3.0414, 26000], # 2.2h\n",
    "[ 12, 10, 2, 560, 2240, 240, 112.1, 3.4065, 3.0438, 26000], # 2.1h\n",
    "[ 12, 10, 2, 560, 2240, 224, 109.5, 3.3915, 3.0378, 26000], # 2.0h\n",
    "[ 12, 10, 2, 560, 2240, 208, 106.9, 3.4025, 3.0427, 26000], # 2.0h\n",
    "[ 12, 10, 2, 560, 2240, 192, 104.3, 3.3798, 3.0419, 26000], # 1.8h\n",
    "[ 12, 10, 2, 560, 2240, 176, 101.8, 3.4532, 3.0414, 26000], # 1.8h\n",
    "[ 12, 10, 2, 560, 2240, 160,  99.2, 3.3848, 3.0407, 26000], # 1.7h\n",
    "\n",
    "\n",
    "# local best for H9(3): 3.0254 (best for L12)\n",
    "[ 12, 9, 3, 792, 3168, 288, 195.9, 3.7980, 3.0532,  29000],# 3.0h\n",
    "[ 12, 9, 3, 792, 3168, 288, 195.9, 3.7637, 3.0486, 26000], # 2.7h\n",
    "[ 12, 9, 3, 792, 3168, 272, 192.3, 3.6402, 3.0359,  29000],# 2.9h\n",
    "[ 12, 9, 3, 792, 3168, 272, 192.3, 3.7662, 3.0480, 26000], # 2.6h\n",
    "[ 12, 9, 3, 792, 3168, 256, 188.6, 3.6234, 3.0533,  29000],# 2.6h 12.9G\n",
    "[ 12, 9, 3, 792, 3168, 256, 188.6, 3.6627, 3.0437, 26000], # 2.4h 13.0G\n",
    "[ 12, 9, 3, 792, 3168, 240, 185.0, 3.7214, 3.0517,  29000],# 2.5h\n",
    "[ 12, 9, 3, 792, 3168, 240, 185.0, 3.8239, 3.0452, 26000], # 2.3h\n",
    "[ 12, 9, 3, 792, 3168, 224, 181.3, 3.5915, 3.0410,  29000],# 2.4h\n",
    "[ 12, 9, 3, 792, 3168, 224, 181.3, 3.7815, 3.0502, 26000], # 2.2h\n",
    "[ 12, 9, 3, 792, 3168, 208, 177.7, 3.5903, 3.0476,  29000],# 2.4h\n",
    "[ 12, 9, 3, 792, 3168, 208, 177.7, 3.7227, 3.0429, 26000], # 2.2h\n",
    "[ 12, 9, 3, 792, 3168, 192, 174.0, 3.6110, 3.0388,  29000],# 2.3h\n",
    "[ 12, 9, 3, 792, 3168, 192, 174.0, 3.6543, 3.0451, 26000], # 2.1h\n",
    "[ 12, 9, 3, 792, 3168, 176, 170.4, 3.5884, 3.0407,  29000],# 2.2h\n",
    "[ 12, 9, 3, 792, 3168, 176, 170.4, 3.6043, 3.0381, 26000], # 2.0h\n",
    "[ 12, 9, 3, 792, 3168, 160, 166.7, 3.5445, 3.0370,  29000],# 2.1h\n",
    "[ 12, 9, 3, 792, 3168, 160, 166.7, 3.5897, 3.0369, 26000], # 1.9h\n",
    "\n",
    "[ 12, 9, 3, 756, 3024, 288, 183.1, 3.5657, 3.0354,  29000],# 2.8h\n",
    "[ 12, 9, 3, 756, 3024, 288, 183.1, 3.6778, 3.0429, 26000], # 2.6h\n",
    "[ 12, 9, 3, 756, 3024, 272, 179.6, 3.5826, 3.0428,  29000],# 2.8h 12.4G\n",
    "[ 12, 9, 3, 756, 3024, 272, 179.6, 3.6629, 3.0362, 26000], # 2.5h\n",
    "[ 12, 9, 3, 756, 3024, 256, 176.1, 3.6100, 3.0417,  29000],# 2.5h 12.6G\n",
    "[ 12, 9, 3, 756, 3024, 256, 176.1, 3.6234, 3.0417, 26000], # 2.3h\n",
    "[ 12, 9, 3, 756, 3024, 240, 172.7, 3.5544, 3.0394,  29000],# 2.4h\n",
    "[ 12, 9, 3, 756, 3024, 240, 172.7, 3.6377, 3.0431, 26000], # 2.2h 12.6G\n",
    "[ 12, 9, 3, 756, 3024, 224, 169.2, 3.5213, 3.0388,  29000],# 2.3h\n",
    "[ 12, 9, 3, 756, 3024, 224, 169.2, 3.6333, 3.0382, 26000], # 2.1h\n",
    "[ 12, 9, 3, 756, 3024, 208, 165.7, 3.5074, 3.0366,  30000],# 2.4h\n",
    "[ 12, 9, 3, 756, 3024, 208, 165.7, 3.5090,+3.0305,  29000],# 2.2h\n",
    "[ 12, 9, 3, 756, 3024, 208, 165.7, 3.5226, 3.0359,  28000],# 2.2h\n",
    "[ 12, 9, 3, 756, 3024, 208, 165.7, 3.5281, 3.0343, 26000], # 2.0h\n",
    "[ 12, 9, 3, 756, 3024, 192, 162.2, 3.5688, 3.0454,  29000],# 2.1h\n",
    "[ 12, 9, 3, 756, 3024, 192, 162.2, 3.5650, 3.0395, 26000], # 1.9h\n",
    "[ 12, 9, 3, 756, 3024, 176, 158.7, 3.5012, 3.0335,  29000],# 2.1h\n",
    "[ 12, 9, 3, 756, 3024, 176, 158.7, 3.5454, 3.0381, 26000], # 1.9h\n",
    "[ 12, 9, 3, 756, 3024, 160, 155.2, 3.5590, 3.0493,  29000],# 2.0h\n",
    "[ 12, 9, 3, 756, 3024, 160, 155.2, 3.5307, 3.0441, 26000], # 1.8h\n",
    "\n",
    "[ 12, 9, 3, 720, 2880, 288, 170.7, 3.5573, 3.0352,  29000],# 2.8h\n",
    "[ 12, 9, 3, 720, 2880, 288, 170.7, 3.6202, 3.0405, 26000], # 2.5h\n",
    "[ 12, 9, 3, 720, 2880, 272, 167.3, 3.5045, 3.0319,  29000],# 2.7h 12.2G\n",
    "[ 12, 9, 3, 720, 2880, 272, 167.3, 3.6511, 3.0494, 26000], # 2.5h\n",
    "[ 12, 9, 3, 720, 2880, 256, 164.0, 3.5844, 3.0462,  29000],# 2.4h\n",
    "[ 12, 9, 3, 720, 2880, 256, 164.0, 3.5365, 3.0348, 26000], # 2.2h\n",
    "[ 12, 9, 3, 720, 2880, 240, 160.7, 3.4749, 3.0336,  31000],# 2.6h\n",
    "[ 12, 9, 3, 720, 2880, 240, 160.7, 3.4384, 3.0306,  30000],# 2.5h\n",
    "[ 12, 9, 3, 720, 2880, 240, 160.7, 3.5057,+3.0295,  29000],# 2.3h\n",
    "[ 12, 9, 3, 720, 2880, 240, 160.7, 3.5687, 3.0490,  28000],# 2.3h\n",
    "[ 12, 9, 3, 720, 2880, 240, 160.7, 3.6964, 3.0440, 26000], # 2.2h 12.4G\n",
    "[ 12, 9, 3, 720, 2880, 224, 157.4, 3.5403, 3.0422,  29000],# 2.3h\n",
    "[ 12, 9, 3, 720, 2880, 224, 157.4, 3.5672, 3.0380, 26000], # 2.1h\n",
    "[ 12, 9, 3, 720, 2880, 208, 154.1, 3.4636, 3.0317,  31000],# 2.4h\n",
    "[ 12, 9, 3, 720, 2880, 208, 154.1, 3.4297,+3.0303,  30000],# 2.3h\n",
    "[ 12, 9, 3, 720, 2880, 208, 154.1, 3.4756,+3.0302,  29000],# 2.2h\n",
    "[ 12, 9, 3, 720, 2880, 208, 154.1, 3.5253, 3.0344,  28000],# 2.2h 12.0G\n",
    "[ 12, 9, 3, 720, 2880, 208, 154.1, 3.5771, 3.0359, 26000], # 2.0h\n",
    "[ 12, 9, 3, 720, 2880, 192, 150.7, 3.4604, 3.0381,  29000],# 2.1h\n",
    "[ 12, 9, 3, 720, 2880, 192, 150.7, 3.4878, 3.0363,  27000],# 2.0h\n",
    "[ 12, 9, 3, 720, 2880, 192, 150.7, 3.5427, 3.0318, 26000], # 1.9h\n",
    "[ 12, 9, 3, 720, 2880, 192, 150.7, 3.5490, 3.0377,  25000],# 1.8h\n",
    "[ 12, 9, 3, 720, 2880, 176, 147.4, 3.4842, 3.0332,  29000],# 2.0h\n",
    "[ 12, 9, 3, 720, 2880, 176, 147.4, 3.5156, 3.0357, 26000], # 1.8h\n",
    "[ 12, 9, 3, 720, 2880, 160, 144.1, 3.5231, 3.0421,  29000],# 1.9h\n",
    "[ 12, 9, 3, 720, 2880, 160, 144.1, 3.5093, 3.0350, 26000], # 1.8h\n",
    "\n",
    "[ 12, 9, 3, 684, 2736, 288, 158.6, 3.5565, 3.0435,  29000],# 2.7h\n",
    "[ 12, 9, 3, 684, 2736, 288, 158.6, 3.5842, 3.0410, 26000], # 2.5h\n",
    "[ 12, 9, 3, 684, 2736, 272, 155.4, 3.4544, 3.0325,  29000],# 2.7h\n",
    "[ 12, 9, 3, 684, 2736, 272, 155.4, 3.5359, 3.0351, 26000], # 2.4h\n",
    "[ 12, 9, 3, 684, 2736, 256, 152.3, 3.4682, 3.0381,  29000],# 2.4h\n",
    "[ 12, 9, 3, 684, 2736, 256, 152.3, 3.5562, 3.0369, 26000], # 2.2h\n",
    "[ 12, 9, 3, 684, 2736, 240, 149.1, 3.4810, 3.0346,  29000],# 2.3h 12.3G\n",
    "[ 12, 9, 3, 684, 2736, 240, 149.1, 3.5267, 3.0347, 26000], # 2.1h 12.2G\n",
    "[ 12, 9, 3, 684, 2736, 224, 146.0, 3.4292, 3.0384,  31000],# 2.4h\n",
    "[ 12, 9, 3, 684, 2736, 224, 146.0, 3.3747,+3.0304,  30000],# 2.4h\n",
    "[ 12, 9, 3, 684, 2736, 224, 146.0, 3.4463,+3.0310,  29000],# 2.2h\n",
    "[ 12, 9, 3, 684, 2736, 224, 146.0, 3.4759, 3.0337,  28000],# 2.2h\n",
    "[ 12, 9, 3, 684, 2736, 224, 146.0, 3.5195, 3.0323, 26000], # 2.0h\n",
    "[ 12, 9, 3, 684, 2736, 208, 142.8, 3.4212, 3.0378,  29000],# 2.1h\n",
    "[ 12, 9, 3, 684, 2736, 208, 142.8, 3.5139, 3.0410, 26000], # 2.0h\n",
    "[ 12, 9, 3, 684, 2736, 192, 139.7, 3.4948, 3.0487,  29000],# 2.0h\n",
    "[ 12, 9, 3, 684, 2736, 192, 139.7, 3.5075, 3.0409, 26000], # 1.9h\n",
    "[ 12, 9, 3, 684, 2736, 176, 136.5, 3.4525, 3.0339,  30000],# 2.1h\n",
    "[ 12, 9, 3, 684, 2736, 176, 136.5, 3.4364,+3.0309,  29000],# 2.0h\n",
    "[ 12, 9, 3, 684, 2736, 176, 136.5, 3.5750, 3.0422,  28000],# 2.0h\n",
    "[ 12, 9, 3, 684, 2736, 176, 136.5, 3.5545, 3.0373, 26000], # 1.8h\n",
    "[ 12, 9, 3, 684, 2736, 160, 133.4, 3.4586, 3.0342,  29000],# 1.9h\n",
    "[ 12, 9, 3, 684, 2736, 160, 133.4, 3.5105, 3.0397, 26000], # 1.7h\n",
    "\n",
    "[ 12, 9, 3, 648, 2592, 304, 149.9, 3.4002, 3.0350,  29000],# 2.8h\n",
    "[ 12, 9, 3, 648, 2592, 304, 149.9, 3.4926, 3.0322, 26000], # 2.6h\n",
    "[ 12, 9, 3, 648, 2592, 288, 146.9, 3.4137, 3.0364,  30000],# 2.9h\n",
    "[ 12, 9, 3, 648, 2592, 288, 146.9, 3.4429,+3.0304,  29000],# 2.7h\n",
    "[ 12, 9, 3, 648, 2592, 288, 146.9, 3.4327,+3.0292,  28000],# 2.7h\n",
    "[+12, 9, 3, 648, 2592, 288, 146.9, 3.4521,+3.0254,  27000],# 2.6h  minGemma-hidden_layers12-att_heads9-kv_heads3-hidden648-intermediate2592-head_dim288-T1024--2025-09-21-00-22.pth\n",
    "[ 12, 9, 3, 648, 2592, 288, 146.9, 3.4829, 3.0345, 26000], # 2.5h\n",
    "[ 12, 9, 3, 648, 2592, 288, 146.9, 3.4638,+3.0298, 26000], # 2.5h again\n",
    "[ 12, 9, 3, 648, 2592, 288, 146.9, 3.8253, 3.0607,  25000],# 2.4h\n",
    "[ 12, 9, 3, 648, 2592, 272, 143.9, 3.4234, 3.0369,  29000],# 2.6h\n",
    "[ 12, 9, 3, 648, 2592, 272, 143.9, 3.4831, 3.0407,  27000],# 2.5h\n",
    "[ 12, 9, 3, 648, 2592, 272, 143.9, 3.4566,+3.0309, 26000], # 2.4h\n",
    "[ 12, 9, 3, 648, 2592, 272, 143.9, 3.4591,+3.0294, 26000], # 2.4h again\n",
    "[ 12, 9, 3, 648, 2592, 272, 143.9, 3.5094,+3.0308,  25000],# 2.3h\n",
    "[ 12, 9, 3, 648, 2592, 272, 143.9, 3.5459, 3.0399,  24000],# 2.2h\n",
    "[ 12, 9, 3, 648, 2592, 256, 140.9, 3.4340, 3.0336,  29000],# 2.3h\n",
    "[ 12, 9, 3, 648, 2592, 256, 140.9, 3.5019, 3.0430, 26000], # 2.1h\n",
    "[ 12, 9, 3, 648, 2592, 240, 137.9, 3.4387, 3.0356,  29000],# 2.3h\n",
    "[ 12, 9, 3, 648, 2592, 240, 137.9, 3.5070, 3.0363, 26000], # 2.1h\n",
    "[ 12, 9, 3, 648, 2592, 224, 134.9, 3.3899, 3.0402,  15000],# 1.8h\n",
    "[ 12, 9, 3, 648, 2592, 224, 134.9, 3.3904, 3.0319,  29000],# 2.2h\n",
    "[ 12, 9, 3, 648, 2592, 224, 134.9, 3.4826, 3.0354, 26000], # 2.0h\n",
    "[ 12, 9, 3, 648, 2592, 208, 131.9, 3.4578, 3.0398,  29000],# 2.1h\n",
    "[ 12, 9, 3, 648, 2592, 208, 131.9, 3.4744, 3.0330, 26000], # 1.9h\n",
    "[ 12, 9, 3, 648, 2592, 192, 129.0, 3.3839, 3.0399,  15000],# 1.6h\n",
    "[ 12, 9, 3, 648, 2592, 192, 129.0, 3.4152, 3.0329,  29000],# 2.0h\n",
    "[ 12, 9, 3, 648, 2592, 192, 129.0, 3.4367, 3.0383,  14000],# 1.5h\n",
    "[ 12, 9, 3, 648, 2592, 192, 129.0, 3.4851, 3.0394, 26000], # 1.8h\n",
    "[ 12, 9, 3, 648, 2592, 192, 129.0, 3.5651, 3.0323, 13000], # lr23e-4\n",
    "[ 12, 9, 3, 648, 2592, 176, 126.0, 3.3715, 3.0316,  29000],# 1.9h\n",
    "[ 12, 9, 3, 648, 2592, 176, 126.0, 3.6647, 3.0716, 26000], # 1.8h\n",
    "[ 12, 9, 3, 648, 2592, 160, 123.0, 3.5471, 3.0538,  29000],# 1.9h\n",
    "[ 12, 9, 3, 648, 2592, 160, 123.0, 3.5477, 3.0413, 26000], # 1.7h\n",
    "\n",
    "[ 12, 9, 3, 612, 2448, 304, 138.4, 3.4046, 3.0420,  29000],# 2.7h\n",
    "[ 12, 9, 3, 612, 2448, 304, 138.4, 3.5047, 3.0394, 26000], # 2.5h\n",
    "[ 12, 9, 3, 612, 2448, 288, 135.5, 3.4940, 3.0321,  29000],# 2.6h\n",
    "[ 12, 9, 3, 612, 2448, 288, 135.5, 3.4302, 3.0336, 26000], # 2.4h\n",
    "[ 12, 9, 3, 612, 2448, 272, 132.7, 3.3692, 3.0352,  30000],# 2.7h\n",
    "[ 12, 9, 3, 612, 2448, 272, 132.7, 3.3911,+3.0286,  29000],# 2.6h\n",
    "[ 12, 9, 3, 612, 2448, 272, 132.7, 3.3992, 3.0334,  28000],# 2.5h\n",
    "[ 12, 9, 3, 612, 2448, 272, 132.7, 3.4671, 3.0338,  27000],# 2.5h 11.6G\n",
    "[ 12, 9, 3, 612, 2448, 272, 132.7, 3.4584, 3.0338, 26000], # 2.4h\n",
    "[ 12, 9, 3, 612, 2448, 256, 129.9, 3.4123, 3.0383,  29000],# 2.3h\n",
    "[ 12, 9, 3, 612, 2448, 256, 129.9, 3.4622, 3.0355, 26000], # 2.1h\n",
    "[ 12, 9, 3, 612, 2448, 240, 127.1, 3.3819, 3.0343,  29000],# 2.2h\n",
    "[ 12, 9, 3, 612, 2448, 240, 127.1, 3.4949, 3.0361, 26000], # 2.0h\n",
    "[ 12, 9, 3, 612, 2448, 224, 124.3, 3.3841, 3.0363,  29000],# 2.1h\n",
    "[ 12, 9, 3, 612, 2448, 224, 124.3, 3.4625, 3.0382, 26000], # 2.0h\n",
    "[ 12, 9, 3, 612, 2448, 208, 121.4, 3.4106, 3.0405,  29000],# 2.1h\n",
    "[ 12, 9, 3, 612, 2448, 208, 121.4, 3.5667, 3.0362, 26000], # 1.9h\n",
    "[ 12, 9, 3, 612, 2448, 192, 118.6, 3.4145, 3.0417,  29000],# 1.9h\n",
    "[ 12, 9, 3, 612, 2448, 192, 118.6, 3.4703, 3.0459, 26000], # 1.8h\n",
    "[ 12, 9, 3, 612, 2448, 176, 115.8, 3.3865, 3.0411,  29000],# 1.9h\n",
    "[ 12, 9, 3, 612, 2448, 176, 115.8, 3.4620, 3.0438, 26000], # 1.7h\n",
    "[ 12, 9, 3, 612, 2448, 160, 113.0, 3.3786, 3.0342,  29000],# 1.8h\n",
    "[ 12, 9, 3, 612, 2448, 160, 113.0, 3.4391, 3.0362, 26000], # 1.6h\n",
    "\n",
    "[ 12, 9, 3, 576, 2304, 288, 124.6, 3.4329, 3.0406,  29000],# 2.6h 11.5G\n",
    "[ 12, 9, 3, 576, 2304, 288, 124.6, 3.4257, 3.0430, 26000], # 2.4h\n",
    "[ 12, 9, 3, 576, 2304, 272, 121.9, 3.3631, 3.0378,  29000],# 2.5h\n",
    "[ 12, 9, 3, 576, 2304, 272, 121.9, 3.4764, 3.0422, 26000], # 2.3h\n",
    "[ 12, 9, 3, 576, 2304, 256, 119.3, 3.3678, 3.0400,  29000],# 2.2h\n",
    "[ 12, 9, 3, 576, 2304, 256, 119.3, 3.4273, 3.0362, 26000], # 2.0h\n",
    "[ 12, 9, 3, 576, 2304, 240, 116.6, 3.3499, 3.0374,  29000],# 2.2h\n",
    "[ 12, 9, 3, 576, 2304, 240, 116.6, 3.4198, 3.0365, 26000], # 2.0h\n",
    "[ 12, 9, 3, 576, 2304, 224, 114.0, 3.3444, 3.0318,  29000],# 2.1h\n",
    "[ 12, 9, 3, 576, 2304, 224, 114.0, 3.4044, 3.0348, 26000], # 1.9h\n",
    "[ 12, 9, 3, 576, 2304, 208, 111.3, 3.3444, 3.0321,  29000],# 2.0h\n",
    "[ 12, 9, 3, 576, 2304, 208, 111.3, 3.4013, 3.0400, 26000], # 1.8h\n",
    "[ 12, 9, 3, 576, 2304, 192, 108.7, 3.3079, 3.0340,  29000],# 1.9h\n",
    "[ 12, 9, 3, 576, 2304, 192, 108.7, 3.3891, 3.0391, 26000], # 1.7h 11.2G\n",
    "[ 12, 9, 3, 576, 2304, 176, 106.0, 3.3746, 3.0367,  29000],# 1.8h\n",
    "[ 12, 9, 3, 576, 2304, 176, 106.0, 3.4320, 3.0440, 26000], # 1.7h\n",
    "[ 12, 9, 3, 576, 2304, 160, 103.3, 3.3714, 3.0440,  29000],# 1.7h\n",
    "[ 12, 9, 3, 576, 2304, 160, 103.3, 3.4274, 3.0348, 26000], # 1.6h \n",
    "\n",
    "[ 12, 9, 3, 540, 2160, 288, 114.0, 3.3524, 3.0433,  29000],# 2.5h\n",
    "[ 12, 9, 3, 540, 2160, 288, 114.0, 3.3910, 3.0435, 26000], # 2.3h\n",
    "[ 12, 9, 3, 540, 2160, 272, 111.5, 3.3322, 3.0412,  29000],# 2.5h\n",
    "[ 12, 9, 3, 540, 2160, 272, 111.5, 3.3857, 3.0381, 26000], # 2.3h\n",
    "[ 12, 9, 3, 540, 2160, 256, 109.0, 3.3490, 3.0391,  29000],# 2.2h\n",
    "[ 12, 9, 3, 540, 2160, 256, 109.0, 3.3911, 3.0432, 26000], # 2.0h\n",
    "[ 12, 9, 3, 540, 2160, 240, 106.5, 3.3381, 3.0431,  29000],# 2.1h 11.3G\n",
    "[ 12, 9, 3, 540, 2160, 240, 106.5, 3.3708, 3.0401, 26000], # 2.0h\n",
    "[ 12, 9, 3, 540, 2160, 224, 104.0, 3.3647, 3.0475,  29000],# 2.0h\n",
    "[ 12, 9, 3, 540, 2160, 224, 104.0, 3.4287, 3.0388, 26000], # 1.9h\n",
    "[ 12, 9, 3, 540, 2160, 208, 101.5, 3.3051, 3.0399,  29000],# 2.0h\n",
    "[ 12, 9, 3, 540, 2160, 208, 101.5, 3.3878, 3.0372, 26000], # 1.8h\n",
    "[ 12, 9, 3, 540, 2160, 192,  99.1, 3.3263, 3.0443,  29000],# 1.9h\n",
    "[ 12, 9, 3, 540, 2160, 192,  99.1, 3.3795, 3.0406, 26000], # 1.7h\n",
    "[ 12, 9, 3, 540, 2160, 176,  96.6, 3.3534, 3.0493,  29000],# 1.8h\n",
    "[ 12, 9, 3, 540, 2160, 176,  96.6, 3.3953, 3.0495, 26000], # 1.6h\n",
    "[ 12, 9, 3, 540, 2160, 160,  94.1, 3.3480, 3.0440,  29000],# 1.7h\n",
    "[ 12, 9, 3, 540, 2160, 160,  94.1, 3.3750, 3.0485, 26000], # 1.6h\n",
    "\n",
    "\n",
    "# local best for H8(4): 3.0294  (bad although only large N_step was tried)\n",
    "[ 12, 8, 4, 816, 3264, 288, 204.7, 3.9291, 3.0631, 29000], # 2.9h 13.6G\n",
    "[ 12, 8, 4, 816, 3264, 272, 200.9, 3.8673, 3.0640, 29000], # 2.8h\n",
    "[ 12, 8, 4, 816, 3264, 256, 197.2, 3.7397, 3.0528, 29000], # 2.5h\n",
    "[ 12, 8, 4, 816, 3264, 240, 193.4, 3.7081, 3.0490, 29000], # 2.5h\n",
    "[ 12, 8, 4, 816, 3264, 224, 189.6, 3.8689, 3.0562, 29000], # 2.4h\n",
    "[ 12, 8, 4, 816, 3264, 208, 185.9, 3.6396, 3.0385, 29000], # 2.3h\n",
    "[ 12, 8, 4, 816, 3264, 192, 182.1, 3.6431, 3.0437, 29000], # 2.2h\n",
    "[ 12, 8, 4, 816, 3264, 176, 178.4, 3.5919, 3.0451, 29000], # 2.1h\n",
    "[ 12, 8, 4, 816, 3264, 160, 174.6, 3.5995, 3.0426, 29000], # 2.1h\n",
    "\n",
    "[ 12, 8, 4, 768, 3072, 288, 187.3, 3.7232, 3.0564, 29000], # 2.7h\n",
    "[ 12, 8, 4, 768, 3072, 272, 183.8, 3.6918, 3.0481, 29000], # 2.7h\n",
    "[ 12, 8, 4, 768, 3072, 256, 180.3, 3.6345, 3.0413, 29000], # 2.4h\n",
    "[ 12, 8, 4, 768, 3072, 240, 176.7, 3.6626, 3.0409, 29000], # 2.3h\n",
    "[ 12, 8, 4, 768, 3072, 224, 173.2, 3.6372, 3.0483, 29000], # 2.2h 12.1G\n",
    "[ 12, 8, 4, 768, 3072, 208, 169.6, 3.5913, 3.0317, 29000], # 2.1h\n",
    "[ 12, 8, 4, 768, 3072, 192, 166.1, 3.5210, 3.0310, 29000], # 2.0h\n",
    "[ 12, 8, 4, 768, 3072, 176, 162.6, 3.6015, 3.0440, 29000], # 1.9h\n",
    "[ 12, 8, 4, 768, 3072, 160, 159.0, 3.5263, 3.0470, 29000], # 1.9h\n",
    "\n",
    "[ 12, 8, 4, 720, 2880, 288, 170.7, 3.5755, 3.0447, 29000], # 2.6h\n",
    "[ 12, 8, 4, 720, 2880, 272, 167.3, 3.6284, 3.0482, 29000], # 2.5h\n",
    "[ 12, 8, 4, 720, 2880, 256, 164.0, 3.5954, 3.0393, 29000], # 2.3h\n",
    "[ 12, 8, 4, 720, 2880, 240, 160.7, 3.5529, 3.0382, 29000], # 2.2h\n",
    "[ 12, 8, 4, 720, 2880, 224, 157.4, 3.5200, 3.0380, 29000], # 2.1h\n",
    "[ 12, 8, 4, 720, 2880, 208, 154.1, 3.5327, 3.0418,  30000],# 2.2h\n",
    "[ 12, 8, 4, 720, 2880, 208, 154.1, 3.4978,+3.0302, 29000], # 2.1h\n",
    "[ 12, 8, 4, 720, 2880, 208, 154.1, 3.5253, 3.0407,  28000],# 2.0h\n",
    "[ 12, 8, 4, 720, 2880, 192, 150.7, 3.7116, 3.0922, 29000], # 2.0h 11.7G\n",
    "[ 12, 8, 4, 720, 2880, 176, 147.4, 3.4693, 3.0417, 29000], # 1.9h\n",
    "[ 12, 8, 4, 720, 2880, 160, 144.1, 3.4827, 3.0325, 29000], # 1.8h 11.5G\n",
    "\n",
    "[ 12, 8, 4, 672, 2688, 288, 154.6, 3.5163, 3.0330, 29000], # 2.5h\n",
    "[ 12, 8, 4, 672, 2688, 272, 151.5, 3.4876, 3.0328, 29000], # 2.5h\n",
    "[ 12, 8, 4, 672, 2688, 256, 148.4, 3.4409, 3.0322,  30000],# 2.3h\n",
    "[ 12, 8, 4, 672, 2688, 256, 148.4, 3.4858,+3.0302, 29000], # 2.2h\n",
    "[ 12, 8, 4, 672, 2688, 256, 148.4, 3.4821, 3.0343,  28000],# 2.2h\n",
    "[ 12, 8, 4, 672, 2688, 240, 145.3, 3.4447, 3.0310, 29000], # 2.1h\n",
    "[ 12, 8, 4, 672, 2688, 224, 142.2, 3.4481, 3.0334,  30000],# 2.2h\n",
    "[ 12, 8, 4, 672, 2688, 224, 142.2, 3.4337,+3.0305, 29000], # 2.1h\n",
    "[ 12, 8, 4, 672, 2688, 224, 142.2, 3.4989, 3.0333,  28000],# 2.0h\n",
    "[ 12, 8, 4, 672, 2688, 208, 139.1, 3.4558, 3.0389, 29000], # 2.0h\n",
    "[ 12, 8, 4, 672, 2688, 192, 136.0, 3.5038, 3.0337, 29000], # 1.9h\n",
    "[ 12, 8, 4, 672, 2688, 176, 133.0, 3.4349, 3.0371,  30000],# 1.9h 11.3G\n",
    "[ 12, 8, 4, 672, 2688, 176, 133.0, 3.4222,+3.0294, 29000], # 1.8h\n",
    "[ 12, 8, 4, 672, 2688, 176, 133.0, 3.4486, 3.0412,  28000],# 1.8h\n",
    "[ 12, 8, 4, 672, 2688, 160, 129.9, 3.4522, 3.0416, 29000], # 1.8h 11.2G\n",
    "\n",
    "[ 12, 8, 4, 624, 2496, 288, 139.3, 3.4249, 3.0373, 29000], # 2.4h 11.3G\n",
    "[ 12, 8, 4, 624, 2496, 272, 136.4, 3.4896, 3.0341, 29000], # 2.4h\n",
    "[ 12, 8, 4, 624, 2496, 256, 133.5, 3.4160, 3.0360, 29000], # 2.1h\n",
    "[ 12, 8, 4, 624, 2496, 240, 130.6, 3.4151, 3.0415, 29000], # 2.1h\n",
    "[ 12, 8, 4, 624, 2496, 224, 127.8, 3.4079, 3.0336, 29000], # 2.0h\n",
    "[ 12, 8, 4, 624, 2496, 208, 124.9, 3.3924, 3.0381,  30000],# 2.1h\n",
    "[ 12, 8, 4, 624, 2496, 208, 124.9, 3.3812,+3.0303, 29000], # 1.9h\n",
    "[ 12, 8, 4, 624, 2496, 208, 124.9, 3.3896, 3.0457,  28000],# 1.9h\n",
    "[ 12, 8, 4, 624, 2496, 192, 122.0, 3.4304, 3.0338, 29000], # 1.8h\n",
    "[ 12, 8, 4, 624, 2496, 176, 119.1, 3.4253, 3.0398, 29000], # 1.8h\n",
    "[ 12, 8, 4, 624, 2496, 160, 116.3, 3.4702, 3.0411, 29000], # 1.7h\n",
    "\n",
    "[ 12, 8, 4, 576, 2304, 288, 124.6, 3.4203, 3.0446, 29000], # 2.4h\n",
    "[ 12, 8, 4, 576, 2304, 272, 121.9, 3.4021, 3.0359, 29000], # 2.3h 11.0G\n",
    "[ 12, 8, 4, 576, 2304, 256, 119.3, 3.4292, 3.0373, 29000], # 2.1h\n",
    "[ 12, 8, 4, 576, 2304, 240, 116.6, 3.3595, 3.0383, 29000], # 2.0h\n",
    "[ 12, 8, 4, 576, 2304, 224, 114.0, 3.3667, 3.0331, 29000], # 1.9h\n",
    "[ 12, 8, 4, 576, 2304, 208, 111.3, 3.3864, 3.0471, 29000], # 1.9h\n",
    "[ 12, 8, 4, 576, 2304, 192, 108.7, 3.4096, 3.0411, 29000], # 1.8h\n",
    "[ 12, 8, 4, 576, 2304, 176, 106.0, 3.4191, 3.0471, 29000], # 1.7h\n",
    "[ 12, 8, 4, 576, 2304, 160, 103.3, 3.3728, 3.0423, 29000], # 1.6h\n",
    "\n",
    "[ 12, 8, 4, 528, 2112, 288, 110.5, 3.3704, 3.0536, 29000], # 2.3h\n",
    "[ 12, 8, 4, 528, 2112, 272, 108.1, 3.3416, 3.0475, 29000], # 2.3h\n",
    "[ 12, 8, 4, 528, 2112, 256, 105.7, 3.3361, 3.0351, 29000], # 2.0h\n",
    "[ 12, 8, 4, 528, 2112, 240, 103.2, 3.3460, 3.0486, 29000], # 2.0h\n",
    "[ 12, 8, 4, 528, 2112, 224, 100.8, 3.3563, 3.0472, 29000], # 1.9h\n",
    "[ 12, 8, 4, 528, 2112, 208,  98.4, 3.3526, 3.0535, 29000], # 1.8h\n",
    "[ 12, 8, 4, 528, 2112, 192,  95.9, 3.3536, 3.0444, 29000], # 1.7h\n",
    "[ 12, 8, 4, 528, 2112, 176,  93.5, 3.3031, 3.0456, 29000], # 1.7h\n",
    "[ 12, 8, 4, 528, 2112, 160,  91.1, 3.3454, 3.0465, 29000], # 1.6h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "48596de9-a3d5-4a0b-b74a-24f93f61b3de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "165.888\n",
      "L12 att9 kv_heads3 hidden648 intermediate2592 head_dim288 T1024\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13500' max='13500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13500/13500 2:37:09, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>13500</td>\n",
       "      <td>3.452100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 12, 9, 3, 648, 2592, 288, 146.9, 3.4521, 3.0254, 27000],\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt; import numpy as np; import time, torch; device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "from transformers import AutoTokenizer, TrainingArguments, DefaultDataCollator, Trainer\n",
    "vocab_size = 50257 # =tokenizer.vocab_size  # FIX!!! # G256128    ### T=256 for minGemma # G8192 for real Gemma\n",
    "num_hidden_layers =  12 # 8 # G28 G18 #blocks\n",
    "num_attention_heads = 9 # 4 # G16 G8\n",
    "num_key_value_heads = 3 # 4 # G16 G1\n",
    "hidden_size = num_attention_heads*72 # 128 # G3072 G2048 # embedding dimension\n",
    "intermediate_size = hidden_size*4 # x4 or x8 # time limiting factor #512 # G24576 G16384  # MLP inner dim\n",
    "head_dim = 288 # 32 # G256 # dim in attention # Doesn't affect time\n",
    "rms_norm_eps = 1e-6 # 1e-6\n",
    "rope_theta = 1000.0 # scale freq is small for S-model. 1000 might work too # G10000.0\n",
    "\n",
    "def apply_rotary_emb(x: torch.Tensor, dim: int) -> torch.Tensor: # seq_len = x.size(1) # N\n",
    "    freqs = 1.0 / (rope_theta ** (torch.arange(0, dim, 2, device=device).float() / dim)) # Dynamically compute frequency cis\n",
    "    t = torch.arange(x.size(1), device=device); freqs = torch.outer(t, freqs).float(); freqs_cis = torch.polar(torch.ones_like(freqs), freqs)  # complex64\n",
    "    x_ = torch.view_as_complex(torch.stack(torch.chunk(x.transpose(1, 2).float(), 2, dim=-1), dim=-1))\n",
    "    x_out = torch.view_as_real(x_ * freqs_cis.unsqueeze(0)).type_as(x)  # Ensure batch dimension is handled\n",
    "    x_out = torch.cat(torch.chunk(x_out, 2, dim=-1), dim=-2)\n",
    "    return x_out.reshape(x_out.shape[0], x_out.shape[1], x_out.shape[2], -1).transpose(1, 2)\n",
    "\n",
    "class RMSNorm(torch.nn.Module): # RMS:4.326552, RMS_no_weight:4.410741 # RMS':4.554899\n",
    "    def __init__(self, dim: int = hidden_size):\n",
    "        super().__init__(); self.weight = torch.nn.Parameter(torch.zeros(dim)) # one weight per feature to be learned\n",
    "    def _norm(self, x): # mean square for each feature (across the last dimension)\n",
    "        return x * torch.rsqrt(x.pow(2).mean(-1, keepdim=True) + rms_norm_eps)\n",
    "    def forward(self, x): # ensure the data type matches the input.\n",
    "        return self._norm(x.float()).type_as(x) * (1 + self.weight)\n",
    "        \n",
    "class GemmaAttention(torch.nn.Module): # MQA = K,V shared by 4Qs\n",
    "    def __init__(self):\n",
    "        super().__init__(); self.qkv_proj = torch.nn.Linear(hidden_size, (num_attention_heads + 2 * num_key_value_heads) * head_dim, bias=False); self.o_proj = torch.nn.Linear(num_attention_heads * head_dim, hidden_size, bias=False) # concatenated attention outputs back to the hidden size.\n",
    "    def forward(self, hidden_states: torch.Tensor,) -> torch.Tensor:  # in=(B, T, hidden_size)\n",
    "        batch_size, input_len, _ = hidden_states.shape\n",
    "        qkv = self.qkv_proj(hidden_states)\n",
    "        xq, xk, xv = qkv.split([num_attention_heads * head_dim, num_key_value_heads * head_dim, num_key_value_heads * head_dim],dim=-1)\n",
    "        xq = xq.view(batch_size, -1, num_attention_heads, head_dim); xk = xk.view(batch_size, -1, num_key_value_heads, head_dim); xv = xv.view(batch_size, -1, num_key_value_heads, head_dim)\n",
    "        xq = apply_rotary_emb(xq, head_dim); xk = apply_rotary_emb(xk, head_dim)\n",
    "        if num_key_value_heads != num_attention_heads:  # Q/KV multiples of K and V to match Q\n",
    "            xk = torch.repeat_interleave(xk, num_attention_heads // num_key_value_heads, dim=2) # [B, T, n_local_heads, head_dim]\n",
    "            xv = torch.repeat_interleave(xv, num_attention_heads // num_key_value_heads, dim=2)\n",
    "        q = xq.transpose(1, 2); k = xk.transpose(1, 2); v = xv.transpose(1, 2) # [batch_size, n_local_heads, input_len, head_dim]\n",
    "        output = torch.nn.functional.scaled_dot_product_attention(q, k, v, attn_mask=None, dropout_p=0, is_causal=True) # B nh T hs        \n",
    "        output = output.transpose(1, 2).contiguous().view(batch_size, input_len, -1)  # [B, T, \"hidden_dim\"]\n",
    "        return self.o_proj(output)\n",
    "\n",
    "class GemmaDecoderLayer(torch.nn.Module): # normalize before and after the attention mechanism\n",
    "    def __init__(self):\n",
    "        super().__init__(); self.self_attn = GemmaAttention(); self.input_layernorm = RMSNorm(); self.post_attention_layernorm = RMSNorm(); self.gate_proj = torch.nn.Linear(hidden_size, intermediate_size); self.up_proj = torch.nn.Linear(hidden_size, intermediate_size); self.down_proj = torch.nn.Linear(intermediate_size, hidden_size) # mlp\n",
    "    def forward(self, hidden_states: torch.Tensor) -> torch.Tensor:  # input_size = (B, T, hidden_size)\n",
    "        residual = hidden_states # Self Attention Block\n",
    "        hidden_states = self.input_layernorm(hidden_states); hidden_states = self.self_attn(hidden_states=hidden_states)\n",
    "        hidden_states = residual + hidden_states\n",
    "        residual = hidden_states # MLP Block\n",
    "        hidden_states = self.post_attention_layernorm(hidden_states); gate = torch.nn.functional.gelu(self.gate_proj(hidden_states)); up = self.up_proj(hidden_states); fuse = gate * up; hidden_states = self.down_proj(fuse) # mlp\n",
    "        return residual + hidden_states\n",
    "\n",
    "class minGemma(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__(); self.embedder = torch.nn.Embedding(vocab_size, hidden_size); self.layers = torch.nn.ModuleList(GemmaDecoderLayer() for _ in range(num_hidden_layers)); self.norm = RMSNorm();\n",
    "    def forward(self, input_token_ids: torch.Tensor) -> torch.Tensor: # (B, T)\n",
    "        hidden_states = self.embedder(input_token_ids[:,:-1]) # (B, T) & (vocab_size, hidden_size) -> (B, T, hidden_size)\n",
    "        hidden_states = hidden_states * (hidden_size**0.5)\n",
    "        for i in range(len(self.layers)):\n",
    "            hidden_states = self.layers[i](hidden_states) # shortened too much???\n",
    "        hidden_states = self.norm(hidden_states) # -> (B, T, hidden_size)        \n",
    "        embedder_weight = self.embedder.weight\n",
    "        logits = torch.matmul(hidden_states, embedder_weight.t()); b,t,v=logits.shape; # (B, T, hidden_size) @ (hidden_size, vocab_size) -> (B, T, vocab_size)\n",
    "        loss = torch.nn.functional.cross_entropy(logits.view(b*t,v), input_token_ids[:,1:].reshape(b*t)) #, weight=None, ignore_index=-100, reduction='mean')\n",
    "        return loss, logits # logits, loss\n",
    "\n",
    "def map_to_array5(ix):\n",
    "    common = torch.stack([torch.from_numpy((train_data[i[0]:i[0]+T+1]).astype(np.int64)) for i in ix]); return {'input_token_ids': common}\n",
    "def map_to_array_Val(ix):\n",
    "    common = torch.stack([torch.from_numpy((val_data[i[0]:i[0]+T+1]).astype(np.int64)) for i in ix]); return {'input_token_ids': common}\n",
    "\n",
    "train_data = np.memmap('train_BabyLM_10M.bin', dtype=np.uint16, mode='r'); val_data = np.memmap('val_BabyLM.bin', dtype=np.uint16, mode='r')\n",
    "T=1024; B=12//2; N_step=13500*2; print(T * B * N_step / 1000000) # 0.01 B-tokens being calculated # n_steps=N_step;\n",
    "model = minGemma().to(device); print(f'L{num_hidden_layers}' f' att{num_attention_heads}' f' kv_heads{num_key_value_heads}' f' hidden{hidden_size}' f' intermediate{intermediate_size}' f' head_dim{head_dim}' f' T{T}')\n",
    "\n",
    "# Normal # lr_scheduler_type=\"linear\" can be omitted\n",
    "training_args = TrainingArguments(gradient_accumulation_steps=2, learning_rate=24.0e-4, weight_decay=1.2, num_train_epochs=1, logging_strategy='epoch', output_dir='./', bf16=True, per_device_train_batch_size=B, per_device_eval_batch_size=B, eval_strategy='no', save_strategy='no', report_to='none', remove_unused_columns=False, dataloader_pin_memory=True) #, dataloader_num_workers=4\n",
    "trainer = Trainer(model=model, args=training_args, train_dataset=torch.utils.data.TensorDataset(torch.randint(len(train_data)-T-1, (B*N_step,))), data_collator=map_to_array5);\n",
    "result = trainer.train(); tloss=result[2][\"train_loss\"] # trainer = Trainer(model=model, args=training_args, eval_dataset=torch.utils.data.TensorDataset(torch.randint(len(val_data)-T-1, (B*400*4,))), data_collator=map_to_array_Val); trainer.can_return_loss = True; loss_current = trainer.evaluate()[\"eval_loss\"]\n",
    "\n",
    "loss = []; model.eval(); B2=16; B2=12//2; torch.cuda.empty_cache();\n",
    "for k in range(5000*2): #4000 # std=0.0056 for 1000 with 89sec\n",
    "    val_ind = torch.randint(len(val_data)-T-1, (B2,)); common = (torch.stack([torch.from_numpy((val_data[i:i+T+1]).astype(np.int64)) for i in val_ind]))\n",
    "    loss += [model(common.to('cuda', non_blocking=True))[0].item()]\n",
    "if torch.Tensor(loss).mean() < 3.0254:\n",
    "    torch.save(model.state_dict(), f'{model.__class__.__name__}' f'-hidden_layers{num_hidden_layers}' f'-att_heads{num_attention_heads}' f'-kv_heads{num_key_value_heads}' f'-hidden{hidden_size}' f'-intermediate{intermediate_size}' f'-head_dim{head_dim}' f'-T{T}' f'--{time.strftime(\"%Y-%m-%d-%H-%M\")}.pth')\n",
    "model.train(); del common; print(f'[ {num_hidden_layers}, {num_attention_heads}, {num_key_value_heads}, {hidden_size}, {intermediate_size}, {head_dim}, {sum(p.numel() for p in model.parameters()) / 10**6:.1f}, {tloss:.4f}, {torch.Tensor(loss).mean():.4f}, {N_step}],')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
