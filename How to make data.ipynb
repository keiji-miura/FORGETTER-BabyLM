{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8c576ca-5e5c-479d-b3cc-e1320a8e2cf5",
   "metadata": {},
   "source": [
    "###  Creating .bin file\n",
    "A binary file for encoded texts is used for pretraining minGemma, as it is economical.\n",
    "The bin file includes bnc_spoken, childes etc. as a single long tape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42a1a711-ebe1-4998-ba64-ef0d46e58742",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1514 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10669646\n",
      "80183016\n",
      "116181114\n",
      "147805441\n",
      "168269687\n",
      "170506593\n"
     ]
    }
   ],
   "source": [
    "# Counting total token length (arr_len) for writing .bin files in the next cell # for babyLM\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('gpt2')\n",
    "\n",
    "## Switch val/test/train data here\n",
    "# dn = \"../BabyLM/text_data/dev/\"; ch = \".dev\"\n",
    "# dn = \"../BabyLM/text_data/test/\"; ch = \".test\"\n",
    "dn = \"../BabyLM/text_data/train_100M/\"; ch = \".train\"\n",
    "arr_len = 0\n",
    "for fn in [\"bnc_spoken\", \"childes\", \"gutenberg\", \"open_subtitles\", \"simple_wiki\", \"switchboard\"]:\n",
    "    with open(dn+fn+ch, encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            arr_len += len(tokenizer.encode(line))\n",
    "    print(arr_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e65a0b04-ddd0-40f7-a335-74f8c07cb17d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10669646\n",
      "80183016\n",
      "116181114\n",
      "147805441\n",
      "168269687\n",
      "170506593\n"
     ]
    }
   ],
   "source": [
    "# Writing .bin files\n",
    "arr = np.memmap(\"train_BabyLM_100M.bin\", dtype=np.uint16, mode='w+', shape=(arr_len,))   ## Switch filename: train_BabyLM_100M.bin, val_BabyLM.bin, test_BabyLM.bin\n",
    "i = 0\n",
    "for fn in [\"bnc_spoken\", \"childes\", \"gutenberg\", \"open_subtitles\", \"simple_wiki\", \"switchboard\"]:\n",
    "    with open(dn+fn+ch, encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            ids = np.array(tokenizer.encode(line), dtype=np.uint16)\n",
    "            arr[i: i+len(ids)] = ids\n",
    "            i += len(ids)\n",
    "    print(i)\n",
    "arr.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3ca1839c-2557-406d-957c-55bf760068a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" wages right, that's  all this\\nWhy have you just discounted it to there?\\nSorry?\\nWhy have you discounted it to W R?\\nWell it's, well, er, there's no need why that should be the case, it could be, you know, it could look something like that.\\nBut, up in the, there the migrant's decision making process will be, is this area here  right, is that area there, greater  than that area there.\\nAlright, so this is the discounted sum in er, in non-agriculture, in the urban area, and this is the value, the discounted sum in agriculture.\\nNow, clearly on the, on the way I've drawn this diagram it is.\\nRight, but that's going to depend on right, not only the wage differential, now if the wage differential is very large it's likely that this discounted sum is going to, you know, be larger than that.\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading .bin files (for practice)\n",
    "train_data = np.memmap('train_BabyLM_100M.bin', dtype=np.uint16, mode='r')\n",
    "tokenizer.decode(train_data[153:353])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
